<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Senit_Co</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://senitco.github.io/"/>
  <updated>2017-07-11T01:15:40.292Z</updated>
  <id>https://senitco.github.io/</id>
  
  <author>
    <name>Senit_Co</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>图像特征之FAST角点检测</title>
    <link href="https://senitco.github.io/2017/07/10/image-feature-fast/"/>
    <id>https://senitco.github.io/2017/07/10/image-feature-fast/</id>
    <published>2017-07-10T01:50:52.855Z</published>
    <updated>2017-07-11T01:15:40.292Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;前面已经介绍多种图像特征点(角点、斑点、极值点)的检测算法，包括Harris、LoG、HoG以及SIFT、SURF等，这些方法大多涉及图像局部邻域的梯度计算和统计，相比较而言，FAST(Features From Accelerated Segment Test)在进行角点检测时，计算速度更快，实时性更好。<br><a id="more"></a></p>
<h3 id="FAST角点定义"><a href="#FAST角点定义" class="headerlink" title="FAST角点定义"></a>FAST角点定义</h3><p>&emsp;&emsp;FAST角点定义为：若某像素点与周围邻域足够多的像素点处于不同区域，则该像素可能为角点。考虑灰度图像，即若某像素点的灰度值比周围邻域足够多的像素点的灰度值大或小，则该点可能为角点。</p>
<h3 id="算法步骤"><a href="#算法步骤" class="headerlink" title="算法步骤"></a>算法步骤</h3><ul>
<li>对于图像中一个像素点$p$，其灰度值为$I_p$</li>
<li>以该像素点为中心考虑一个半径为3的离散化的Bresenham圆，圆边界上有16个像素(如下图所示)</li>
<li>设定一个合适的阈值$t$，如果圆上有n个连续像素点的灰度值小于$I_p-t$或者大于$I_p+t$，那么这个点即可判断为角点(n的值可取12或9)</li>
</ul>
<p><img src="https://ooo.0o0.ooo/2017/07/10/596386112222c.jpg" alt="circle.jpg"></p>
<p>一种快速排除大部分非角点像素的方法就是检查周围1、5、9、13四个位置的像素，如果位置1和9与中心像素P点的灰度差小于给定阈值，则P点不可能是角点，直接排除；否则进一步判断位置5和13与中心像素的灰度差，如果四个像素中至少有3个像素与P点的灰度差超过阈值，则考察邻域圆上16个像素点与中心点的灰度差，如果有至少9个超过给定阈值则认为是角点。</p>
<h3 id="角点分类器"><a href="#角点分类器" class="headerlink" title="角点分类器"></a>角点分类器</h3><ul>
<li>选取需要检测的场景的多张图像进行FAST角点检测，选取合适的阈值n(n&lt;12)，提取多个特征点作为训练数据</li>
<li>对于特征点邻域圆上的16个像素$x \in {1,2,…,16 }$，按下式将其划分为3类<br>$$S_{p\rightarrow x} = \begin{cases} d, &emsp;I_{p\rightarrow x} \leq I_p-t \\ s, &emsp;I_p-t \leq I_{p\rightarrow x} \leq I_p+t \\ b, &emsp;I_p+t \leq  I_{p\rightarrow x} \end{cases}$$</li>
<li>对每个特征点定义一个bool变量$K_p$，如果$p$是一个角点，则$K_p$为真，否则为假</li>
<li>对提取的特征点集进行训练，使用ID3算法建立一颗决策树，通过第$x$个像素点进行决策树的划分，对集合$P$，得到熵值为<br>$$H(P)=(c+\hat{c})log_2 (c+\hat{c})-clog_2 c - \hat{c}log_2 \hat{c} $$<br>其中$c$为角点的数目，$\hat{c}$为非角点的数目。由此得到的信息增益为<br>$$\Delta H = H(P) - H(P_d) - H(P_s) - H(P_b)$$<br>选择信息增益最大位置进行划分，得到决策树</li>
<li>使用决策树对类似场景进行特征点的检测与分类</li>
</ul>
<h3 id="非极大值抑制"><a href="#非极大值抑制" class="headerlink" title="非极大值抑制"></a>非极大值抑制</h3><p>&emsp;&emsp;对于邻近位置存在多个特征点的情况，需要进一步做非极大值抑制(Non-Maximal Suppression)。给每个已经检测到的角点一个量化的值$V$，然后比较相邻角点的$V$值，保留局部邻域内$V$值最大的点。$V$值可定义为</p>
<ul>
<li>特征点与邻域16个像素点灰度绝对差值的和</li>
<li>$V = max(\Sigma_{x \in S_{bright}} |I_{p\rightarrow x} - I_p| - t, \Sigma_{x \in S_{dark}} |I_{p\rightarrow x} - I_p| - t)$<br>式中，$S_{bright}$是16个邻域像素点中灰度值大于$I_p+t$的像素点的集合，而$S_{dark}$表示的是那些灰度值小于$I_p−t$的像素点。</li>
</ul>
<h3 id="算法特点"><a href="#算法特点" class="headerlink" title="算法特点"></a>算法特点</h3><ul>
<li>FAST算法比其他角点检测算法要快</li>
<li>受图像噪声以及设定阈值影响较大</li>
<li>当设置$n&lt;12$时，不能用快速方法过滤非角点</li>
<li>FAST不产生多尺度特征，不具备旋转不变性，而且检测到的角点不是最优</li>
</ul>
<h3 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h3><ul>
<li><a href="https://www.edwardrosten.com/work/rosten_2006_machine.pdf" target="_blank" rel="external">Paper: Machine learning for high-speed corner detection</a></li>
<li><a href="https://pdfs.semanticscholar.org/a963/288ffecda4fd2bc475efe7cfb59ab094e7c1.pdf" target="_blank" rel="external">Paper: Faster and better: a machine learning approach to corner detection</a></li>
<li><a href="http://www.cnblogs.com/ronny/p/4078710.html" target="_blank" rel="external">http://www.cnblogs.com/ronny/p/4078710.html</a></li>
<li><a href="http://blog.csdn.net/hujingshuang/article/details/46898007" target="_blank" rel="external">http://blog.csdn.net/hujingshuang/article/details/46898007</a></li>
<li><a href="http://blog.csdn.net/lql0716/article/details/65662648" target="_blank" rel="external">http://blog.csdn.net/lql0716/article/details/65662648</a></li>
<li><a href="https://liu-wenwu.github.io/2016/10/08/fast-corners/" target="_blank" rel="external">https://liu-wenwu.github.io/2016/10/08/fast-corners/</a></li>
<li><a href="http://blog.csdn.net/skeeee/article/details/9405531" target="_blank" rel="external">http://blog.csdn.net/skeeee/article/details/9405531</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp;前面已经介绍多种图像特征点(角点、斑点、极值点)的检测算法，包括Harris、LoG、HoG以及SIFT、SURF等，这些方法大多涉及图像局部邻域的梯度计算和统计，相比较而言，FAST(Features From Accelerated Segment Test)在进行角点检测时，计算速度更快，实时性更好。&lt;br&gt;
    
    </summary>
    
      <category term="Algorithm" scheme="https://senitco.github.io/categories/Algorithm/"/>
    
    
      <category term="Image" scheme="https://senitco.github.io/tags/Image/"/>
    
  </entry>
  
  <entry>
    <title>图像特征描述子之PCA-SIFT与GLOH</title>
    <link href="https://senitco.github.io/2017/07/04/image-feature-PCA_SIFT-GLOH/"/>
    <id>https://senitco.github.io/2017/07/04/image-feature-PCA_SIFT-GLOH/</id>
    <published>2017-07-04T01:44:29.241Z</published>
    <updated>2017-07-04T02:57:26.787Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;SIFT和SURF是两种应用较为广泛的图像特征描述子，SURF可以看做是SIFT特征的加速版本。在SIFT的基础上，又陆续诞生了其他的变体：PCA-SIFT和GLOH(Gradient Location-Orientation Histogram)。<br><a id="more"></a></p>
<h3 id="PCA-SIFT"><a href="#PCA-SIFT" class="headerlink" title="PCA-SIFT"></a>PCA-SIFT</h3><p>&emsp;&emsp;SIFT特征提取主要分为4步：尺度空间构建，关键点定位，主方向分配，生成特征描述子。PCA-SIFT的前3步和标准SIFT相同，也就说PCA-SIFT和标准SIFT具有相同的尺度空间、亚像素定位以及主方向。但在生成特征描述子时，使用特征点周围$41 \times 41$的邻域计算特征向量，并通过主成分分析(PCA)，对特征向量进行降维，以滤除噪声，保留有效信息，并提高匹配效率。PCA-SIFT生成特征描述子的算法流程如下： </p>
<ol>
<li>以特征点为中心，选定$41 \times 41$的矩形邻域  </li>
<li>计算邻域内所有像素水平和垂直方向的梯度(偏导数)，得到一个$39 \times 39 \times 2 = 3042$维的特征向量(不计最外层像素)</li>
<li>假设有$N$个特征点，所有特征点描述子向量构成一个$N \times 3042$的矩阵，计算所有向量的协方差矩阵$C$</li>
<li>计算协方差矩阵$C$前$k$个最大特征值对应的特征向量，组成一个$3042 \times k$的投影矩阵$T$</li>
<li>对于新的特征描述子向量，乘以投影矩阵$T$，可以得到降维后的特征向量</li>
</ol>
<p>&emsp;&emsp;实际上，第3步和第4步一般提前计算好，也就是投影矩阵$T$是事先通过大量典型样本的训练得到。关于维数$k$的选择，可以是一个经验设定的固定值，也可以是基于特征值能量百分比动态选择。一般取20可得到较佳的效果。<br>&emsp;&emsp;PCA-SIFT描述子和标准SIFT相比，在保持各种不变性的同时，降低了特征向量的维数，使得特征点匹配速度大大提升。但其缺点是事先需要有一组典型图像的学习，而且，训练得到的投影矩阵只适用于同类的输入图像。</p>
<h3 id="GLOH"><a href="#GLOH" class="headerlink" title="GLOH"></a>GLOH</h3><p>&emsp;&emsp;梯度位置方向直方图(Gradient Location-Orientation Histogram, GLOH)也是SIFT特征描述子的一种扩展，其目的是为了增加特征描述子的鲁棒性和独特性。GLOH把标准SIFT中$4 \times 4$的邻域子块改成仿射状的对数-极坐标同心圆，同心圆半径分别设为6、11、15。在角度方向分成8等分，每等分为$\pi / 4$，这样一共产生了17个图像子块。如下图所示，在每个子块中，计算梯度方向直方图，梯度方向分为16个方向区间，因此可生成一个$17 \times 16 = 272$的特征向量。借助PCA-SIFT的思想，通过事先建立典型图像的协方差矩阵，并得到投影矩阵。然后，对每个特征点进行PCA降维处理，最终得到一个128维的特征向量，与标准SIFT保持一致。此外，也可以对GLOH进行简化，在生成梯度直方图时，只分8个方向，这样特征向量的维数为$17 \times 8 = 136$，就不需要进行降维处理，减少对样本图像的依赖性。</p>
<p><img src="https://ooo.0o0.ooo/2017/07/04/595b01624b9bf.jpg" alt="keypoint descriptor.jpg" title="GLOH特征点描述子"></p>
<h3 id="result"><a href="#result" class="headerlink" title="result"></a>result</h3><p>&emsp;&emsp;SIFT、PCA-SIFT、GLOH的实验结果如下所示</p>
<p><img src="https://ooo.0o0.ooo/2017/07/04/595b027a6da58.jpg" alt="keypoint match.jpg" title="SIFT、PCA-SIFT特征点匹配"></p>
<p><img src="https://ooo.0o0.ooo/2017/07/04/595b027a6c35e.jpg" alt="keypoint detection.jpg" title="GLOH特征点检测与匹配"></p>
<h3 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h3><ul>
<li><a href="http://www.cs.cmu.edu/~rahuls/pub/cvpr2004-keypoint-rahuls.pdf" target="_blank" rel="external">Paper: PCA-SIFT: A More Distinctive Representation for Local Image Descriptors</a></li>
<li><a href="https://www.robots.ox.ac.uk/~vgg/research/affine/det_eval_files/mikolajczyk_pami2004.pdf" target="_blank" rel="external">Paper: A Performance Evaluation of Local Descriptors</a></li>
<li><a href="http://blog.csdn.net/JIEJINQUANIL/article/details/50419119" target="_blank" rel="external">http://blog.csdn.net/JIEJINQUANIL/article/details/50419119</a></li>
<li><a href="http://blog.csdn.net/luoshixian099/article/details/49174869" target="_blank" rel="external">http://blog.csdn.net/luoshixian099/article/details/49174869</a></li>
<li><a href="http://blog.csdn.net/songzitea/article/details/18270457" target="_blank" rel="external">http://blog.csdn.net/songzitea/article/details/18270457</a></li>
<li><a href="http://blog.csdn.net/abcjennifer/article/details/7681718" target="_blank" rel="external">http://blog.csdn.net/abcjennifer/article/details/7681718</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp;SIFT和SURF是两种应用较为广泛的图像特征描述子，SURF可以看做是SIFT特征的加速版本。在SIFT的基础上，又陆续诞生了其他的变体：PCA-SIFT和GLOH(Gradient Location-Orientation Histogram)。&lt;br&gt;
    
    </summary>
    
      <category term="Algorithm" scheme="https://senitco.github.io/categories/Algorithm/"/>
    
    
      <category term="Image" scheme="https://senitco.github.io/tags/Image/"/>
    
  </entry>
  
  <entry>
    <title>图像特征之SURF特征匹配</title>
    <link href="https://senitco.github.io/2017/07/03/image-feature-surf/"/>
    <id>https://senitco.github.io/2017/07/03/image-feature-surf/</id>
    <published>2017-07-03T00:59:31.310Z</published>
    <updated>2017-07-04T03:03:04.174Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;加速鲁棒特征(Speed Up Robust Feature, SURF)和SIFT特征类似，同样是一个用于检测、描述、匹配图像局部特征点的特征描述子。SIFT是被广泛应用的特征点提取算法，但其实时性较差，如果不借助于硬件的加速和专用图形处理器(GPUs)的配合，很难达到实时的要求。对于一些实时应用场景，如基于特征点匹配的实时目标跟踪系统，每秒要处理数十帧的图像，需要在毫秒级完成特征点的搜索定位、特征向量的生成、特征向量的匹配以及目标锁定等工作，SIFT特征很难满足这种需求。SURF借鉴了SIFT中近似简化(DoG近似替代LoG)的思想，将Hessian矩阵的高斯二阶微分模板进行了简化，借助于积分图，使得模板对图像的滤波只需要进行几次简单的加减法运算，并且这种运算与滤波模板的尺寸无关。SURF相当于SIFT的加速改进版本，在特征点检测取得相似性能的条件下，提高了运算速度。整体来说，SUFR比SIFT在运算速度上要快数倍，综合性能更优。<br><a id="more"></a></p>
<h3 id="积分图像"><a href="#积分图像" class="headerlink" title="积分图像"></a>积分图像</h3><p>&emsp;&emsp;SURF算法中用到了积分图的概念，积分图(Integral Image)由Viola和Jones提出，在前面的博文<a href="https://senitco.github.io/2017/06/25/image-feature-haar/">Haar特征提取</a>中做了详细的介绍。借助积分图，图像与高斯二阶微分模板的滤波转化为对积分图像的加减运算，从而在特征点的检测时大大缩短了搜索时间。<br>&mesp;&emsp;积分图中任意一点$(i,j)$的值$ii(i,j)$，为原图像左上角到任意点$(i,j)$相应对角线区域灰度值的总和，即<br>$$ii(x,y) = \Sigma_{x’\leq x,y’\leq y} i(x’,y’)$$<br>式中，$i(x’,y’)$表示原图像中的灰度值，具体实现时$ii(x,y)$可由下式迭代计算得到<br>$$s(x,y)=s(x,y-1)+i(x,y)$$<br>$$ii(x,y)=ii(x-1,y)+s(x,y)$$<br>求取积分图时，对图像所有像素遍历一遍，得到积分图后，计算任何矩形区域内的像素灰度和只需进行三次加减运算，如下图所示。</p>
<p><img src="https://ooo.0o0.ooo/2017/07/03/5959f26a69af1.png" alt="integral image.png"></p>
<h3 id="Hessian矩阵近似"><a href="#Hessian矩阵近似" class="headerlink" title="Hessian矩阵近似"></a>Hessian矩阵近似</h3><p>&emsp;&emsp;图像点的二阶微分Hessian矩阵的行列式(Determinant of Hessian, DoH)极大值，可用于图像的斑点检测(Blob Detection)。Hessian矩阵定义如下：<br>$$H(x,y,\sigma)=\left( \begin{matrix} L_{xx}&amp; L_{xy} \\ L_{xy} &amp; L_{yy}\end{matrix} \right)$$<br>式中，$L_{xx}、L_{yy}、L_{xy}$分别是高斯二阶微分算子$\dfrac{\partial ^2 g}{\partial x^2}、\dfrac{\partial ^2 g}{\partial y^2}、\dfrac{\partial ^2 g}{\partial x \partial y}$与原图像的卷积，Hessian矩阵的行列式值DoH为<br>$$detH = L_{xx} L_{yy} - L_{xy}^2$$<br>与LoG算子一样，DoH同样反映了图像局部的纹理或结构信息，与LoG相比，DoH对图像中细长结构的斑点有较好的抑制作用。LoG和DoH在利用二阶微分算子对图像进行斑点检测时，都需要利用高斯滤波平滑图像、抑制噪声，检测过程主要分为以下两步：</p>
<ul>
<li>使用不同的$\sigma$生成$(\dfrac{\partial ^2 g}{\partial x^2} + \dfrac{\partial ^2 g}{\partial y^2})$或$\dfrac{\partial ^2 g}{\partial x^2}、\dfrac{\partial ^2 g}{\partial y^2}、\dfrac{\partial ^2 g}{\partial x \partial y}$高斯卷积模板，并对图像进行卷积运算。</li>
<li>在图像的位置空间和尺度空间搜索LoG或DoH的峰值，并进行非极大值抑制，精确定位到图像极值点。</li>
</ul>
<p>三个高斯微分算子的响应图像如下图所示：</p>
<p><img src="https://ooo.0o0.ooo/2017/07/03/5959f8e4d9702.png" alt="gaussian.png"></p>
<p>由于二阶高斯微分模板被离散化和裁剪的原因，导致了图像在旋转奇数倍的$\pi/4$即模板对角线方向时，特征点检测的重复性(Repeatability)降低，即原来是特征点的地方在旋转后可能检测不到了；而旋转$\pi/2$时，特征点检测的重复性最高。不过这一不足并不影响Hessian矩阵检测特征点。</p>
<p>&emsp;&emsp;为了将模板与图像的卷积转化为盒子滤波器(Box Filter)运算，并能够使用积分图，需要对高斯二阶微分模板进行简化，使得简化后的模板只是由几个矩形区域组成，矩形区域内填充同一值，如下图所示，在简化模板中白色区域的值为1，黑色区域的值为-1或-2(由相对面积决定)，灰色区域的值为0。</p>
<p><img src="https://ooo.0o0.ooo/2017/07/03/5959fd140cfe1.png" alt="simplify mask.png" title="高斯二阶微分模板及相应简化模板"></p>
<p>对于$\sigma=1.2$的高斯二阶微分滤波，设定模板的尺寸为$9 \times 9$的大小，并用它作为最小尺度空间值对图像进行滤波和斑点检测。使用$D_{xx}、D_{yy}、D_{xy}$表示简化模板与图像进行卷积的结果，Hessian矩阵的行列式可进一步简化为：<br>$$Det(H)=L_{xx}L_{yy}-L_{xy}^2=D_{xx} \dfrac{L_{xx}}{D_{xx}} D_{yy} \dfrac{L_{yy}}{D_{yy}} - D_{xy} \dfrac{L_{xy}}{D_{xy}} D_{xy} \dfrac{L_{xy}}{D_{xy}}$$<br>$$= D_{xx}D_{yy}(\dfrac{L_{xx}}{D_{xx}} \dfrac{L_{yy}}{D_{yy}}) - D_{xy} D_{xy} \dfrac{L_{xy}}{D_{xy}} \dfrac{L_{xy}}{D_{xy}} = (D_{xx}D_{yy} - D_{xy} D_{xy} Y)C$$<br>$$Y = (\dfrac{L_{xy}}{D_{xy}} \dfrac{L_{xy}}{D_{xy}}) (\dfrac{D_{xx}}{L_{xx}} \dfrac{D_{yy}}{L_{yy}})$$<br>$$C = \dfrac{L_{xx}}{D_{xx}} \dfrac{L_{yy}}{D_{yy}}$$<br>式中，$Y=(||L_{xy}(1.2)||_F ||D_{xx}(9)||_F)/(||L_{xx}(1.2)||_F ||D_{xy}(9))||_F)=0.912 \approx 0.9$，$||X||_F$为Frobenius范数，$1.2$是LoG的尺度$\sigma$，$9$是box filter的尺寸。理论上说，对于不同的$\sigma$值和对应的模板尺寸，$Y$值应该是不同的，但为了简化起见，可将其视为一个常数，同样$C$也为一常数，且不影响极值求取，因此，DoH可近似如下：<br>$$Det(H_{approx}) = D_{xx} D_{yy} - (0.9D_{xy})^2$$<br>在实际计算滤波响应值时，需要使用模板中盒子(矩形)区域的面积进行归一化处理，以保证一个统一的Frobenius范数能适应所有的滤波尺寸。</p>
<p>&emsp;&emsp;使用近似的Hessian矩阵行列式来表示一个图像中某一点处的斑点响应值，遍历图像中的所有像素，便形成了在某一尺度下斑点检测的响应图像。使用不同的模糊尺度和模板尺寸，便形成了多尺度斑点响应的金字塔图像，利用这一金字塔图像，可以进行斑点响应极值点的搜索定位，其过程与SIFT算法类似。</p>
<h3 id="尺度空间表示"><a href="#尺度空间表示" class="headerlink" title="尺度空间表示"></a>尺度空间表示</h3><p>&emsp;&emsp;要想检测不同尺度的极值点，必须建立图像的尺度空间金字塔。一般的方法是通过采用不同$\sigma$的高斯函数，对图像进行平滑滤波，然后重采样获得更高一层(Octave)的金字塔图像。Lowe在SIFT算法中就是通过相邻两层(Interval)高斯金字塔图像相减得到DoG图像，然后在DoG金字塔图像上进行特征点检测。与SIFT特征不同的是，SURF算法不需要通过降采样的方式得到不同尺寸大小的图像建立金字塔，而是借助于盒子滤波和积分图像，不断增大盒子滤波模板，通过积分图快速计算盒子滤波的响应图像。然后在响应图像上采用非极大值抑制，检测不同尺度的特征点。SIFT算法的LoG金字塔和SURF算法的近似DoH金字塔如下图所示：</p>
<p><img src="https://ooo.0o0.ooo/2017/07/03/595a2141bea36.jpg" alt="pyramid.jpg" title="LoG金字塔与盒状滤波金字塔"></p>
<p>&emsp;&emsp;如前所述，使用$9 \times 9$的模板对图像滤波，其结果作为最初始的尺度空间层，后续层将通过逐步增大滤波模板尺寸，以及放大后的模板与图像卷积得到。由于采用了box filter和积分图，滤波过程并不随着滤波模板尺寸的增大而增加运算量。<br>&emsp;&emsp;在建立盒状滤波金字塔时，与SIFT算法类似，需要将尺度空间划分为若干组(Octaves)。每组又由若干固定层组成，包括不同尺寸的滤波模板对同一输入图像进行滤波得到的一系列响应图。由于积分图像的离散特性，两个相邻层之间的最小尺度变化量，是由高斯二阶微分滤波模板在微分方向上对正负斑点响应长度(波瓣长度)$l_0$决定的，它是盒子滤波模板尺寸的1/3。对于$9 \times 9$的滤波模板，$l_0$为3。下一层的响应长度至少应该在$l_0$的基础上增加2个像素，以保证一边一个像素，即$l_0=5$，这样模板的尺寸为$15 \times 15$，如下图所示。依次类推，可以得到一个尺寸逐渐增大的模板序列，尺寸分别为$9 \times 9$、$15 \times 15$、$21 \times 21$、$27 \times 27$。显然，第一个模板和最后一份模板产生的Hessian响应图像只作为比较用，而不会产生最后的响应极值。这样，通过插值计算，可能的最小尺度值为$\sigma=1.2 \times \dfrac{(15+9)/2}{9}=1.6$，对应的模板尺寸为$12 \times 12$；可能的最大尺度值为$\sigma=1.2 \times \dfrac{(27+21)/2}{9}=3.2$，对应的模板尺寸为$24 \times 24$。</p>
<p><img src="https://ooo.0o0.ooo/2017/07/03/595a295515d31.jpg" alt="filter template.jpg" title="滤波模板尺寸变化"></p>
<p>&emsp;&emsp;采用类似的方法处理其他组的模板序列，其方法是将滤波器尺寸增加量按Octave的组数$m$翻倍，即$6 \times 2^{m-1} $，序列依次为$(6, 12, 24, 48, …)$，这样，在盒状滤波金字塔中，每组滤波器的尺寸如下图所示，滤波器的组数可由原始图像的尺寸决定。对数水平轴代表尺度，组之间有相互重叠，其目的是为了覆盖所有可能的尺度。在通常尺度分析情况下，随着尺度的增大，被检测的特征点数迅速衰减。</p>
<p><img src="https://ooo.0o0.ooo/2017/07/03/595a2b5a57f41.png" alt="scale-octaves.png" title="不同组滤波器尺寸"><br>滤波器的尺寸$L$、滤波响应长度$l$、组索引$o$、层索引$s$、尺度$\sigma$之间的相互关系如下：<br>$$L=3 \times (2^{o+1}(s+1)+1)$$<br>$$l=\dfrac{L}{3}=2^{o+1}(s+1)+1$$<br>$$\sigma=1.2 \times \dfrac{L}{9} = 1.2 \times \dfrac{l}{3}$$</p>
<h3 id="关键点定位"><a href="#关键点定位" class="headerlink" title="关键点定位"></a>关键点定位</h3><p>&emsp;&emsp;和LoG、DoG类似，建立尺度空间后，需要搜索定位关键点。将经过box filter处理过的响应图像中每个像素点<br>与其3维邻域中的26个像素点进行比较，若是最极大值点，则认为是该区域的局部特征点。然后，采用3维线性插值法得到亚像素级的特征点，同时去掉一些小于给定阈值的点，使得极值检测出来的特征点更稳健。和DoG不同的是，不需要剔除边缘导致的极值点，因为Hessian矩阵的行列式已经考虑了边缘的问题。</p>
<p><img src="https://ooo.0o0.ooo/2017/07/03/595a2ee656e20.png" alt="maximum detectoin.png" title="极值检测"></p>
<h3 id="特征点方向分配"><a href="#特征点方向分配" class="headerlink" title="特征点方向分配"></a>特征点方向分配</h3><p>&emsp;&emsp;为了保证特征描述子具有旋转不变性，与SIFT一样，需要对每个特征点分配一个主方向。为此，在以特征点为中心，以$6s$(s为特征点的尺度)为半径的区域内，计算图像的Haar小波响应，实际上就是对图像进行梯度运算，只不过需要利用积分图，提高梯度计算效率。求Haar小波响应的图像区域和Haar小波模板如下图所示，用于计算梯度的Haar小波的尺度是$4s$，扫描步长为$s$。</p>
<p><img src="https://ooo.0o0.ooo/2017/07/03/595a34455c031.jpg" alt="haar response.jpg" title="Haar小波响应计算"></p>
<p>使用$\sigma=2s$的高斯函数对Haar小波的响应值进行加权。为了求取主方向，设计一个以特征点为中心，张角为$\pi/3$的扇形窗口，如下图所示，以一定旋转角度$\theta$旋转窗口，并对窗口内的Haar小波响应值$dx、dy$进行累加，得到一个矢量$(m_w, \theta_w)$<br>$$m_w=\Sigma_w dx + \Sigma_w dy$$<br>$$\theta_w=arctan(\Sigma_w dy / \Sigma_w dx) $$<br>主方向为最大Haar响应累加值所对应的方向，即$\theta=\theta_w|max{m_w}$</p>
<p><img src="https://ooo.0o0.ooo/2017/07/03/595a3745a0dc7.png" alt="main direction.png" title="统计旋转窗口内的Haar小波响应和值"></p>
<p>仿照SIFT求主方向时策略，当存在大于主峰值80%以上的峰值时，则将对应方向认为是该特征点的辅方向。一个特征点可能会被指定多个方向，可以增强匹配的鲁棒性。</p>
<h3 id="特征描述子生成"><a href="#特征描述子生成" class="headerlink" title="特征描述子生成"></a>特征描述子生成</h3><p>&emsp;&emsp;生成特征点描述子时，同样需要计算图像的Haar小波响应。与确定主方向不同的是，这里不再使用圆形区域，而是在一个矩形区域计算Haar小波响应。以特征点为中心，沿主方向将$20s \times 20s$的邻域划分为$4 \times 4$个子块，每个子块利用尺寸为$2s$的Haar模板计算响应值，然后对响应值统计$\Sigma dx、\Sigma |dx|、\Sigma dy、\Sigma |dy|$形成特征向量，如下图所示：</p>
<p><img src="https://ooo.0o0.ooo/2017/07/03/595a3c15098a0.png" alt="feature descriptor.png" title="特征描述子生成"></p>
<p>将$20s$的窗口划分为$4 \times 4$个子窗口，每个子窗口大小为$5s \times 5s$，使用尺寸为$2s$的Haar小波计算子窗口的响应值；然后，以特征点为中心，用$\sigma=10s/3=3.3s$的高斯核函数对$dx、dy$进行加权计算；最后，分别对每个子块的加权响应值进行统计，得到每个子块的向量：<br>$$V_i=[\Sigma dx,\Sigma |dx|,\Sigma dy,\Sigma |dy|]$$<br>由于共有$4 \times 4$个子块，特征描述子的特征维数为$4 \times 4 \times 4 = 64$。SURF描述子不仅具有尺度和旋转不变性，还具有光照不变性，这由小波响应本身决定，而对比度不变性则是通过将特征向量归一化来实现。下图为3种简单模式图像及其对应的特征描述子，可以看出，引入Haar小波响应绝对值的统计和是必要的，否则只计算$\Sigma dx、\Sigma dy$的话，第一幅图和第二幅图的特征表现形式是一样的，因此，采用4个统计量描述子区域使特征更具有区分度。</p>
<p><img src="https://ooo.0o0.ooo/2017/07/03/595a3f7e23db4.png" alt="pattern feature.png" title="不同模式图像的描述子"></p>
<p>&emsp;&emsp;为了充分利用积分图像计算Haar小波的响应值，在具体实现中，并不是直接通过旋转Haar小波模板求其响应值，而是在积分图像上先使用水平和垂直的Haar模板求得响应值$dx、dy$，对$dx、dy$进行高斯加权处理，并根据主方向的角度，对$dx、dy$进行旋转变换，从而得到旋转后的$dx’、dy’$。</p>
<p>&emsp;&emsp;SURF在求取描述子特征向量时，是对一个子块的梯度信息进行求和，而SIFT是依靠单个像素计算梯度的方向。在有噪声的干扰下，SURF描述子具有更好的鲁棒性。一般而言，特征向量的长度越长，所承载的信息量就越大，特征描述子的独特性就越好，但匹配时所付出的时间代价也越大。对于SURF描述子，可以将其扩展到128维。具体方法就是在求Haar小波响应值的统计和时，区分$dx \geq 0$和$dx &lt; 0$的情况，以及$dy \geq 0$和$dy &lt; 0$的情况。为了实现快速匹配，SURF在特征向量中增加了一个新的元素，即特征点的拉普拉斯响应正负号。在特征点检测时，将Hessian矩阵的迹(Trace)的正负号记录下来，作为特征向量中的一个变量。在特征匹配时可以节省运算时间，因为只用具有相同正负号的特征点才可能匹配，对于不同正负号的特征点不再进行相似性计算。<br>下图是用SURF进行特征点匹配的实验结果</p>
<p><img src="https://ooo.0o0.ooo/2017/07/04/595b05c548ec2.png" alt="result.png" title="SURF特征点匹配"></p>
<h3 id="SURF与SIFT的对比"><a href="#SURF与SIFT的对比" class="headerlink" title="SURF与SIFT的对比"></a>SURF与SIFT的对比</h3><ul>
<li>尺度空间：SIFT使用DoG金字塔与图像进行卷积操作，而且对图像有做降采样处理；SURF是用近似DoH金字塔(即不同尺度的box filters)与图像做卷积，借助积分图，实际操作只涉及到数次简单的加减运算，而且不改变图像大小。</li>
<li>特征点检测：SIFT是先进行非极大值抑制，去除对比度低的点，再通过Hessian矩阵剔除边缘点。而SURF是计算Hessian矩阵的行列式值(DoH)，再进行非极大值抑制。</li>
<li>特征点主方向：SIFT在方形邻域窗口内统计梯度方向直方图，并对梯度幅值加权，取最大峰对应的方向；SURF是在圆形区域内，计算各个扇形范围内$x、y$方向的Haar小波响应值，确定响应累加和值最大的扇形方向。</li>
<li>特征描述子：SIFT将关键点附近的邻域划分为$4 \times 4$的区域，统计每个子区域的梯度方向直方图，连接成一个$4 \times 4 \times 8 = 128$维的特征向量；SURF将$20s \times 20s$的邻域划分为$4 \times 4$个子块，计算每个子块的Haar小波响应，并统计4个特征量，得到$4 \times 4 \times 4 = 64$维的特征向量。   </li>
</ul>
<p>&emsp;&emsp;总体来说，SURF和SIFT算法在特征点的检测取得了相似的性能，SURF借助积分图，将模板卷积操作近似转换为加减运算，在计算速度方面要优于SIFT特征。</p>
<h3 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h3><ul>
<li><a href="http://www.vision.ee.ethz.ch/~surf/eccv06.pdf" target="_blank" rel="external">Paper: SURF: Speeded Up Robust Features</a></li>
<li><a href="http://blog.csdn.net/songzitea/article/details/16986423" target="_blank" rel="external">http://blog.csdn.net/songzitea/article/details/16986423</a></li>
<li><a href="http://www.cnblogs.com/ronny/p/4045979.html" target="_blank" rel="external">http://www.cnblogs.com/ronny/p/4045979.html</a></li>
<li><a href="http://www.cnblogs.com/ronny/p/4048213.html" target="_blank" rel="external">http://www.cnblogs.com/ronny/p/4048213.html</a></li>
<li><a href="http://www.cnblogs.com/YiXiaoZhou/p/5903690.html" target="_blank" rel="external">http://www.cnblogs.com/YiXiaoZhou/p/5903690.html</a></li>
<li><a href="http://www.cnblogs.com/tornadomeet/archive/2012/08/17/2644903.html" target="_blank" rel="external">http://www.cnblogs.com/tornadomeet/archive/2012/08/17/2644903.html</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp;加速鲁棒特征(Speed Up Robust Feature, SURF)和SIFT特征类似，同样是一个用于检测、描述、匹配图像局部特征点的特征描述子。SIFT是被广泛应用的特征点提取算法，但其实时性较差，如果不借助于硬件的加速和专用图形处理器(GPUs)的配合，很难达到实时的要求。对于一些实时应用场景，如基于特征点匹配的实时目标跟踪系统，每秒要处理数十帧的图像，需要在毫秒级完成特征点的搜索定位、特征向量的生成、特征向量的匹配以及目标锁定等工作，SIFT特征很难满足这种需求。SURF借鉴了SIFT中近似简化(DoG近似替代LoG)的思想，将Hessian矩阵的高斯二阶微分模板进行了简化，借助于积分图，使得模板对图像的滤波只需要进行几次简单的加减法运算，并且这种运算与滤波模板的尺寸无关。SURF相当于SIFT的加速改进版本，在特征点检测取得相似性能的条件下，提高了运算速度。整体来说，SUFR比SIFT在运算速度上要快数倍，综合性能更优。&lt;br&gt;
    
    </summary>
    
      <category term="Algorithm" scheme="https://senitco.github.io/categories/Algorithm/"/>
    
    
      <category term="Image" scheme="https://senitco.github.io/tags/Image/"/>
    
  </entry>
  
  <entry>
    <title>图像特征之SIFT特征匹配</title>
    <link href="https://senitco.github.io/2017/06/30/image-feature-sift/"/>
    <id>https://senitco.github.io/2017/06/30/image-feature-sift/</id>
    <published>2017-06-30T07:01:18.380Z</published>
    <updated>2017-07-01T10:34:43.999Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;尺度不变特征变换(Scale-invariant feature transform, SIFT)是计算机视觉中一种检测、描述和匹配图像局部特征点的方法，通过在不同的尺度空间中检测极值点或特征点(Conrner Point, Interest Point)，提取出其位置、尺度和旋转不变量，并生成特征描述子，最后用于图像的特征点匹配。SIFT特征凭借其良好的性能广泛应用于运动跟踪(Motion tracking)、图像拼接(Automatic mosaicing)、3D重建(3D reconstruction)、移动机器人导航(Mobile robot navigation)以及目标识别(Object Recognition)等领域。<br><a id="more"></a></p>
<h3 id="尺度空间极值检测"><a href="#尺度空间极值检测" class="headerlink" title="尺度空间极值检测"></a>尺度空间极值检测</h3><p>&emsp;&emsp;Harris特征进行角点检测时，不具备尺度不变性。为了能够在不同的尺度检测到尽可能完整的特征点或关键点，需要借助尺度空间理论来描述图像的多尺度特征。相关研究证明高斯卷积核是实现尺度变换的唯一线性核。因此可用图像的高斯金字塔表示尺度空间，而且尺度规范化的LoG算子具有尺度不变性，在具体实现中，可用高斯差分(DoG)算子近似LoG算子，在构建的尺度空间中检测稳定的特征点。</p>
<h4 id="构建尺度空间"><a href="#构建尺度空间" class="headerlink" title="构建尺度空间"></a>构建尺度空间</h4><p>&emsp;&emsp;尺度空间理论的基本思想是：在图像处理模型中引入一个被视为尺度的参数，通过连续变化尺度参数获取多尺度下的空间表示序列，对这些空间序列提取某些特征描述子，抽象成特征向量，实现图像在不同尺度或不同分辨率的特征提取。尺度空间中各尺度图像的模糊程度逐渐变大，模拟人在由近到远时目标在人眼视网膜上的成像过程。而且尺度空间需满足一定的不变性，包括图像灰度不变性、对比度不变性、平移不变性、尺度不变性以及旋转不变性等。在某些情况下甚至要求尺度空间算子具备仿射不变性。<br>&emsp;&emsp;一幅图像的尺度空间可定义为对原图像进行可变尺度的高斯卷积：<br>$$L(x,y,\sigma)=G(x,y,\sigma) \ast I(x,y)$$<br>$$G(x,y,\sigma)=\dfrac{1}{2 \pi \sigma^2} e^{-\dfrac{x^2+y^2}{2\sigma^2}}$$<br>式中，$G(x,y,\sigma)$是尺度可变的高斯函数，$(x,y)$是图像的空间坐标，$\sigma$是尺度坐标(尺度变化因子)，$\sigma$大小决定图像的平滑程度，值越大图像模糊得越严重。大尺度对应图像的概貌特征，小尺度对应图像的细节特征。一般根据$3\sigma$原则，高斯核矩阵的大小设为$(6\sigma+1) \times (6\sigma+1)$。<br>&emsp;&emsp;在使用高斯金字塔构建尺度空间时，主要分成两部分，对图像做降采样，以及对图像做不同尺度的高斯模糊。对图像做降采样得到不同尺度的图像，也就是不同的组(Octave)，后面的Octave(高一层的金字塔)为上一个Octave(低一层的金字塔)降采样得到，图像宽高分别为上一个Octave的1/2。每组(Octave)又分为若干层(Interval)，通过对图像做不同尺度的高斯模糊得到。为了有效地在尺度空间检测稳定的关键点，提出了高斯差分尺度空间(DoG Scale-Space)，利用不同尺度的高斯差分核与图像卷积生成。<br>$$D(x,y,\sigma)=(G(x,y,k\sigma)-G(x,y,\sigma)) \ast I(x,y) = L(x,y,k\sigma)-L(x,y,\sigma)$$<br>图像的高斯金字塔和高斯差分金字塔如下图所示，高斯差分图像由高斯金字塔中同一组(Octave)内相邻层(Interval)的图像作差得到。</p>
<p><img src="https://ooo.0o0.ooo/2017/06/30/5956098d36da8.jpg" alt="Gaussian Pyramid.jpg" title="图像高斯金字塔"></p>
<h4 id="尺度空间的参数确定"><a href="#尺度空间的参数确定" class="headerlink" title="尺度空间的参数确定"></a>尺度空间的参数确定</h4><p>&emsp;&emsp;在由图像金字塔表示的尺度空间中，图像的组数(Octave)由原始图像的大小和塔顶图像的大小决定。<br>$$Octave = log_2(min(width_0, height_0)) - log_2(min(width, height)) $$<br>式中，$width_0、height_0$分别为原始图像的宽高，$width、height$为塔顶图像的宽高。对于一幅大小为$512 \times 512$的图像，当塔顶图像大小为$4 \times 4$时，图像的组数为$Octave = 7$。<br>尺度参数$\sigma$的取值与金字塔的组数和层数相关，设第一组第一层的尺度参数取值为$\sigma(1,1)=\sigma_0$，则第$m$组第$n$层的$\sigma$取值为<br>$$\sigma(m,n)=\sigma_0 \cdot 2^{m-1} \cdot k^{n-1}, &emsp;k=2^{\dfrac{1}{S}}$$<br>式中，$S$为金字塔中每组的有效层数。为了得到更多的特征点，将图像扩大为原来的两倍，原始图像的尺度参数为$\sigma=0.5$，扩大两倍后的尺度为$\sigma=1.6$。在检测极值点前对原始图像的高斯平滑会导致图像高频信息的丢失，所以在建立尺度空间前先将图像扩大为原来的两倍，以保留原始图像信息，增加特征点数量。</p>
<h4 id="DoG算子检测极值点"><a href="#DoG算子检测极值点" class="headerlink" title="DoG算子检测极值点"></a>DoG算子检测极值点</h4><p>&emsp;&emsp;为了寻找DoG尺度空间的极值点，每一个采样点要和其所有邻域像素相比较，如下图所示，中间检测点与其同尺度的$8$个邻域像素点以及上下相邻两层对应的$9 \times 2$个像素点一共$26$个点作比较，以确保在图像空间和尺度空间都能检测到极值点。一个像素点如果在DoG尺度空间本层及上下两层的26邻域中取得最大或最小值时，就可以认为该点是图像在该尺度下的一个特征点。</p>
<p><img src="https://ooo.0o0.ooo/2017/06/30/59562da5c15d9.png" alt="extremum.png" title="DoG尺度空间极值检测"></p>
<p>&emsp;&emsp;在极值比较的过程中，每一组差分图像的首末两层是无法比较的，为了在每组中检测$S$个尺度的极值点，则DoG金字塔每组须有$S+2$层图像，高斯金字塔每组须有$S+3$层图像。另外，在降采样时，高斯金字塔中一组(Octive)的底层图像是由前一组图像的倒数第3张图像(S+1层)隔点采样得到。这样也保证了尺度变化的连续性，如下图所示：</p>
<p><img src="https://ooo.0o0.ooo/2017/06/30/59562da5c399e.png" alt="parameter.png" title="尺度参数的变化"></p>
<p>假设每组的层数$S=3$，则$k=2^{1/S}=s^{1/3}$，在高斯金字塔中，第一个Octave中第$S+1$层图像尺度为$k^3\sigma=2\sigma$，经降采样后得到第二个Octave的第$1$层图像，尺度仍为$2\sigma$。在DoG尺度空间中，第一组(1st-Octave)图像中间三项的尺度分别为$(k\sigma, k^2\sigma, k^3\sigma)$，下一组中间三项为$(2k\sigma, 2k^2\sigma, 2k^3\sigma)$，其“首项”$2k\sigma=2^{4/3}\sigma$，与上一组“末项”$k^3\sigma=2^{3/3}\sigma$尺度变化连续，变化尺度为$k=2^{1/S}=2^{1/3}$。</p>
<h3 id="关键点定位"><a href="#关键点定位" class="headerlink" title="关键点定位"></a>关键点定位</h3><p>&emsp;&emsp;在DoG尺度空间检测到的极值点是离散的，通过拟合三元二次函数可以精确定位关键点的位置和尺度，达到亚像素精度。同时去除低对比度的检测点和不稳定的边缘点，以增强匹配稳定性，提高抗噪声能力。</p>
<h4 id="关键点精确定位"><a href="#关键点精确定位" class="headerlink" title="关键点精确定位"></a>关键点精确定位</h4><p>&emsp;&emsp;DoG函数$D(X)=D(x,y,\sigma)$在尺度空间的的Taylor展开式为<br>$$D(X)=D+\dfrac{\partial D^T}{\partial X} X + \dfrac{1}{2} X^T \dfrac{\partial^2 D}{\partial X^2}X$$<br>令$D(X)$导数为0，得到极值点的偏移量<br>$$\hat {X} = -(\dfrac{\partial^2 D}{\partial X^2})^{-1} \dfrac{\partial D}{\partial X}$$<br>若$\hat {X}=(x,y,\sigma)^T$在任意一个维度大于$0.5$，说明极值点精确位置距离另一个点更近，应该改变当前关键点的位置，定位到新点后执行相同操作，若迭代5次仍不收敛，则认为该检测点不为关键点。精确关键点处函数值为<br>$$D(\hat {X})=D+\dfrac{1}{2} \dfrac{\partial D^T}{\partial X} \hat {X}$$<br>$|D(\hat {X})|$过小易受噪声点的干扰而变得不稳定，若其小于某个阈值(例如$0.03$或者$0.04/S$)，则将该极值点删除。</p>
<h4 id="消除边缘效应"><a href="#消除边缘效应" class="headerlink" title="消除边缘效应"></a>消除边缘效应</h4><p>&emsp;&emsp;高斯差分函数DoG有较强的边缘响应，需要剔除不稳定的边缘响应点。边缘点的特征表现在某个方向有较大的主曲率，而在与其垂直方向主曲率较小。主曲率可通过一个$2 \times 2$的$Hessian$矩阵求出。<br>$$H=\left( \begin{matrix} D_{xx}&amp; D_{xy} \\ D_{xy} &amp; D_{yy}\end{matrix} \right)$$<br>$D$的主曲率和$H$的特征值成正比，令$\alpha$为较大特征值，$\beta$为较小特征值，且$\alpha / \beta = r$，则<br>$$Tr(H)=D_{xx}+D_{yy}=\alpha + \beta, &emsp;Det(H)=D_{xx}D_{yy}-D_{xy}^2=\alpha \beta$$<br>$$\dfrac{Tr(H)^2}{Det(H)}=\dfrac{(\alpha + \beta)^2}{\alpha \beta} = \dfrac{(r+1)^2}{r}$$<br>$(r+1)^2/r$在两个特征值相等时最小，随着$r$的增大而增大，$r$值越大，说明两个特征值的比值越大，正好对应边缘的情况。因此，设定一个阈值$r_t$，若满足<br>$$\dfrac{Tr(H)^2}{Det(H)} &lt; \dfrac{(r_t+1)^2}{r_t}$$<br>则认为该关键点不是边缘，否则予以剔除。</p>
<h3 id="关键点方向分配"><a href="#关键点方向分配" class="headerlink" title="关键点方向分配"></a>关键点方向分配</h3><p>&emsp;&emsp;为了使特征描述子具有旋转不变性，需要利用关键点邻域像素的梯度方向分布特性为每个关键点指定方向参数。对于在DoG金字塔中检测出的关键点，在其邻近高斯金字塔图像的$3\sigma$邻域窗口内计算其梯度幅值和方向，公式如下：<br>$$m(x,y)=\sqrt{[L(x+1,y)-L(x-1,y)]^2 + [L(x,y+1)-L(x,y-1)]^2}$$<br>$$\theta(x,y)=tan^{-1}{[L(x,y+1)-L(x,y-1)] / [L(x+1,y)-L(x-1,y)]}$$<br>式中，$L$为关键点所在尺度空间的灰度值，$m(x,y)$为梯度幅值，$\theta(x,y)$为梯度方向。对模值$m(x,y)$按$\sigma=1.5\sigma_{oct}$、邻域窗口为$3\sigma=3 \times 1.5\sigma_{oct}$的高斯分布加权。在完成关键点的梯度计算后，使用直方图统计邻域内像素的梯度和方向，梯度直方图将梯度方向$(0, 360^{\circ })$分为36柱(bins)，如下图所示，直方图的峰值所在的方向代表了该关键点的主方向。</p>
<p><img src="https://ooo.0o0.ooo/2017/06/30/59564f338a59c.png" alt="main direction.png" title="梯度方向直方图"></p>
<p>梯度方向直方图的峰值代表了该特征点处邻域梯度的主方向，为了增强鲁棒性，保留峰值大于主方向峰值80%的方向作为该关键点的辅方向，因此，在相同位置和尺度，将会有多个关键点被创建但方向不同，可以提高特征点匹配的稳定性。</p>
<h3 id="关键点特征描述"><a href="#关键点特征描述" class="headerlink" title="关键点特征描述"></a>关键点特征描述</h3><p>&emsp;&emsp;在经过上述流程后，检测到的每个关键点有三个信息：位置、尺度以及方向，接下来要做的就是抽象出一组特征向量描述每个关键点。这个特征描述子不但包括关键点，还包括其邻域像素的贡献，而且需具备较高的独特性和稳定性，以提高特征点匹配的准确率。SIFT特征描述子是关键点邻域梯度经过高斯加权后统计结果的一种表示。通过对关键点周围图像区域分块，计算块内的梯度直方图，得到表示局部特征点信息的特征向量。例如在尺度空间$4 \times 4$的窗口内统计8个方向的梯度直方图，生成一个$4 \times 4 \times 8 = 128$维的表示向量。</p>
<h4 id="确定特征描述子采样区域"><a href="#确定特征描述子采样区域" class="headerlink" title="确定特征描述子采样区域"></a>确定特征描述子采样区域</h4><p>&emsp;&emsp;特征描述子与特征点所在的尺度空间有关，因此对梯度的求取应该在特征点对应的高斯图像上进行。将关键点附近的邻域划分为$d \times d(d=4)$个子区域，每个子区域的大小与关键点方向分配时相同，即边长为$3\sigma_{oct}$，考虑到实际计算时需要进行三线性插值，邻域窗口边长设为$3\sigma_{oct}(d+1)$，又考虑到旋转因素(坐标轴旋转至关键点主方向)，最后所需的图像区域半径为<br>$$radius=\dfrac{3\sigma_{oct} \times \sqrt{2} \times (d+1)}{2}$$<br><img src="https://ooo.0o0.ooo/2017/06/30/595656c99be22.jpg" alt="radius.jpg"></p>
<h4 id="旋转坐标轴至关键点主方向"><a href="#旋转坐标轴至关键点主方向" class="headerlink" title="旋转坐标轴至关键点主方向"></a>旋转坐标轴至关键点主方向</h4><p>&emsp;&emsp;将坐标轴旋转至关键点主方向，以确保旋转不变性。旋转后采样点的新坐标为<br>$$\left[ \begin{matrix} x’\\ y’\end{matrix} \right] = \left( \begin{matrix} cos\theta &amp; -sin\theta \\ sin\theta &amp; cos\theta \end{matrix} \right) \left[ \begin{matrix} x\\ y \end{matrix} \right], &emsp;x,y \in [-radius, radius]$$</p>
<p><img src="https://ooo.0o0.ooo/2017/06/30/595656c9f07bc.png" alt="rotation.png"></p>
<h4 id="三线性插值计算权值"><a href="#三线性插值计算权值" class="headerlink" title="三线性插值计算权值"></a>三线性插值计算权值</h4><p>&emsp;&emsp;在图像半径区域内对每个像素点求其梯度幅值和方向，并对每个梯度幅值乘以高斯权重参数<br>$$w=m(a+x,b+y) \times e^{-\dfrac{(x’)^2+(y’)^2}{2\sigma_w^2}}$$<br>式中，$x’、y’$分别表示像素点与关键点的行、列距离，$m(x,y)$表示像素梯度幅值，高斯尺度因子为$\sigma_w=3\sigma \times 0.5d$。<br>将旋转后的采样点坐标分配到对应的子区域，计算影响子区域的采样点的梯度和方向，分配到8个方向上。旋转后的采样点$(x’,y’)$落在子区域的下标为<br>$$\left[ \begin{matrix} u\\ v\end{matrix} \right] = \dfrac{1}{3\sigma_{oct}} \left[ \begin{matrix} x’\\ y’\end{matrix} \right] + \dfrac{d}{2}, &emsp;u,v \in [0,d]$$<br>将采样点在子区域的下标进行三线性插值，根据三维坐标计算与周围子区域的距离，按距离远近计算权重，最终累加在相应子区域的相关方向上的权值为<br>$$weight = w \cdot dr^i \cdot (1-dr)^{1-i} \cdot dc^j \cdot (1-dc)^{1-j} \cdot do^k \cdot (1-do)^{1-k}$$<br>式中$i、j、k$取0或者1.</p>
<p><img src="https://ooo.0o0.ooo/2017/06/30/59565c422740a.jpg" alt="grad hist.jpg" title="梯度方向统计直方图"></p>
<h4 id="向量归一化生成描述子"><a href="#向量归一化生成描述子" class="headerlink" title="向量归一化生成描述子"></a>向量归一化生成描述子</h4><p>&emsp;&emsp;得到128维特征向量后，为了去除光照变化的影响，需要对向量进行归一化处理。非线性光照变化仍可能导致梯度幅值的较大变化，但对梯度方向影响较小。因此对于超过阈值0.2的梯度幅值设为0.2，然后再进行一次归一化。最后将特征向量按照对应高斯金字塔的尺度大小排序。至此，SIFT特征描述子形成。</p>
<h3 id="SIFT特征匹配"><a href="#SIFT特征匹配" class="headerlink" title="SIFT特征匹配"></a>SIFT特征匹配</h3><p>&emsp;&emsp;对两幅图像中检测到的特征点，可采用特征向量的欧式距离作为特征点相似性的度量，取图像1中某个关键点，并在图像2中找到与其距离最近的两个关键点，若最近距离与次近距离的比值小于某个阈值，则认为距离最近的这一对关键点为匹配点。降低比例阈值，SIFT匹配点数量会减少，但相对而言会更加稳定。阈值ratio的取值范围一般为0.4~0.6。</p>
<h3 id="SIFT特征的特点"><a href="#SIFT特征的特点" class="headerlink" title="SIFT特征的特点"></a>SIFT特征的特点</h3><p>&emsp;&emsp;SIFT是一种检测、描述、匹配图像局部特征点的算法，通过在尺度空间中检测极值点，提取位置、尺度、旋转不变量，并抽象成特征向量加以描述，最后用于图像特征点的匹配。SIFT特征对灰度、对比度变换、旋转、尺度缩放等保持不变性，对视角变化、仿射变化、噪声也具有一定的鲁棒性。但其实时性不高，对边缘光滑的目标无法准确提取特征点。</p>
<h3 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h3><ul>
<li><a href="http://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf" target="_blank" rel="external">Paper: Distinctive Image Features from Scale-Invariant Keypoints</a></li>
<li><a href="http://cgit.nutn.edu.tw:8080/cgit/PaperDL/iccv99.pdf" target="_blank" rel="external">Paper: Object Recognition from Local Scale-Invariant Features</a></li>
<li><a href="https://people.cs.umass.edu/~elm/Teaching/ppt/SIFT.pdf" target="_blank" rel="external">PPT: Object Recognition from Local Scale-Invariant Features (SIFT)</a></li>
<li><a href="https://github.com/robwhess/opensift" target="_blank" rel="external">Code: RobHess OpenSIFT</a></li>
<li><a href="http://blog.csdn.net/abcjennifer/article/details/7639681" target="_blank" rel="external">http://blog.csdn.net/abcjennifer/article/details/7639681</a></li>
<li><a href="http://blog.csdn.net/zddblog/article/details/7521424" target="_blank" rel="external">http://blog.csdn.net/zddblog/article/details/7521424</a></li>
<li><a href="http://www.sun11.me/blog/2016/sift-implementation-in-matlab/" target="_blank" rel="external">http://www.sun11.me/blog/2016/sift-implementation-in-matlab/</a></li>
<li><a href="http://masikkk.com/article/RobHess-SIFT-Source-Code-Analysis-Overview/" target="_blank" rel="external">http://masikkk.com/article/RobHess-SIFT-Source-Code-Analysis-Overview/</a></li>
<li><a href="http://masikkk.com/article/RANSAC-SIFT-Image-Match/" target="_blank" rel="external">http://masikkk.com/article/RANSAC-SIFT-Image-Match/</a></li>
<li><a href="http://www.cnblogs.com/letben/p/5510976.html" target="_blank" rel="external">http://www.cnblogs.com/letben/p/5510976.html</a></li>
<li><a href="http://blog.csdn.net/fzthao/article/details/62424271" target="_blank" rel="external">http://blog.csdn.net/fzthao/article/details/62424271</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp;尺度不变特征变换(Scale-invariant feature transform, SIFT)是计算机视觉中一种检测、描述和匹配图像局部特征点的方法，通过在不同的尺度空间中检测极值点或特征点(Conrner Point, Interest Point)，提取出其位置、尺度和旋转不变量，并生成特征描述子，最后用于图像的特征点匹配。SIFT特征凭借其良好的性能广泛应用于运动跟踪(Motion tracking)、图像拼接(Automatic mosaicing)、3D重建(3D reconstruction)、移动机器人导航(Mobile robot navigation)以及目标识别(Object Recognition)等领域。&lt;br&gt;
    
    </summary>
    
      <category term="Algorithm" scheme="https://senitco.github.io/categories/Algorithm/"/>
    
    
      <category term="Image" scheme="https://senitco.github.io/tags/Image/"/>
    
  </entry>
  
  <entry>
    <title>图像特征之LoG算子与DoG算子</title>
    <link href="https://senitco.github.io/2017/06/29/image-feature-LoG-DoG/"/>
    <id>https://senitco.github.io/2017/06/29/image-feature-LoG-DoG/</id>
    <published>2017-06-29T06:41:56.463Z</published>
    <updated>2017-06-29T11:11:04.965Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;LoG(Laplacian of Gaussian)算子和DoG(Difference of Gaussian)算子是图像处理中实现极值点检测(Blob Detection)的两种方法。通过利用高斯函数卷积操作进行尺度变换，可以在不同的尺度空间检测到关键点(Key Point)或兴趣点(Interest Point)，实现尺度不变性(Scale invariance)的特征点检测。<br><a id="more"></a></p>
<h3 id="Laplacian-of-Gaussian-LoG"><a href="#Laplacian-of-Gaussian-LoG" class="headerlink" title="Laplacian of Gaussian(LoG)"></a>Laplacian of Gaussian(LoG)</h3><p>&emsp;&emsp;Laplace算子通过对图像求取二阶导数的零交叉点(zero-cross)来进行边缘检测，其计算公式如下：<br>$$\nabla ^2 f(x,y)=\dfrac{\partial^2 f}{\partial x^2} + \dfrac{\partial^2 f}{\partial y^2}$$<br>由于微分运算对噪声比较敏感，可以先对图像进行高斯平滑滤波，再使用Laplace算子进行边缘检测，以降低噪声的影响。由此便形成了用于极值点检测的LoG算子。常用的二维高斯函数如下：<br>$$G_\sigma(x,y)=\dfrac{1}{\sqrt {2\pi \sigma ^{2}}} exp(-\dfrac{x^2+y^2}{2\sigma ^2})$$<br>原图像与高斯核函数卷积后再做laplace运算<br>$$\Delta [G_\sigma(x,y) \ast f(x,y)]=[\Delta G_\sigma(x,y)] \ast f(x,y)$$<br>$$LoG = \Delta G_\sigma(x,y)=\dfrac{\partial^2 G_\sigma(x,y)}{\partial x^2} + \dfrac{\partial^2 G_\sigma(x,y)}{\partial y^2}=\dfrac{x^2+y^2-2\sigma^2}{\sigma^4}e^{-(x^2+y^2)/2\sigma^2}$$<br>所以先对高斯核函数求取二阶导数，再与原图像进行卷积操作。由于高斯函数是圆对称的，因此LoG算子可以有效地实现极值点或局部极值区域的检测。</p>
<h3 id="Difference-of-Gaussian-DoG"><a href="#Difference-of-Gaussian-DoG" class="headerlink" title="Difference of Gaussian(DoG)"></a>Difference of Gaussian(DoG)</h3><p>&emsp;&emsp;DoG算子是高斯函数的差分，具体到图像中，就是将图像在不同参数下的高斯滤波结果相减，得到差分图。DoG算子的表达式如下：<br>$$DoG = G_{\sigma_1} - G_{\sigma_2}=\dfrac{1}{\sqrt{2\pi}} [\dfrac{1}{\sigma_1} e^{-(x^2+y^2)/2\sigma_1^2} - \dfrac{1}{\sigma_2} e^{-(x^2+y^2)/2\sigma_2^2}]$$<br>如果将高斯核函数的形式表示为<br>$$G_\sigma(x,y)=\dfrac{1}{2\pi \sigma ^{2}} exp(-\dfrac{x^2+y^2}{2\sigma ^2})$$<br>则存在以下等式<br>$$\dfrac{\partial G}{\partial \sigma} = \sigma \nabla ^2 G$$<br>$$\dfrac{\partial G}{\partial \sigma} \approx \dfrac{G(x,y,k\sigma)-G(x,y,\sigma)}{k\sigma-\sigma}$$<br>因此有<br>$$G(x,y,k\sigma)-G(x,y,\sigma) \approx (k-1)\sigma^2 \nabla ^2 G$$<br>其中$k-1$是个常数，不影响极值点的检测，LoG算子和DoG算子的函数波形对比如下图所示，由于高斯差分的计算更加简单，因此可用DoG算子近似替代LoG算子</p>
<p><img src="https://ooo.0o0.ooo/2017/06/29/5954c1640caeb.jpg" alt="LoG-DoG.jpg" title="LoG与DoG的对比"></p>
<h3 id="边缘检测-Edge-Detection-和极值点检测-Blob-Detection"><a href="#边缘检测-Edge-Detection-和极值点检测-Blob-Detection" class="headerlink" title="边缘检测(Edge Detection)和极值点检测(Blob Detection)"></a>边缘检测(Edge Detection)和极值点检测(Blob Detection)</h3><p>&emsp;&emsp;LoG算子和DoG算子既可以用于检测图像边缘，也可用于检测局部极值点或极值区域，图像边缘在LoG算子下的响应情况如下图所示，二阶微分算子在边缘处为一过零点，而且过零点两边的最大值(正)和最小值(负)的差值较大。</p>
<p><img src="https://ooo.0o0.ooo/2017/06/29/5954d7a6ca776.jpg" alt="edge.jpg" title="LoG算子检测边缘响应"></p>
<p>接下来观察下图，由边缘过渡到极值点，LoG算子的响应变化</p>
<p><img src="https://ooo.0o0.ooo/2017/06/29/5954d7a6cb78d.jpg" alt="edge to blob.jpg" title="边缘到极值点的LoG响应变化"></p>
<p>LoG算子在极值点(Blob)处的响应如下图所示：</p>
<p><img src="https://ooo.0o0.ooo/2017/06/29/5954d7a6c963e.jpg" alt="blob.jpg"></p>
<p>通过定义不同尺寸的高斯核函数，可以实现在不同尺度检测Blob，如下图所示</p>
<p><img src="https://ooo.0o0.ooo/2017/06/29/5954d7a6c08d4.jpg" alt="scale blob.jpg"></p>
<h3 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h3><ul>
<li>对原图像进行LoG或者DoG卷积操作</li>
<li>检测卷积后图像中的过零点(边缘)或者极值点(Blob)</li>
<li>如果是检测边缘，则对过零点进行阈值化(过零点两边的最大值和最小值之间的差值要大于某个阈值)；如果是检测极值点，则极值点的LoG或DoG响应值应该大于某个阈值。</li>
</ul>
<h3 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h3><ul>
<li><a href="http://fourier.eng.hmc.edu/e161/lectures/gradient/node8.html" target="_blank" rel="external">http://fourier.eng.hmc.edu/e161/lectures/gradient/node8.html</a></li>
<li><a href="http://fourier.eng.hmc.edu/e161/lectures/gradient/node9.html" target="_blank" rel="external">http://fourier.eng.hmc.edu/e161/lectures/gradient/node9.html</a></li>
<li><a href="http://blog.csdn.net/songzitea/article/details/12851079" target="_blank" rel="external">http://blog.csdn.net/songzitea/article/details/12851079</a></li>
<li><a href="http://blog.csdn.net/kezunhai/article/details/11579785" target="_blank" rel="external">http://blog.csdn.net/kezunhai/article/details/11579785</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp;LoG(Laplacian of Gaussian)算子和DoG(Difference of Gaussian)算子是图像处理中实现极值点检测(Blob Detection)的两种方法。通过利用高斯函数卷积操作进行尺度变换，可以在不同的尺度空间检测到关键点(Key Point)或兴趣点(Interest Point)，实现尺度不变性(Scale invariance)的特征点检测。&lt;br&gt;
    
    </summary>
    
      <category term="Algorithm" scheme="https://senitco.github.io/categories/Algorithm/"/>
    
    
      <category term="Image" scheme="https://senitco.github.io/tags/Image/"/>
    
  </entry>
  
  <entry>
    <title>图像特征之Harris角点检测</title>
    <link href="https://senitco.github.io/2017/06/28/image-feature-harris/"/>
    <id>https://senitco.github.io/2017/06/28/image-feature-harris/</id>
    <published>2017-06-28T11:12:03.114Z</published>
    <updated>2017-06-29T04:16:32.578Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;角点检测(Corner Detection)也称为特征点检测，是图像处理和计算机视觉中用来获取图像局部特征点的一类方法，广泛应用于运动检测、图像匹配、视频跟踪、三维建模以及目标识别等领域中。<br><a id="more"></a></p>
<!-- mathjax config similar to math.stackexchange -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
        inlineMath: [ ['$', '$'] ],
        displayMath: [ ['$$', '$$']],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    messageStyle: "none",
    "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<h3 id="局部特征"><a href="#局部特征" class="headerlink" title="局部特征"></a>局部特征</h3><p>&emsp;&emsp;不同于HOG、LBP、Haar等基于区域(Region)的图像局部特征，Harris是基于角点的特征描述子，属于feature detector，主要用于图像特征点的匹配(match)，在SIFT算法中就有用到此类角点特征；而HOG、LBP、Haar等则是通过提取图像的局部纹理特征(feature extraction)，用于目标的检测和识别等领域。无论是HOG、Haar特征还是Harris角点都属于图像的局部特征，满足局部特征的一些特性。主要有以下几点：</p>
<ul>
<li>可重复性(Repeatability)：同一个特征可以出现在不同的图像中，这些图像可以在不同的几何或光学环境下成像。也就是说，同一物体在不同的环境下成像(不同时间、不同角度、不同相机等)，能够检测到同样的特征。</li>
<li>独特性(Saliency)：特征在某一特定目标上表现为独特性，能够与场景中其他物体相区分，能够达到后续匹配或识别的目的。</li>
<li>局部性(Locality)；特征能够刻画图像的局部特性，而且对环境影响因子(光照、噪声等)鲁棒。</li>
<li>紧致性和有效性(Compactness and efficiency)；特征能够有效地表达图像信息，而且在实际应用中运算要尽可能地快。  </li>
</ul>
<p>相比于考虑局部邻域范围的局部特征，全局特征则是从整个图像中抽取特征，较多地运用在图像检索领域，例如图像的颜色直方图。<br>除了以上几点通用的特性外，对于一些图像匹配、检测识别等任务，可能还需进一步考虑图像的局部不变特征。例如尺度不变性(Scale invariance)和旋转不变性(Rotation invariance)，当图像中的物体或目标发生旋转或者尺度发生变换，依然可以有效地检测或识别。此外，也会考虑局部特征对光照、阴影的不变性。</p>
<h3 id="Harris角点检测"><a href="#Harris角点检测" class="headerlink" title="Harris角点检测"></a>Harris角点检测</h3><p>&emsp;&emsp;特征点在图像中一般有具体的坐标，并具有某些数学特征，如局部最大或最小灰度、以及某些梯度特征等。角点可以简单的认为是两条边的交点，比较严格的定义则是在邻域内具有两个主方向的特征点，也就是说在两个方向上灰度变化剧烈。如下图所示，在各个方向上移动小窗口，如果在所有方向上移动，窗口内灰度都发生变化，则认为是角点；如果任何方向都不变化，则是均匀区域；如果灰度只在一个方向上变化，则可能是图像边缘。</p>
<p><img src="https://ooo.0o0.ooo/2017/06/28/5953a445031a0.jpg" alt="corner.jpg"></p>
<p>&emsp;&emsp;对于给定图像$I(x,y)$和固定尺寸的邻域窗口，计算窗口平移前后各个像素差值的平方和，也就是自相关函数<br>$$E(u,v)=\Sigma_x\Sigma_yw(x,y)[I(x+u,y+v)-I(x,y)]^2$$<br>其中，窗口加权函数$w(x,y)$可取均值函数或者高斯函数，如下图所示：</p>
<p><img src="https://ooo.0o0.ooo/2017/06/28/5953a7fa5a172.jpg" alt="weights.jpg" title="窗口加权函数"></p>
<p>根据泰勒展开，可得到窗口平移后图像的一阶近似<br>$$I(x+u,y+v)\approx I(x,y)+I_x(x,y)u+I_y(x,y)v$$<br>因此$E(u, v)$可化为<br>$$E(u,v) \approx \Sigma_{x,y}w(x,y)[I_x(x,y)u+I_y(x,y)v]^2=\left[u,v\right] M(x,y) \left[ \begin{matrix} u\\ v\end{matrix} \right]$$<br>$$M(x,y)=\Sigma_w \left[ \begin{matrix} I_x^2&amp; I_xI_y \\ I_xI_y &amp; I_y^2\end{matrix} \right] = \left[ \begin{matrix} A&amp; C\\ C&amp; B\end{matrix} \right]$$<br>$E(u,v)$可表示为一个二次项函数<br>$$E(u,v)=Au^2+2Cuv+Bv^2$$<br>其中$A=\Sigma_w I_x^2, B = \Sigma_w I_y^2, C=\Sigma_w I_x I_y$<br>二次项函数本质上是一个椭圆函数，椭圆的曲率和尺寸可由$M(x,y)$的特征值$\lambda_1,\lambda_2$决定，椭圆方向由$M(x,y)$的特征向量决定，椭圆方程和其图形分别如下所示：<br>$$\left[u,v\right] M(x,y) \left[ \begin{matrix} u\\ v\end{matrix} \right] = 1$$</p>
<p><img src="https://ooo.0o0.ooo/2017/06/28/5953af7c8c289.png" alt="tuoyuan.png"></p>
<p>考虑角点的边界和坐标轴对齐的情况，如下图所示，在平移窗口内，只有上侧和左侧边缘，上边缘$I_y$很大而$I_x$很小，左边缘$I_x$很大而$I_y$很小，所以矩阵$M$可化简为<br>$$M=\left[ \begin{matrix} \lambda_1&amp; 0\\ 0&amp; \lambda_2\end{matrix} \right]$$</p>
<p><img src="https://ooo.0o0.ooo/2017/06/28/5953b0d8c854c.jpg" alt="axis-aligned.jpg"></p>
<p>当角点边界和坐标轴没有对齐时，可对角点进行旋转变换，将其变换到与坐标轴对齐，这种旋转操作可用矩阵的相似对角化来表示，即<br>$$M=X\Sigma X^T = X \left[ \begin{matrix} \lambda_1&amp; 0\\ 0&amp; \lambda_2\end{matrix} \right] X^T$$<br>$$Mx_i=\lambda_i x_i$$</p>
<p><img src="https://ooo.0o0.ooo/2017/06/28/5953b0d8e3d2d.jpg" alt="not-aligned.jpg"></p>
<p>&emsp;&emsp;对于矩阵$M$，可以将其和协方差矩阵类比，协方差表示多维随机变量之间的相关性，协方差矩阵对角线的元素表示的是各个维度的方差，而非对角线上的元素表示的是各个维度之间的相关性，在PCA(主成分分析)中，将协方差矩阵对角化，使不同维度的相关性尽可能的小，并取特征值较大的维度，来达到降维的目的。类似的，可以将矩阵$M$看成是一个二维随机分布的协方差矩阵，通过将其对角化，求取矩阵的两个特征值，并根据这两个特征值来判断角点。</p>
<p>如下图所示，可根据矩阵$M$的特征值来判断是否为角点，当两个特征值都较大时为角点(corne)，一个特征值较大而另一个较小时则为图像边缘(edge)，两个特征值都较小时为均匀区域(flat)。<br><img src="https://ooo.0o0.ooo/2017/06/28/5953b3774c2f2.png" alt="judge corners.png"></p>
<p>在判断角点时，无需具体计算矩阵$M$的特征值，而使用下式近似计算角点响应值。<br>$$R = detM-\alpha (traceM)^2$$<br>$$detM=\lambda_1 \lambda_2=AB-C^2$$<br>$$traceM=\lambda_1 + \lambda_2 = A+B$$<br>式中，$detM$为矩阵$M$的行列式，$traceM$为矩阵$M$的迹，$\alpha$为一常数，通常取值为0.04~0.06。</p>
<h3 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h3><p>Harris角点检测的算法步骤归纳如下：</p>
<ul>
<li>计算图像$I(x,y)$在$X$方向和$Y$方向的梯度<br>$$I_x=\dfrac {\partial I} {\partial x}=I(x,y)\otimes \left( \begin{matrix} -1&amp; 0&amp; 1\end{matrix} \right)$$<br>$$I_y=\dfrac {\partial I} {\partial y}=I(x,y)\otimes \left( \begin{matrix} -1&amp; 0&amp; 1\end{matrix} \right)^T$$</li>
<li>计算图像两个方向梯度的乘积$I_x^2、I_y^2、I_x I_y$</li>
<li>使用窗口高斯函数分别对$I_x^2、I_y^2、I_x I_y$进行高斯加权，生成矩阵$M$。</li>
<li>计算每个像素的Harris响应值$R$，并设定一阈值$T$，对小于阈值$T$的$R$置零。</li>
<li>在一个固定窗口大小的邻域内($5 \times 5$)进行非极大值抑制，局部极大值点即为图像中的角点。</li>
</ul>
<h3 id="Harris角点性质"><a href="#Harris角点性质" class="headerlink" title="Harris角点性质"></a>Harris角点性质</h3><p>1.参数$\alpha$对角点检测的影响：增大$\alpha$的值，将减小角点响应值$R$，减少被检测角点的数量；减小$\alpha$的值，将增大角点响应值$R$，增加被检测角点的数量。<br>2.Harris角点检测对亮度和对比度的变化不敏感。</p>
<p><img src="https://ooo.0o0.ooo/2017/06/28/5953bb60bb814.jpg" alt="Brightness-Contrast.jpg"></p>
<p>3.Harris角点检测具有旋转不变性，但不具备尺度不变性。如下图所示，在小尺度下的角点被放大后可能会被认为是图像边缘。</p>
<p><img src="https://ooo.0o0.ooo/2017/06/28/5953bb317b0b6.png" alt="scale.png"></p>
<p>Harris角点检测的结果示意图：</p>
<p><img src="https://ooo.0o0.ooo/2017/06/28/5953bc1427011.jpg" alt="result.jpg"></p>
<h3 id="多尺度Harris角点检测"><a href="#多尺度Harris角点检测" class="headerlink" title="多尺度Harris角点检测"></a>多尺度Harris角点检测</h3><p>&emsp;&emsp;Harris角点具有灰度不变性和旋转不变性，但不具备尺度不变性，而尺度不变性对于图像的局部特征来说至关重要。将Harris角点检测算子和高斯尺度空间表示相结合，可有效解决这个问题。与Harris角点检测中的二阶矩表示类似，定义一个尺度自适应的二阶矩<br>$$M=\mu (x,y,\sigma_I, \sigma_D)=\sigma_D^2g(\sigma_I) \otimes \left[ \begin{matrix} L_x^2(x,y,\sigma_D)&amp; L_xL_y(x,y,\sigma_D)\\ L_xL_y(x,y,\sigma_D)&amp; L_y^2(x,y,\sigma_D)\end{matrix} \right]$$<br>式中，$g(\sigma_I)$表示尺度为$\sigma_I$的高斯卷积核，$L_x(x,y,\sigma_D)$和$L_y(x,y,\sigma_D)$表示对图像使用高斯函数$g(\sigma_D)$进行平滑后取微分的结果。$\sigma_I$通常称为积分尺度，是决定Harris角点当前尺度的变量，$\sigma_D$为微分尺度，是决定角点附近微分值变化的变量，通常$\sigma_I$应大于$\sigma_D$。<br>算法流程：</p>
<ul>
<li>确定尺度空间的一组取值$\sigma_I=(\sigma_0, \sigma_1, \sigma_2,…, \sigma_n)=(\sigma, k\sigma, k^2\sigma,…, k^n\sigma), \sigma_D=s\sigma_I$</li>
<li>对于给定的尺度空间值$\sigma_D$，进行角点响应值的计算和判断，并做非极大值抑制处理</li>
<li>在位置空间搜索候选角点后，还需在尺度空间上进行搜索，计算候选点的拉普拉斯响应值，并于给定阈值作比较<br>$$F(x,y,\sigma_n)=\sigma_n^2|L_{xx}(x,y,\sigma_n)+L_{yy}(x,y,\sigma_n)| \geq threshold$$</li>
<li>将响应值$F$与邻近的两个尺度空间的拉普拉斯响应值进行比较，使其满足<br>$$F(x,y,\sigma_n) &gt; F(x,y,\sigma_l),&emsp;l=n-1, n+1$$</li>
</ul>
<p>这样既可确定在位置空间和尺度空间均满足条件的Harris角点。</p>
<h3 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h3><ul>
<li><a href="http://www.bmva.org/bmvc/1988/avc-88-023.pdf" target="_blank" rel="external">Paper: A COMBINED CORNER AND EDGE DETECTOR</a></li>
<li><a href="https://www.robots.ox.ac.uk/~vgg/research/affine/det_eval_files/mikolajczyk_ijcv2004.pdf" target="_blank" rel="external">Paper: Scale &amp; Affine Invariant Interest Point Detectors</a></li>
<li><a href="https://github.com/ronnyyoung/ImageFeatures" target="_blank" rel="external">Code: Harris Detector</a></li>
<li><a href="http://www.cnblogs.com/ronny/p/4009425.html" target="_blank" rel="external">http://www.cnblogs.com/ronny/p/4009425.html</a></li>
<li><a href="http://www.cnblogs.com/ronny/p/3886013.html" target="_blank" rel="external">http://www.cnblogs.com/ronny/p/3886013.html</a></li>
<li><a href="https://xmfbit.github.io/2017/01/25/cs131-finding-features/" target="_blank" rel="external">https://xmfbit.github.io/2017/01/25/cs131-finding-features/</a></li>
<li><a href="http://www.voidcn.com/blog/app_12062011/article/p-6071346.html" target="_blank" rel="external">http://www.voidcn.com/blog/app_12062011/article/p-6071346.html</a></li>
<li><a href="http://blog.csdn.net/jwh_bupt/article/details/7628665" target="_blank" rel="external">http://blog.csdn.net/jwh_bupt/article/details/7628665</a></li>
<li><a href="http://www.cnblogs.com/ztfei/archive/2012/05/07/2487123.html" target="_blank" rel="external">http://www.cnblogs.com/ztfei/archive/2012/05/07/2487123.html</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp;角点检测(Corner Detection)也称为特征点检测，是图像处理和计算机视觉中用来获取图像局部特征点的一类方法，广泛应用于运动检测、图像匹配、视频跟踪、三维建模以及目标识别等领域中。&lt;br&gt;
    
    </summary>
    
      <category term="Algorithm" scheme="https://senitco.github.io/categories/Algorithm/"/>
    
    
      <category term="Image" scheme="https://senitco.github.io/tags/Image/"/>
    
  </entry>
  
  <entry>
    <title>图像特征提取之Haar特征</title>
    <link href="https://senitco.github.io/2017/06/25/image-feature-haar/"/>
    <id>https://senitco.github.io/2017/06/25/image-feature-haar/</id>
    <published>2017-06-25T06:06:55.987Z</published>
    <updated>2017-06-28T02:22:15.917Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;Haar特征是一种用于目标检测或识别的图像特征描述子，Haar特征通常和AdaBoost分类器组合使用，而且由于Haar特征提取的实时性以及AdaBoost分类的准确率，使其成为人脸检测以及识别领域较为经典的算法。<br><a id="more"></a></p>
<h3 id="多种Haar-like特征"><a href="#多种Haar-like特征" class="headerlink" title="多种Haar-like特征"></a>多种Haar-like特征</h3><p>&emsp;&emsp;在Haar-like特征提出之前，传统的人脸检测算法一般是基于图像像素值进行的，计算量较大且实时性较差。Papageorgiou等人最早将Harr小波用于人脸特征表示，Viola和Jones则在此基础上，提出了多种形式的Haar特征。Lienhart等人对Haar矩形特征做了进一步的扩展，加入了旋转$45^{\circ}$的矩形特征，因此现有的Haar特征模板主要如下图所示：</p>
<p><img src="https://ooo.0o0.ooo/2017/06/25/594f76b0d6c65.jpg" alt="haar.jpg" title="Haar-like矩形特征"></p>
<p>&emsp;&emsp;在计算Haar特征值时，用白色区域像素值的和减去黑色区域像素值的和，也就是说白色区域的权值为正值，黑色区域的权值为负值，而且权值与矩形区域的面积成反比，抵消两种矩形区域面积不等造成的影响，保证Haar特征值在灰度分布均匀的区域特征值趋近于0。Haar特征在一定程度上反应了图像灰度的局部变化，在人脸检测中，脸部的一些特征可由矩形特征简单刻画，例如，眼睛比周围区域的颜色要深，鼻梁比两侧颜色要浅等。<br>&emsp;&emsp;Haar-like矩形特征分为多类，特征模板可用于图像中的任一位置，而且大小也可任意变化，因此Haar特征的取值受到特征模板的类别、位置以及大小这三种因素的影响，使得在一固定大小的图像窗口内，可以提取出大量的Haar特征。例如，在一个$24\times 24$的检测窗口内，矩形特征的数量可以达到16万个。这样就需要解决两个重要问题，快速计算Haar矩形特征值——积分图；筛选有效的矩形特征用于分类识别——AdaBoost分类器。</p>
<h3 id="快速计算——积分图"><a href="#快速计算——积分图" class="headerlink" title="快速计算——积分图"></a>快速计算——积分图</h3><h4 id="积分图构建"><a href="#积分图构建" class="headerlink" title="积分图构建"></a>积分图构建</h4><p>&emsp;&emsp;在一个图像窗口中，可以提取出大量的Haar矩形特征区域，如果在计算Haar特征值时，每次都遍历矩形特征区域，将会造成大量重复计算，严重浪费时间。而积分图正是一种快速计算矩形特征的方法，其主要思想是将图像起始像素点到每一个像素点之间所形成的矩形区域的像素值的和，作为一个元素保存下来，也就是将原始图像转换为积分图(或者求和图)，这样在求某一矩形区域的像素和时，只需索引矩形区域4个角点在积分图中的取值，进行普通的加减运算，即可求得Haar特征值，整个过程只需遍历一次图像，计算特征的时间复杂度为常数(O(1))。因此可以大大提升计算效率。<br>积分图中元素的公式定义如下：<br>$$ii(x,y) = \Sigma_{x’\leq x,y’\leq y} i(x’,y’)$$<br>上式含义是在$(x,y)$(第$x$行第$y$列)位置处，积分图中元素为原图像中对应像素左上角所有像素值之和。在具体实现时，可用下式进行迭代运算。<br>$$s(x,y)=s(x,y-1)+i(x,y)$$<br>$$ii(x,y)=ii(x-1,y)+s(x,y)$$<br>$s(x,y)$为行元素累加值，初始值$s(x,-1)=0,ii(-1,y)=0$</p>
<h4 id="矩形特征计算"><a href="#矩形特征计算" class="headerlink" title="矩形特征计算"></a>矩形特征计算</h4><p>&emsp;&emsp;构建好积分图后，图像中任何矩形区域的像素值累加和都可以通过简单的加减运算快速得到，如下图所示，矩形区域D的像素和值计算公式如下：<br>$$Sum(D)=ii(x_4, y_4)-ii(x_2,y_2)-ii(x_3,y_3)+ii(x_1,y_1)$$</p>
<p><img src="https://ooo.0o0.ooo/2017/06/25/594fb4dceae3c.jpg" alt="rectangle.jpg" title="矩形区域求和示意图"><br>在下图中，以水平向右为x轴正方向，垂直向下为y轴正方向，可定义积分图公式Summed Area Table($SAT(x,y)$)<br>$$SAT(x,y)=\Sigma_{x’\leq x,y’\leq y} i(x’,y’)$$<br>以及迭代求解式<br>$$SAT(x,y)=SAT(x,y-1)+SAT(x-1,y)-SAT(x-1,y-1)+I(x,y)$$<br>$$SAT(-1,y)=0, SAT(x,-1)=0$$<br>对于左上角坐标为$(x,y)$，宽高为$(w,h)$的矩形区域$r(x,y,w,h,0)$，可利用积分图$SAT(x,y)$求取像素和值<br>$$RecSum(r)=SAT(x+w-1, y+h-1)+SAT(x-1, y-1)-SAT(x+w-1, y-1)-SAT(x-1,y+h-1)$$<br><img src="https://ooo.0o0.ooo/2017/06/25/594fb9abd4e14.jpg" alt="integer.jpg" title="积分图求矩形区域和值"></p>
<h4 id="旋转矩形特征的计算"><a href="#旋转矩形特征的计算" class="headerlink" title="旋转矩形特征的计算"></a>旋转矩形特征的计算</h4><p>&emsp;&emsp;对于旋转矩形特征，相应的有$45^{\circ}$倾斜积分图用于快速计算Haar特征值，如下图所示，倾斜积分图的定义为像素点左上角$45^{\circ}$区域和左下角$45^{\circ}$区域的像素和，公式表示如下：<br>$$RSAT(x,y)=\Sigma_{x’\leq x,x’\leq x-\left|y-y’\right|} i(x’,y’)$$<br>其递推公式计算如下：<br>$$RSAT(x,y)=RSAT(x-1,y-1)+RSAT(x-1,y)-RSAT(x-2,y-1)+I(x,y)$$<br>$$RSAT(x,y)=RSAT(x,y)+RSAT(x-1,y+1)-RSAT(x-2,y)$$<br>其中$RSAT(-1,y)=RSAT(-2,y)=RSAT(x,-1)=0$<br>也可直接通过下式递归计算：<br>$$RSAT(x,y)=RSAT(x-1,y-1)+RSAT(x+1,y-1)-RSAT(x,y-2)+I(x-1,y)+I(x,y)$$<br>以上3个积分图计算公式是等价的。<br><img src="https://ooo.0o0.ooo/2017/06/25/594fb9abd4190.jpg" alt="titled interger.jpg" title="倾斜积分图求倾斜矩形区域和值"><br>如下图所示，构建好倾斜积分图后，可快速计算倾斜矩形区域$r=(x,y,w,h,45^{\circ})$的像素和值<br>$$RecSum(r)=RSAT(x+w,y+w)+RSAT(x-h,y+h)-RSAT(x,y)-RSAT(x+w-h,y+w+h)$$<br><img src="https://ooo.0o0.ooo/2017/06/25/594fb9abe7aa1.jpg" alt="rotated rectangle.jpg" title="倾斜矩形区域求和示意图"></p>
<h3 id="AdaBoost分类器"><a href="#AdaBoost分类器" class="headerlink" title="AdaBoost分类器"></a>AdaBoost分类器</h3><p>&emsp;&emsp;由输入图像得到积分图，通过取不同种类、大小的Haar特征模板，并在不同位置处，利用积分图提取Haar矩形特征，可快速得到大量Haar特征值，AdaBoost分类器可用于对提取的Haar特征(通常需要做归一化处理)进行训练分类，并应用于人脸检测中。AdaBoost是一种集成分类器，由若干个强分类级联而成，而每个强分类器又由若干个弱分类器(例如决策树)组合训练得到。<br>弱分类器的定义如下：<br>$$h_j(x)=\begin{cases} 1,&emsp;p_j f_j(x) &lt; p_j \theta_j\\ 0,&emsp;otherwise\end{cases}$$<br>上式中$p_j$是为了控制不等式的方向而设置的参数。$x$表示一个图像窗口，$f_j(x)$表示提取的Haar特征，阈值$\theta$用于判断该窗口是否为目标区域(人脸)。<br>算法流程：</p>
<ul>
<li>假设训练样本为$(x_i,y_i),i=0,1,…,n$，$y_i$取值为0(负样本)、1(正样本)。</li>
<li>初始化权重$w_1,i=\dfrac{1}{2m},y_i=\dfrac{1}{2l}$，其中$m$表示负样本的个数，$l$表示正样本的个数。</li>
<li>For $t =1,2,…,T$<br>1.归一化权值：$w_{t,i} = \dfrac{w_{t,i}}{\Sigma_{j=1}^n w_{t,j}} $<br>2.对于每个(种)特征，训练一个分类器($h_j$)，每个分类器只使用一种Haar特征进行训练。分类误差为$\varepsilon_j=\Sigma_i w_i \left|h_j(x_i)-y_i\right|$，$h_j$为特征分类器，$x_i$为训练图像样本。<br>3.选择最低误差的分类器$h_t$<br>4.更新训练样本的权值$w_{t+1,i}=w_{t,i}\beta_t^{1-e_i}$，分类正确$e_i=0$，分类错误$e_i=1$，$\beta_t=\dfrac{\varepsilon_t}{1-\varepsilon_t}$</li>
<li>最后的强分类器为<br>$$h(x)=\begin{cases} 1,&emsp;\Sigma_{t=1}^T \alpha_t h_t \geq \dfrac{1}{2}\Sigma_{t=1}^T \alpha_t \\ 0,&emsp;otherwise\end{cases}$$<br>其中$\alpha_t=log(\dfrac{1}{\beta_t})$。</li>
</ul>
<p>&emsp;&emsp;在训练多个弱分类器得到强分类器的过程中，采用了两次加权的处理方法，一是对样本进行加权，在迭代过程中，提高错分样本的权重；二是对筛选出的弱分类器$h_t$进行加权，弱分类器准确率越高，权重越大。此外，还需进一步对强分类器进行级联，以提高检测正确率并降低误识率。级联分类器如下所示：</p>
<p><img src="https://ooo.0o0.ooo/2017/06/26/59506e87bf0f5.jpg" alt="cascade.jpg" title="级联分类器"></p>
<p>&emsp;&emsp;首先将所有待检测的子窗口输入到第一个分类器中，如果某个子窗口判决通过，则进入下一个分类器继续检测识别，否则该子窗口直接退出检测流程，也就是说后续分类器不需要处理该子窗口。通过这样一种级联的方式可以去除一些误识为目标的子窗口，降低误识率。例如，单个强分类器，99%的目标窗口可以通过，同时50%的非目标窗口也能通过，假设有20个强分类器级联，那么最终的正确检测率为$0.99^{20}=98\%$，而错误识别率为$0.50^{20} \approx 0.0001\%$，在不影响检测准确率的同时，大大降低了误识率。当然前提是单个强分类器的准确率非常高，这样级联多个分类器才能不影响最终的准确率或者影响很小。</p>
<p>&emsp;&emsp;在一幅图像中，为了能够检测到不同位置的目标区域，需要以一定步长遍历整幅图像；而对于不同大小的目标，则需要改变检测窗口的尺寸，或者固定窗口而缩放图像。这样，最后检测到的子窗口必然存在相互重叠的情况，因此需要进一步对这些重叠的子窗口进行合并，也就是非极大值抑制(NMS,non-maximum suppression)，同时剔除零散分布的错误检测窗口。</p>
<h3 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h3><ul>
<li><a href="http://wearables.cc.gatech.edu/paper_of_week/viola01rapid.pdf" target="_blank" rel="external">Paper: Rapid Object Detection using a Boosted Cascade of Simple Features</a></li>
<li><a href="https://link.springer.com/content/pdf/10.1007%2F978-3-540-45243-0_39.pdf" target="_blank" rel="external">Paper: Empirical Analysis of Detection Cascades of Boosted Classifiers for Rapid Object Detection</a></li>
<li><a href="https://pdfs.semanticscholar.org/72e0/8cf12730135c5ccd7234036e04536218b6c1.pdf" target="_blank" rel="external">Paper: An Extended Set of Haar-like Features for Rapid Object Detection</a></li>
<li><a href="http://blog.csdn.net/xizero00/article/details/46929261" target="_blank" rel="external">http://blog.csdn.net/xizero00/article/details/46929261</a></li>
<li><a href="http://www.cnblogs.com/bhlsheji/p/4726376.html" target="_blank" rel="external">http://www.cnblogs.com/bhlsheji/p/4726376.html</a></li>
<li><a href="http://blog.csdn.net/zy1034092330/article/details/50383097" target="_blank" rel="external">http://blog.csdn.net/zy1034092330/article/details/50383097</a></li>
<li><a href="http://blog.csdn.net/zouxy09/article/details/7929570" target="_blank" rel="external">http://blog.csdn.net/zouxy09/article/details/7929570</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp;Haar特征是一种用于目标检测或识别的图像特征描述子，Haar特征通常和AdaBoost分类器组合使用，而且由于Haar特征提取的实时性以及AdaBoost分类的准确率，使其成为人脸检测以及识别领域较为经典的算法。&lt;br&gt;
    
    </summary>
    
      <category term="Algorithm" scheme="https://senitco.github.io/categories/Algorithm/"/>
    
    
      <category term="Image" scheme="https://senitco.github.io/tags/Image/"/>
    
  </entry>
  
  <entry>
    <title>图像特征提取之LBP特征</title>
    <link href="https://senitco.github.io/2017/06/12/image-feature-lbp/"/>
    <id>https://senitco.github.io/2017/06/12/image-feature-lbp/</id>
    <published>2017-06-12T06:16:51.586Z</published>
    <updated>2017-06-13T04:35:51.262Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;局部二值模式(Local Binary Patter, LBP)是一种用来描述图像局部纹理特征的算子，LBP特征具有灰度不变性和旋转不变性等显著优点，它将图像中的各个像素与其邻域像素值进行比较，将结果保存为二进制数，并将得到的二进制比特串作为中心像素的编码值，也就是LBP特征值。LBP提供了一种衡量像素间邻域关系的特征模式，因此可以有效地提取图像的局部特征，而且由于其计算简单，可用于基于纹理分类的实时应用场景，例如目标检测、人脸识别等。<br><a id="more"></a></p>
<!-- mathjax config similar to math.stackexchange -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
        inlineMath: [ ['$', '$'] ],
        displayMath: [ ['$$', '$$']],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    messageStyle: "none",
    "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<h3 id="原始LBP特征"><a href="#原始LBP特征" class="headerlink" title="原始LBP特征"></a>原始LBP特征</h3><p>&emsp;&emsp;原始的LBP算子定义于图像中$3 \times 3$的邻域窗口，取窗口内中心像素的灰度值作为阈值，将8邻域像素的灰度值与其进行比较，若邻域像素值大于中心像素值，则比较结果取值为1，否则为0。这样邻域内的8个像素点经过比较后可得到8位二进制数，将其按顺序依次排列即可得到中心像素的LBP值。LBP特征值反映了中心像素和其邻域的纹理信息。LBP的取值一共有$2^8 = 256$种，和一幅普通的灰度图像类似，因此可将LBP特征以灰度图的形式表达出来。由于LBP特征考虑的是纹理信息，而不包含颜色信息，因此彩色图需转换为灰度图。原始LBP特征的提取过程如下图所示：</p>
<p><img src="https://ooo.0o0.ooo/2017/06/12/593e3dae121e4.jpg" alt="origin-LBP.jpg" title="LBP特征提取"></p>
<p>公式定义如下：<br>$$LBP(x_c,y_c)=\Sigma_{p=0}^{P-1} 2^p s(i_p-i_c)$$<br>其中$(x_c,y_c)$代表邻域窗口内的中心像素，其像素值为$i_c$，$i_p为邻域内其他像素值$，s(x)是符号函数。<br>原始LBP特征的实现代码(OpenCV)如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">template &lt;typename _tp&gt;</div><div class="line">void getOriginLBPFeature(InputArray _src,OutputArray _dst)</div><div class="line">&#123;</div><div class="line">    Mat src = _src.getMat();</div><div class="line">    _dst.create(src.rows-2,src.cols-2,CV_8UC1);</div><div class="line">    Mat dst = _dst.getMat();</div><div class="line">    dst.setTo(0);</div><div class="line">    for(int i=1;i&lt;src.rows-1;i++)</div><div class="line">    &#123;</div><div class="line">        for(int j=1;j&lt;src.cols-1;j++)</div><div class="line">        &#123;</div><div class="line">            _tp center = src.at&lt;_tp&gt;(i,j);</div><div class="line">            unsigned char lbpCode = 0;</div><div class="line">            lbpCode |= (src.at&lt;_tp&gt;(i-1,j-1) &gt; center) &lt;&lt; 7;</div><div class="line">            lbpCode |= (src.at&lt;_tp&gt;(i-1,j  ) &gt; center) &lt;&lt; 6;</div><div class="line">            lbpCode |= (src.at&lt;_tp&gt;(i-1,j+1) &gt; center) &lt;&lt; 5;</div><div class="line">            lbpCode |= (src.at&lt;_tp&gt;(i  ,j+1) &gt; center) &lt;&lt; 4;</div><div class="line">            lbpCode |= (src.at&lt;_tp&gt;(i+1,j+1) &gt; center) &lt;&lt; 3;</div><div class="line">            lbpCode |= (src.at&lt;_tp&gt;(i+1,j  ) &gt; center) &lt;&lt; 2;</div><div class="line">            lbpCode |= (src.at&lt;_tp&gt;(i+1,j-1) &gt; center) &lt;&lt; 1;</div><div class="line">            lbpCode |= (src.at&lt;_tp&gt;(i  ,j-1) &gt; center) &lt;&lt; 0;</div><div class="line">            dst.at&lt;uchar&gt;(i-1,j-1) = lbpCode;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="圆形LBP特征-Circular-LBP-or-Extended-LBP"><a href="#圆形LBP特征-Circular-LBP-or-Extended-LBP" class="headerlink" title="圆形LBP特征(Circular LBP or Extended LBP)"></a>圆形LBP特征(Circular LBP or Extended LBP)</h3><p>&emsp;&emsp;原始LBP特征考虑的是固定半径范围内的邻域像素，不能满足不同尺寸和频率纹理的需求，当图像的尺寸发生变化时，LBP特征将不能正确编码局部邻域的纹理信息。为了适应不同尺寸的纹理特征，Ojala等人对LBP算子<br>进行了改进，将$3 \times 3$邻域窗口扩展到任意邻域，并用圆形邻域代替了正方形邻域，改进后的LBP算子允许在半径为R的邻域内有任意多个像素点，从而得到在半径为R的区域内含有P个采样点的LBP算子。</p>
<p><img src="https://ooo.0o0.ooo/2017/06/12/593e49563d486.png" alt="circular-lbp.png" title="不同尺寸的圆形LBP算子"></p>
<p>采样点的坐标可通过以下公式计算：<br>$$x_p=x_c+R cos(2\pi p / P)$$<br>$$y_p=y_c+R sin(2\pi p / P)$$<br>其中$(x_c,y_c)$为中心像素点，$(x_p,y_p),p\in P$为邻域内某个采样点，通过上次可以计算任意个采样点的坐标，但是得到的坐标值未必为整数，因此可通过双线性插值的方法来得到该采样点的像素值：<br>$$f(x, y) = \left[ \begin{matrix} 1-x&amp; x\end{matrix} \right] \left[ \begin{matrix} f(0,0)&amp; f(0,1)\\ f(1,0)&amp; f(1,1)\end{matrix} \right] \left[ \begin{matrix} 1-y\\ y\end{matrix} \right]$$</p>
<p>圆形LBP特征的实现代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div></pre></td><td class="code"><pre><div class="line">//圆形LBP特征计算，这种方法适于理解，但在效率上存在问题，声明时默认neighbors=8</div><div class="line">template &lt;typename _tp&gt;</div><div class="line">void getCircularLBPFeature(InputArray _src,OutputArray _dst,int radius,int neighbors)</div><div class="line">&#123;</div><div class="line">    Mat src = _src.getMat();</div><div class="line">    //LBP特征图像的行数和列数的计算要准确</div><div class="line">    _dst.create(src.rows-2*radius,src.cols-2*radius,CV_8UC1);</div><div class="line">    Mat dst = _dst.getMat();</div><div class="line">    dst.setTo(0);</div><div class="line">    //循环处理每个像素</div><div class="line">    for(int i=radius;i&lt;src.rows-radius;i++)</div><div class="line">    &#123;</div><div class="line">        for(int j=radius;j&lt;src.cols-radius;j++)</div><div class="line">        &#123;</div><div class="line">            //获得中心像素点的灰度值</div><div class="line">            _tp center = src.at&lt;_tp&gt;(i,j);</div><div class="line">            unsigned char lbpCode = 0;</div><div class="line">            for(int k=0;k&lt;neighbors;k++)</div><div class="line">            &#123;</div><div class="line">                //根据公式计算第k个采样点的坐标，这个地方可以优化，不必每次都进行计算radius*cos，radius*sin</div><div class="line">                float x = i + static_cast&lt;float&gt;(radius * \</div><div class="line">                    cos(2.0 * CV_PI * k / neighbors));</div><div class="line">                float y = j - static_cast&lt;float&gt;(radius * \</div><div class="line">                    sin(2.0 * CV_PI * k / neighbors));</div><div class="line">                //根据取整结果进行双线性插值，得到第k个采样点的灰度值</div><div class="line"></div><div class="line">                //1.分别对x，y进行上下取整</div><div class="line">                int x1 = static_cast&lt;int&gt;(floor(x));</div><div class="line">                int x2 = static_cast&lt;int&gt;(ceil(x));</div><div class="line">                int y1 = static_cast&lt;int&gt;(floor(y));</div><div class="line">                int y2 = static_cast&lt;int&gt;(ceil(y));</div><div class="line"></div><div class="line">                //2.计算四个点(x1,y1),(x1,y2),(x2,y1),(x2,y2)的权重</div><div class="line">                //下面的权重计算方式有个问题，如果四个点都相等，则权重全为0，计算出来的插值为0</div><div class="line">                //float w1 = (x2-x)*(y2-y); //(x1,y1)</div><div class="line">                //float w2 = (x2-x)*(y-y1); //(x1,y2)</div><div class="line">                //float w3 = (x-x1)*(y2-y); //(x2,y1)</div><div class="line">                //float w4 = (x-x1)*(y-y1); //(x2,y2)</div><div class="line"></div><div class="line">                //将坐标映射到0-1之间</div><div class="line">                float tx = x - x1;</div><div class="line">                float ty = y - y1;</div><div class="line">                //根据0-1之间的x，y的权重计算公式计算权重</div><div class="line">                float w1 = (1-tx) * (1-ty);</div><div class="line">                float w2 =    tx  * (1-ty);</div><div class="line">                float w3 = (1-tx) *    ty;</div><div class="line">                float w4 =    tx  *    ty;</div><div class="line">                //3.根据双线性插值公式计算第k个采样点的灰度值</div><div class="line">                float neighbor = src.at&lt;_tp&gt;(x1,y1) * w1 + src.at&lt;_tp&gt;(x1,y2) *w2 \</div><div class="line">                    + src.at&lt;_tp&gt;(x2,y1) * w3 +src.at&lt;_tp&gt;(x2,y2) *w4;</div><div class="line">                //通过比较获得LBP值，并按顺序排列起来</div><div class="line">                lbpCode |= (neighbor&gt;center) &lt;&lt;(neighbors-k-1);</div><div class="line">            &#125;</div><div class="line">            dst.at&lt;uchar&gt;(i-radius,j-radius) = lbpCode;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>圆形LBP特征的效率优化版本：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div></pre></td><td class="code"><pre><div class="line">//圆形LBP特征计算，效率优化版本，声明时默认neighbors=8</div><div class="line">template &lt;typename _tp&gt;</div><div class="line">void getCircularLBPFeatureOptimization(InputArray _src,OutputArray _dst,int radius,int neighbors)</div><div class="line">&#123;</div><div class="line">    Mat src = _src.getMat();</div><div class="line">    //LBP特征图像的行数和列数的计算要准确</div><div class="line">    _dst.create(src.rows-2*radius,src.cols-2*radius,CV_8UC1);</div><div class="line">    Mat dst = _dst.getMat();</div><div class="line">    dst.setTo(0);</div><div class="line">    for(int k=0;k&lt;neighbors;k++)</div><div class="line">    &#123;</div><div class="line">        //计算采样点对于中心点坐标的偏移量rx，ry</div><div class="line">        float rx = static_cast&lt;float&gt;(radius * cos(2.0 * CV_PI * k / neighbors));</div><div class="line">        float ry = -static_cast&lt;float&gt;(radius * sin(2.0 * CV_PI * k / neighbors));</div><div class="line">        //为双线性插值做准备</div><div class="line">        //对采样点偏移量分别进行上下取整</div><div class="line">        int x1 = static_cast&lt;int&gt;(floor(rx));</div><div class="line">        int x2 = static_cast&lt;int&gt;(ceil(rx));</div><div class="line">        int y1 = static_cast&lt;int&gt;(floor(ry));</div><div class="line">        int y2 = static_cast&lt;int&gt;(ceil(ry));</div><div class="line">        //将坐标偏移量映射到0-1之间</div><div class="line">        float tx = rx - x1;</div><div class="line">        float ty = ry - y1;</div><div class="line">        //根据0-1之间的x，y的权重计算公式计算权重，权重与坐标具体位置无关，与坐标间的差值有关</div><div class="line">        float w1 = (1-tx) * (1-ty);</div><div class="line">        float w2 =    tx  * (1-ty);</div><div class="line">        float w3 = (1-tx) *    ty;</div><div class="line">        float w4 =    tx  *    ty;</div><div class="line">        //循环处理每个像素</div><div class="line">        for(int i=radius;i&lt;src.rows-radius;i++)</div><div class="line">        &#123;</div><div class="line">            for(int j=radius;j&lt;src.cols-radius;j++)</div><div class="line">            &#123;</div><div class="line">                //获得中心像素点的灰度值</div><div class="line">                _tp center = src.at&lt;_tp&gt;(i,j);</div><div class="line">                //根据双线性插值公式计算第k个采样点的灰度值</div><div class="line">                float neighbor = src.at&lt;_tp&gt;(i+x1,j+y1) * w1 + src.at&lt;_tp&gt;(i+x1,j+y2) *w2 \</div><div class="line">                    + src.at&lt;_tp&gt;(i+x2,j+y1) * w3 +src.at&lt;_tp&gt;(i+x2,j+y2) *w4;</div><div class="line">                //LBP特征图像的每个邻居的LBP值累加，累加通过与操作完成，对应的LBP值通过移位取得</div><div class="line">                dst.at&lt;uchar&gt;(i-radius,j-radius) |= (neighbor&gt;center) &lt;&lt;(neighbors-k-1);</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="旋转不变LBP特征-Rotation-Invariant-LBP"><a href="#旋转不变LBP特征-Rotation-Invariant-LBP" class="headerlink" title="旋转不变LBP特征(Rotation Invariant LBP)"></a>旋转不变LBP特征(Rotation Invariant LBP)</h3><p>&emsp;&emsp;无论是原始LBP算子还是圆形LBP算子，都只是灰度不变的，而不是旋转不变的，旋转图像会得到不同的LBP特征值。相关研究人员又提出了一种具有旋转不变性的LBP算子，即不断旋转圆形邻域的采样点，或者以不同的邻域像素作为起始点，顺时针遍历所有采样点，得到一系列编码值(P个)，取其中最小的作为该邻域中心像素的LBP值。旋转不变LBP算子的示意图如下：</p>
<p><img src="https://ooo.0o0.ooo/2017/06/13/593f6abf457df.jpg" alt="Rota-inv-lbp.jpg" title="旋转不变LBP算子"></p>
<p>旋转不变LBP特征的实现代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div></pre></td><td class="code"><pre><div class="line">//旋转不变圆形LBP特征计算，声明时默认neighbors=8</div><div class="line">template &lt;typename _tp&gt;</div><div class="line">void getRotationInvariantLBPFeature(InputArray _src,OutputArray _dst,int radius,int neighbors)</div><div class="line">&#123;</div><div class="line">    Mat src = _src.getMat();</div><div class="line">    //LBP特征图像的行数和列数的计算要准确</div><div class="line">    _dst.create(src.rows-2*radius,src.cols-2*radius,CV_8UC1);</div><div class="line">    Mat dst = _dst.getMat();</div><div class="line">    dst.setTo(0);</div><div class="line">    for(int k=0;k&lt;neighbors;k++)</div><div class="line">    &#123;</div><div class="line">        //计算采样点对于中心点坐标的偏移量rx，ry</div><div class="line">        float rx = static_cast&lt;float&gt;(radius * cos(2.0 * CV_PI * k / neighbors));</div><div class="line">        float ry = -static_cast&lt;float&gt;(radius * sin(2.0 * CV_PI * k / neighbors));</div><div class="line">        //为双线性插值做准备</div><div class="line">        //对采样点偏移量分别进行上下取整</div><div class="line">        int x1 = static_cast&lt;int&gt;(floor(rx));</div><div class="line">        int x2 = static_cast&lt;int&gt;(ceil(rx));</div><div class="line">        int y1 = static_cast&lt;int&gt;(floor(ry));</div><div class="line">        int y2 = static_cast&lt;int&gt;(ceil(ry));</div><div class="line">        //将坐标偏移量映射到0-1之间</div><div class="line">        float tx = rx - x1;</div><div class="line">        float ty = ry - y1;</div><div class="line">        //根据0-1之间的x，y的权重计算公式计算权重，权重与坐标具体位置无关，与坐标间的差值有关</div><div class="line">        float w1 = (1-tx) * (1-ty);</div><div class="line">        float w2 =    tx  * (1-ty);</div><div class="line">        float w3 = (1-tx) *    ty;</div><div class="line">        float w4 =    tx  *    ty;</div><div class="line">        //循环处理每个像素</div><div class="line">        for(int i=radius;i&lt;src.rows-radius;i++)</div><div class="line">        &#123;</div><div class="line">            for(int j=radius;j&lt;src.cols-radius;j++)</div><div class="line">            &#123;</div><div class="line">                //获得中心像素点的灰度值</div><div class="line">                _tp center = src.at&lt;_tp&gt;(i,j);</div><div class="line">                //根据双线性插值公式计算第k个采样点的灰度值</div><div class="line">                float neighbor = src.at&lt;_tp&gt;(i+x1,j+y1) * w1 + src.at&lt;_tp&gt;(i+x1,j+y2) *w2 \</div><div class="line">                    + src.at&lt;_tp&gt;(i+x2,j+y1) * w3 +src.at&lt;_tp&gt;(i+x2,j+y2) *w4;</div><div class="line">                //LBP特征图像的每个邻居的LBP值累加，累加通过与操作完成，对应的LBP值通过移位取得</div><div class="line">                dst.at&lt;uchar&gt;(i-radius,j-radius) |= (neighbor&gt;center) &lt;&lt;(neighbors-k-1);</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    //进行旋转不变处理</div><div class="line">    for(int i=0;i&lt;dst.rows;i++)</div><div class="line">    &#123;</div><div class="line">        for(int j=0;j&lt;dst.cols;j++)</div><div class="line">        &#123;</div><div class="line">            unsigned char currentValue = dst.at&lt;uchar&gt;(i,j);</div><div class="line">            unsigned char minValue = currentValue;</div><div class="line">            for(int k=1;k&lt;neighbors;k++)		//循环左移</div><div class="line">            &#123;</div><div class="line">                unsigned char temp = (currentValue&gt;&gt;(neighbors-k)) | (currentValue&lt;&lt;k);</div><div class="line">                if(temp &lt; minValue)</div><div class="line">                &#123;</div><div class="line">                    minValue = temp;</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">            dst.at&lt;uchar&gt;(i,j) = minValue;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="LBP等价模式-Uniform-LBP"><a href="#LBP等价模式-Uniform-LBP" class="headerlink" title="LBP等价模式(Uniform LBP)"></a>LBP等价模式(Uniform LBP)</h3><p>&emsp;&emsp;对于一个半径为R的圆形区域，包含有P个邻域采样点，则LBP算子可能产生$2^P$种模式。随着邻域内采样点数的增加，LBP值的取值数量呈指数级增长。例如$5 \times 5$邻域内20个采样点，则对应有$2^{20}$中模式，过多的二进制模式不利于纹理信息的提取、分类、识别。例如，将LBP特征用于纹理分类或人脸识别时，一般采用LBP特征的统计直方图来表达图像的信息，而较多的模式种类将使得数据量过大，且直方图过于稀疏。因此，需要对原始的LBP特征进行降维，使得数据量减少的情况下能最好地表达图像的信息。<br>&emsp;&emsp;为了解决二进制模式过多的问题，提高统计性，Ojala提出了一种“等价模式”(Uniform Pattern)来对LBP特征的模式种类进行降维。Ojala认为，在实际图像中，绝大数LBP模式最多只包含两次从0到1或者从1到0的跳变，“等价模式”定义为：当某个LBP所对应的循环二进制数从0到1或者从1到0最多有两次跳变时，该LBP所对应的二进制就是一个等价模式类。如00000000(0次跳变)，11000011(2次跳变)都是等价模式类。除等价模式类以外的模式都归为另一类，称为混合模式类，例如10010111(共4次跳变)。通过改进，二进制模式的种类大大减少，由原来的$2^P$中降为$P(P-1)+2+1$种，其中$P(P-1)$为2次跳变的模式数，2为0次跳变(全”0”或全”1”)的模式数，1为混合模式的数量，由于是循环二进制数，因此’0’、’1’跳变次数不可能为奇数次。对于$3 \times 3$邻域内8个采样点来说，二进制模式由原始的256种变为59种。这使得特征向量的维数大大减少，并且可以减少高频噪声带来的影响。实验表明，一般情况下，等价模式的数目占全部模式的90%以上，可以有效对数据进行降维。下图为58种等价模式类：</p>
<p><img src="https://ooo.0o0.ooo/2017/06/13/593f48869b16f.png" alt="uniform LBP.png" title="LBP等价模式"></p>
<p>在具体实现中，等价模式类按值递增从1开始编码，混合模式类编码为0，因此得到的LBP特征图整体偏暗。LBP等价模式的实现代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div></pre></td><td class="code"><pre><div class="line">//等价模式LBP特征计算</div><div class="line">template &lt;typename _tp&gt;</div><div class="line">void getUniformPatternLBPFeature(InputArray _src,OutputArray _dst,int radius,int neighbors)</div><div class="line">&#123;</div><div class="line">    Mat src = _src.getMat();</div><div class="line">    //LBP特征图像的行数和列数的计算要准确</div><div class="line">    _dst.create(src.rows-2*radius,src.cols-2*radius,CV_8UC1);</div><div class="line">    Mat dst = _dst.getMat();</div><div class="line">    dst.setTo(0);</div><div class="line">    //LBP特征值对应图像灰度编码表，直接默认采样点为8位</div><div class="line">    uchar temp = 1;</div><div class="line">    uchar table[256] = &#123;0&#125;;</div><div class="line">    for(int i=0;i&lt;256;i++)</div><div class="line">    &#123;</div><div class="line">        if(getHopTimes(i)&lt;3)</div><div class="line">        &#123;</div><div class="line">            table[i] = temp;</div><div class="line">            temp++;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    //是否进行UniformPattern编码的标志</div><div class="line">    bool flag = false;</div><div class="line">    //计算LBP特征图</div><div class="line">    for(int k=0;k&lt;neighbors;k++)</div><div class="line">    &#123;</div><div class="line">        if(k==neighbors-1)</div><div class="line">        &#123;</div><div class="line">            flag = true;</div><div class="line">        &#125;</div><div class="line">        //计算采样点对于中心点坐标的偏移量rx，ry</div><div class="line">        float rx = static_cast&lt;float&gt;(radius * cos(2.0 * CV_PI * k / neighbors));</div><div class="line">        float ry = -static_cast&lt;float&gt;(radius * sin(2.0 * CV_PI * k / neighbors));</div><div class="line">        //为双线性插值做准备</div><div class="line">        //对采样点偏移量分别进行上下取整</div><div class="line">        int x1 = static_cast&lt;int&gt;(floor(rx));</div><div class="line">        int x2 = static_cast&lt;int&gt;(ceil(rx));</div><div class="line">        int y1 = static_cast&lt;int&gt;(floor(ry));</div><div class="line">        int y2 = static_cast&lt;int&gt;(ceil(ry));</div><div class="line">        //将坐标偏移量映射到0-1之间</div><div class="line">        float tx = rx - x1;</div><div class="line">        float ty = ry - y1;</div><div class="line">        //根据0-1之间的x，y的权重计算公式计算权重，权重与坐标具体位置无关，与坐标间的差值有关</div><div class="line">        float w1 = (1-tx) * (1-ty);</div><div class="line">        float w2 =    tx  * (1-ty);</div><div class="line">        float w3 = (1-tx) *    ty;</div><div class="line">        float w4 =    tx  *    ty;</div><div class="line">        //循环处理每个像素</div><div class="line">        for(int i=radius;i&lt;src.rows-radius;i++)</div><div class="line">        &#123;</div><div class="line">            for(int j=radius;j&lt;src.cols-radius;j++)</div><div class="line">            &#123;</div><div class="line">                //获得中心像素点的灰度值</div><div class="line">                _tp center = src.at&lt;_tp&gt;(i,j);</div><div class="line">                //根据双线性插值公式计算第k个采样点的灰度值</div><div class="line">                float neighbor = src.at&lt;_tp&gt;(i+x1,j+y1) * w1 + src.at&lt;_tp&gt;(i+x1,j+y2) *w2 \</div><div class="line">                    + src.at&lt;_tp&gt;(i+x2,j+y1) * w3 +src.at&lt;_tp&gt;(i+x2,j+y2) *w4;</div><div class="line">                //LBP特征图像的每个邻居的LBP值累加，累加通过与操作完成，对应的LBP值通过移位取得</div><div class="line">                dst.at&lt;uchar&gt;(i-radius,j-radius) |= (neighbor&gt;center) &lt;&lt;(neighbors-k-1);</div><div class="line">                //进行LBP特征的UniformPattern编码</div><div class="line">                if(flag)</div><div class="line">                &#123;</div><div class="line">                    dst.at&lt;uchar&gt;(i-radius,j-radius) = table[dst.at&lt;uchar&gt;(i-radius,j-radius)];</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">//计算跳变次数</div><div class="line">int getHopTimes(int n)</div><div class="line">&#123;</div><div class="line">    int count = 0;</div><div class="line">    bitset&lt;8&gt; binaryCode = n;</div><div class="line">    for(int i=0;i&lt;8;i++)</div><div class="line">    &#123;</div><div class="line">        if(binaryCode[i] != binaryCode[(i+1)%8])</div><div class="line">        &#123;</div><div class="line">            count++;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    return count;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>此外，旋转不变的Uniform LBP算子的等价模式类的数目为P+1个，对于8个采样点，基于等价模式的旋转不变LBP模式只有9个输出，该模式对于上图的Uniform LBP，每一行都是旋转不变的，对应同一个编码值。</p>
<h3 id="多尺度LBP-Multiscale-Block-LBP"><a href="#多尺度LBP-Multiscale-Block-LBP" class="headerlink" title="多尺度LBP(Multiscale Block LBP)"></a>多尺度LBP(Multiscale Block LBP)</h3><p>&emsp;&emsp;基本LBP算子获取的是单个像素和其邻域像素间的纹理信息，属于微观特征。中科院的研究人员针对此提出了一种多尺度的LBP算子，将图像分为一个个块(block)，再将每个块分为一个个的小连通区域(cell)，类似于HOG特征，cell内的灰度平均值或者和值作为当前cell的灰度阈值，与邻域cell进行比较得到LBP值，生成的特征即为MB-LBP，block大小为$3 \times 3$，cell大小为1，就是原始的LBP特征。下图所示block为$9 \times 9$，cell为$3 \times 3$。</p>
<p><img src="https://ooo.0o0.ooo/2017/06/13/593f4e9ec38c4.jpg" alt="MB-LBP.jpg" title="MB-LBP特征"></p>
<p>MB-LBP特征的实现代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">//MB-LBP特征的计算</div><div class="line">void getMultiScaleBlockLBPFeature(InputArray _src,OutputArray _dst,int scale)</div><div class="line">&#123;</div><div class="line">    Mat src = _src.getMat();</div><div class="line">    Mat dst = _dst.getMat();</div><div class="line">    //定义并计算积分图像</div><div class="line">    int cellSize = scale / 3;</div><div class="line">    int offset = cellSize / 2;</div><div class="line">    Mat cellImage(src.rows-2*offset,src.cols-2*offset,CV_8UC1);</div><div class="line">    for(int i=offset;i&lt;src.rows-offset;i++)</div><div class="line">    &#123;</div><div class="line">        for(int j=offset;j&lt;src.cols-offset;j++)</div><div class="line">        &#123;</div><div class="line">            int temp = 0;</div><div class="line">            for(int m=-offset;m&lt;offset+1;m++)</div><div class="line">            &#123;</div><div class="line">                for(int n=-offset;n&lt;offset+1;n++)</div><div class="line">                &#123;</div><div class="line">                    temp += src.at&lt;uchar&gt;(i+n,j+m);</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">            temp /= (cellSize*cellSize);</div><div class="line">            cellImage.at&lt;uchar&gt;(i-cellSize/2,j-cellSize/2) = uchar(temp); </div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    getOriginLBPFeature&lt;uchar&gt;(cellImage,dst);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>多尺度模式下同样用到了降维，论文中是直接采样统计的方法对不同尺度的LBP算子的模式进行统计，选取占比例较高的模式，而不是利用跳变规则。具体来说，就是将得到的MB-LBP特征计算统计直方图，通过对bin中的数值进行排序以及权衡，将排序在前N(63)位的特征值看作是等价模式类，其余的为混合模式类，总共为N+1类，论文中称之为(SEMB-LBP, Statistically Effective MB-LBP)。<br>SEMB-LBP的实现代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div></pre></td><td class="code"><pre><div class="line">//求SEMB-LBP</div><div class="line">void SEMB_LBPFeature(InputArray _src,OutputArray _dst,int scale)</div><div class="line">&#123;</div><div class="line">    Mat dst=_dst.getMat();</div><div class="line">    Mat MB_LBPImage;</div><div class="line">    getMultiScaleBlockLBPFeature(_src,MB_LBPImage,scale);</div><div class="line">    //imshow(&quot;dst&quot;,dst);</div><div class="line">    Mat histMat;</div><div class="line">    int histSize = 256;</div><div class="line">    float range[] = &#123;float(0),float(255)&#125;;</div><div class="line">    const float* ranges = &#123;range&#125;;</div><div class="line">    //计算LBP特征值0-255的直方图</div><div class="line">    calcHist(&amp;MB_LBPImage,1,0,Mat(),histMat,1,&amp;histSize,&amp;ranges,true,false);</div><div class="line">    histMat.reshape(1,1);</div><div class="line">    vector&lt;float&gt; histVector(histMat.rows*histMat.cols);</div><div class="line">    uchar table[256];</div><div class="line">    memset(table,64,256);</div><div class="line">    if(histMat.isContinuous())</div><div class="line">    &#123;</div><div class="line">        //histVector = (int *)(histMat.data);</div><div class="line">        //将直方图histMat变为vector向量histVector</div><div class="line">        histVector.assign((float*)histMat.datastart,(float*)histMat.dataend);</div><div class="line">        vector&lt;float&gt; histVectorCopy(histVector);</div><div class="line">        //对histVector进行排序，即对LBP特征值的数量进行排序，降序排列</div><div class="line">        sort(histVector.begin(),histVector.end(),greater&lt;float&gt;());</div><div class="line">        for(int i=0;i&lt;63;i++)</div><div class="line">        &#123;</div><div class="line">            for(int j=0;j&lt;histVectorCopy.size();j++)</div><div class="line">            &#123;</div><div class="line">                if(histVectorCopy[j]==histVector[i])</div><div class="line">                &#123;</div><div class="line">                    //得到类似于Uniform的编码表</div><div class="line">                    table[j]=i;</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    dst = MB_LBPImage;</div><div class="line">    //根据编码表得到SEMB-LBP</div><div class="line">    for(int i=0;i&lt;dst.rows;i++)</div><div class="line">    &#123;</div><div class="line">        for(int j=0;j&lt;dst.cols;j++)</div><div class="line">        &#123;</div><div class="line">            dst.at&lt;uchar&gt;(i,j) = table[dst.at&lt;uchar&gt;(i,j)];</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="图像的LBP特征向量-Local-Binary-Patterns-Histograms"><a href="#图像的LBP特征向量-Local-Binary-Patterns-Histograms" class="headerlink" title="图像的LBP特征向量(Local Binary Patterns Histograms)"></a>图像的LBP特征向量(Local Binary Patterns Histograms)</h3><p>&emsp;&emsp;对图像中的每个像素求取LBP特征值可得到图像的LBP特征图谱，但一般不直接将LBP图谱作为特征向量用于分类识别，而是类似于HOG特征，采用LBP特征的统计直方图作为特征向量。将LBP特征图谱划分为若干个子连通区域，并提取每个局部块的直方图，然后将这些直方图一次连接在一起形成LBP特征的统计直方图(LBPH)，即可用于分类识别的LBP特征向量。<br>LBP特征向量的具体计算过程如下：</p>
<ul>
<li>按照上述算法计算图像的LBP特征图谱</li>
<li>将LBP特征图谱分块，例如分成$8 \times 8 = 64$个区域</li>
<li>计算每个子区域中LBP特征值的统计直方图，并进行归一化，直方图大小为$1 \times numPatterns$</li>
<li>将所有区域的统计直方图按空间顺序依次连接，得到整幅图像的LBP特征向量，大小为$1 \times (numPatterns \times 64)$</li>
<li>从足够数量的样本中提取LBP特征，并利用机器学习的方法进行训练得到模型，用于分类和识别等领域。  </li>
</ul>
<p>&emsp;&emsp;对于LBP特征向量的维度，邻域采样点为8个，如果是原始的LBP特征，其模式数量为256，特征维数为$64 \times 256 = 16384$；如果是Uniform LBP特征，其模式数量为59，特征维数为$64 \times 59 = 3776$，使用等价模式特征，可以有效进行数据降维，而对模型性能却无较大影响。<br>LBP特征向量的实现代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div></pre></td><td class="code"><pre><div class="line">//计算LBP特征图像的直方图LBPH</div><div class="line">Mat getLBPH(InputArray _src,int numPatterns,int grid_x,int grid_y,bool normed)</div><div class="line">&#123;</div><div class="line">    Mat src = _src.getMat();</div><div class="line">    int width = src.cols / grid_x;</div><div class="line">    int height = src.rows / grid_y;</div><div class="line">    //定义LBPH的行和列，grid_x*grid_y表示将图像分割成这么些块，numPatterns表示LBP值的模式种类</div><div class="line">    Mat result = Mat::zeros(grid_x * grid_y,numPatterns,CV_32FC1);</div><div class="line">    if(src.empty())</div><div class="line">    &#123;</div><div class="line">        return result.reshape(1,1);</div><div class="line">    &#125;</div><div class="line">    int resultRowIndex = 0;</div><div class="line">    //对图像进行分割，分割成grid_x*grid_y块，grid_x，grid_y默认为8</div><div class="line">    for(int i=0;i&lt;grid_x;i++)</div><div class="line">    &#123;</div><div class="line">        for(int j=0;j&lt;grid_y;j++)</div><div class="line">        &#123;</div><div class="line">            //图像分块</div><div class="line">            Mat src_cell = Mat(src,Range(i*height,(i+1)*height),Range(j*width,(j+1)*width));</div><div class="line">            //计算直方图</div><div class="line">            Mat hist_cell = getLocalRegionLBPH(src_cell,0,(numPattern-1),true);</div><div class="line">            //将直方图放到result中</div><div class="line">            Mat rowResult = result.row(resultRowIndex);</div><div class="line">            hist_cell.reshape(1,1).convertTo(rowResult,CV_32FC1);</div><div class="line">            resultRowIndex++;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    return result.reshape(1,1);</div><div class="line">&#125;</div><div class="line"></div><div class="line">//计算一个LBP特征图像块的直方图</div><div class="line">Mat getLocalRegionLBPH(const Mat&amp; src,int minValue,int maxValue,bool normed)</div><div class="line">&#123;</div><div class="line">    //定义存储直方图的矩阵</div><div class="line">    Mat result;</div><div class="line">    //计算得到直方图bin的数目，直方图数组的大小</div><div class="line">    int histSize = maxValue - minValue + 1;</div><div class="line">    //定义直方图每一维的bin的变化范围</div><div class="line">    float range[] = &#123; static_cast&lt;float&gt;(minValue),static_cast&lt;float&gt;(maxValue + 1) &#125;;</div><div class="line">    //定义直方图所有bin的变化范围</div><div class="line">    const float* ranges = &#123; range &#125;;</div><div class="line">    //计算直方图，src是要计算直方图的图像，1是要计算直方图的图像数目，0是计算直方图所用的图像的通道序号，从0索引</div><div class="line">    //Mat()是要用的掩模，result为输出的直方图，1为输出的直方图的维度，histSize直方图在每一维的变化范围</div><div class="line">    //ranges，所有直方图的变化范围（起点和终点）</div><div class="line">    calcHist(&amp;src,1,0,Mat(),result,1,&amp;histSize,&amp;ranges,true,false);</div><div class="line">    //归一化</div><div class="line">    if(normed)</div><div class="line">    &#123;</div><div class="line">        result /= (int)src.total();</div><div class="line">    &#125;</div><div class="line">    //结果表示成只有1行的矩阵</div><div class="line">    return result.reshape(1,1);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;除了以上几种比较经典的LBP特征外，还有诸多变种，如TLBP(中心像素与周围所有像素比较，而不是根据采样点的数目)，DLBP(编码4邻域的灰度变化，每个方向上用两个比特编码)，MLBP(将中心像素值替换为采样点像素的平均值)，VLBP，RGB-LBP等。</p>
<h3 id="LBP特征的应用"><a href="#LBP特征的应用" class="headerlink" title="LBP特征的应用"></a>LBP特征的应用</h3><h4 id="目标检测"><a href="#目标检测" class="headerlink" title="目标检测"></a>目标检测</h4><p>&emsp;&emsp;人脸检测中比较典型的模型是Haar特征 + AdaBoost分类器，目前OpenCV也支持LBP + AdaBoost和HOG + AdaBoost的方法进行目标检测，而且LBP特征的训练速度较快，适用于实时检测场景。</p>
<h4 id="人脸识别"><a href="#人脸识别" class="headerlink" title="人脸识别"></a>人脸识别</h4><p>&emsp;&emsp;人脸识别中LBP特征向量主要是用于直方图的比较，通过距离度量的方式(例如方差)找到训练数据中与输入图像距离最小的特征向量，将其对应的类别作为识别结果输出。</p>
<h3 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h3><ul>
<li><a href="https://pdfs.semanticscholar.org/8e01/f162182365c7a275fb6b7ecaafe7b9719673.pdf" target="_blank" rel="external">Paper: Gray Scale and Rotation Invariant Texture Classification with Local Binary Patterns</a></li>
<li><a href="https://pdfs.semanticscholar.org/33fa/d977a6b317cfd6ecd43d978687e0df8a7338.pdf" target="_blank" rel="external">Paper: Multiresolution Gray Scale and Rotation Invariant Texture Classification with Local Binary Patterns</a></li>
<li><a href="http://www.ee.oulu.fi/mvg/files/pdf/pdf_494.pdf" target="_blank" rel="external">Paper: Face Recognition with Local Binary Patterns</a></li>
<li><a href="http://www.cbsr.ia.ac.cn/users/lzhang/papers/ICB07/ICB07_Liao.pdf" target="_blank" rel="external">Paper: Learning Multi-scale Block Local Binary Patterns for Face Recognition</a></li>
<li><a href="http://www.voidcn.com/blog/quincuntial/article/p-4988349.html" target="_blank" rel="external">http://www.voidcn.com/blog/quincuntial/article/p-4988349.html</a></li>
<li><a href="http://blog.csdn.net/zouxy09/article/details/7929531" target="_blank" rel="external">http://blog.csdn.net/zouxy09/article/details/7929531</a></li>
<li><a href="http://blog.jasonding.top/2014/11/04/Machine%20Learning/%E3%80%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E3%80%91LBP%E7%BA%B9%E7%90%86%E7%89%B9%E5%BE%81/" target="_blank" rel="external">http://blog.jasonding.top/2014/11/04/Machine%20Learning/%E3%80%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E3%80%91LBP%E7%BA%B9%E7%90%86%E7%89%B9%E5%BE%81/</a></li>
<li><a href="http://blog.csdn.net/liulina603/article/details/8291105" target="_blank" rel="external">http://blog.csdn.net/liulina603/article/details/8291105</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp;局部二值模式(Local Binary Patter, LBP)是一种用来描述图像局部纹理特征的算子，LBP特征具有灰度不变性和旋转不变性等显著优点，它将图像中的各个像素与其邻域像素值进行比较，将结果保存为二进制数，并将得到的二进制比特串作为中心像素的编码值，也就是LBP特征值。LBP提供了一种衡量像素间邻域关系的特征模式，因此可以有效地提取图像的局部特征，而且由于其计算简单，可用于基于纹理分类的实时应用场景，例如目标检测、人脸识别等。&lt;br&gt;
    
    </summary>
    
      <category term="Algorithm" scheme="https://senitco.github.io/categories/Algorithm/"/>
    
    
      <category term="Image" scheme="https://senitco.github.io/tags/Image/"/>
    
  </entry>
  
  <entry>
    <title>图像特征提取之HOG特征</title>
    <link href="https://senitco.github.io/2017/06/08/image-feature-hog/"/>
    <id>https://senitco.github.io/2017/06/08/image-feature-hog/</id>
    <published>2017-06-08T10:10:40.545Z</published>
    <updated>2017-06-10T04:34:37.919Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;方向梯度直方图(Histogram of Oriented Gradient, HOG)特征是一种在计算机视觉和图像处理中用来进行物体检测的特征描述子。它通过计算和统计图像局部区域的梯度方向直方图来构成特征。Hog特征结合SVM分类器已经被广泛应用于图像识别中，尤其在行人检测中获得了极大的成功。<br><a id="more"></a></p>
<h3 id="算法思想"><a href="#算法思想" class="headerlink" title="算法思想"></a>算法思想</h3><p>&emsp;&emsp;HOG特征的核心思想是在一幅图像中，局部目标的表象和形状(appearance and shape)能够被梯度和边缘的方向密度（梯度的统计信息，而梯度主要存在于边缘地方）很好地描述。通过将整幅图像分为多个小的连通区域(cells)，并计算每个cell的梯度或边缘方向直方图，这些直方图的组合可用于构成特征描述子，为了提高准确率，可以将局部直方图在图像更大范围内(称为block)进行对比度归一化(constrast-normalized)。所采用的方法是：先计算各直方图在对应的block中的密度，然后根据这个密度对block中的所有cell做归一化(normalize)。归一化操作对光照变化和阴影具有更好的鲁棒性。</p>
<h3 id="算法特点"><a href="#算法特点" class="headerlink" title="算法特点"></a>算法特点</h3><ul>
<li>HOG特征是在图像的局部操作，对图像几何和光学的变化有较好的稳健性，这两种变化只会出现在更大的空域上。</li>
<li>在粗粒度的空域抽样、细粒度的方向抽样，以及较强的局部光学归一化条件下，只要行人大体保持直立的姿势，可以容许行人有一些细微的肢体动作，而不影响检测效果。</li>
</ul>
<h3 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h3><p>HOG特征提取的流程如下：  </p>
<h4 id="图像预处理"><a href="#图像预处理" class="headerlink" title="图像预处理"></a>图像预处理</h4><ul>
<li>灰度化：HOG提取的是纹理特征，颜色信息不起作用，所以将彩色图转化为灰度图。</li>
<li>Gamma校正(归一化)：对图像进行Gamma校正，完成对整个图像的标准化(归一化)，可以调节图像的对比度，降低局部光照不均匀或者阴影的影响，同时也可以在一定程度上降低噪声的干扰，提高特征描述器对光照等干扰因素的鲁棒性。校正公式如下：<br>$$I(x, y) = I(x, y)^{\gamma}, \gamma = \dfrac{1}{2}$$</li>
</ul>
<h4 id="计算图像梯度"><a href="#计算图像梯度" class="headerlink" title="计算图像梯度"></a>计算图像梯度</h4><p>&emsp;&emsp;分别求取图像水平方向和垂直方向的梯度，然后计算每个像素点的梯度幅值和方向，微分求图像梯度不仅可以捕获图像边缘和纹理信息，而且可以弱化光照不均匀的影响。<br>$$G_x(x,y) = I(x+1,y) - I(x-1,y)$$<br>$$G_y(x,y) = I(x,y+1) - I(x,y-1)$$<br>$$\nabla G(x,y) = \sqrt{G_x(x,y)^2+G_y(x,y)^2}$$<br>$$theta(x,y) = arctan(G_y(x,y) / G_x(x,y))$$<br>一般采用梯度算子对图像进行卷积运算求取图像梯度，例如用$[-1,0,1]$梯度算子对图像进行卷积操作得到水平方向的梯度分量，用$[-1,0,1]^T$梯度算子进行卷积操作得到竖直方向的梯度分量，然后求取图像的梯度幅值和方向。</p>
<h4 id="在cell中计算梯度方向直方图-Orientation-binning"><a href="#在cell中计算梯度方向直方图-Orientation-binning" class="headerlink" title="在cell中计算梯度方向直方图(Orientation binning)"></a>在cell中计算梯度方向直方图(Orientation binning)</h4><p>&emsp;&emsp;将图像划分为若干个连通区域(cell)，例如每个cell为$8\times 8$个像素，相邻cell之间不重叠，将所有梯度方向划分为9个方向块(bin)，然后在每个cell内统计梯度方向直方图。在计算梯度方向时，可把方向的角度范围定位$(0, 180^{\circ})$或者$(0, 360^{\circ})$。最后每个cell都对应一个9维的特征向量。此外，还可以考虑梯度幅值作为bin的统计权重。<br>&emsp;&emsp;在行人检测中，通过给局部图像区域进行编码，可以保持对目标对象的姿势和外观的弱敏感性，更好地捕获图像的轮廓和纹理信息。</p>
<h4 id="在block中归一化梯度方向直方图-Block-Normalization"><a href="#在block中归一化梯度方向直方图-Block-Normalization" class="headerlink" title="在block中归一化梯度方向直方图(Block Normalization)"></a>在block中归一化梯度方向直方图(Block Normalization)</h4><p>&emsp;&emsp;将多个cell组合成更大连通块(block)，将block内所有cell的特征向量串联起来便得到该block的HOG特征描述子，不同block之间可能相互重叠，可以有效地利用局部邻域信息。类比在卷积神经网络(CNN)中，掩码(Kernel)和步长(stride)的选择。在跟大范围内(block)统计梯度直方图，并做归一化处理，能够更好地适应光照和对比度的变化。常用的归一化方法有以下几种：</p>
<ul>
<li>L2-norm<br>$$v = \dfrac{v}{\left|v\right|_{2}^{2} + \varepsilon^2}$$</li>
<li>L1-norm<br>$$v = \dfrac{v}{\left|v\right|_{1} + \varepsilon}$$</li>
<li>L1-sqrt<br>$$v = \sqrt{\dfrac{v}{\left|v\right|_{1} + \varepsilon}}$$<br>还有一种L2-Hys，即先做一次L2-norm,然后把大于特定值(0.2)的分量幅值为0.2再做一次L2-norm，一般在检测中采用L2-norm效果更好。在一个block中，如果cell的数量为$2\times 2$，那block的特征数为$2\times 2 \times 9 = 36$维特征。</li>
</ul>
<h4 id="统计整幅图像-检测窗口-的HOG特征"><a href="#统计整幅图像-检测窗口-的HOG特征" class="headerlink" title="统计整幅图像(检测窗口)的HOG特征"></a>统计整幅图像(检测窗口)的HOG特征</h4><p>&emsp;&emsp;在实际应用中，通常是选取固定大小的滑动窗口来提取HOG特征，对于一个$64\times 128$的图像窗口(window)，每$8\times 8$个像素组成一个cell，每$2\times 2$个cell组成一个block，一共有$(8-1)\times (16-1) = 105$个block，因此该图像的窗口特征维数为$105\times 36 = 3780$。当然也可以将整幅图像作为一个窗口来提取HOG特征。</p>
<h4 id="HOG特征-SVM分类器进行行人检测"><a href="#HOG特征-SVM分类器进行行人检测" class="headerlink" title="HOG特征 + SVM分类器进行行人检测"></a>HOG特征 + SVM分类器进行行人检测</h4><p>&emsp;&emsp;训练过程中正样本为图片中包含有目标区域(行人)的boundingbox，尺寸统一为检测窗口的大小即$64\times 128$，负样本不需要统一尺寸，只需比检测窗口大，且图片中不包含检测目标，可任意截取图片中$64\times 128$大小的区域提取HOG特征作为负样本的特征向量，并与正样本图片中boundingbox区域提取出的HOG特征向量一起训练，得到SVM的分类模型。<br>&emsp;&emsp;检测过程中采用滑动窗口法，检测窗口尺寸固定不变，对待检测图片进行尺度缩放，在每一层的图像上，用固定大小的滑动窗口提取HOG特征，并根据训练好的分类模型判断检测窗口是否为目标(行人)。因此HOG + SVM进行行人检测的过程实际上就是对图像的检测窗口提取HOG特征进行分类判决的过程。  </p>
<h3 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h3><ul>
<li><a href="http://lear.inrialpes.fr/people/triggs/pubs/Dalal-cvpr05.pdf" target="_blank" rel="external">paper: Histograms of Oriented Gradients for Human Detection</a></li>
<li><a href="https://en.wikipedia.org/wiki/Histogram_of_oriented_gradients" target="_blank" rel="external">wikipedia: Histogram of oriented gradients</a></li>
<li><a href="http://blog.csdn.net/zouxy09/article/details/7929348" target="_blank" rel="external">http://blog.csdn.net/zouxy09/article/details/7929348</a></li>
<li><a href="http://blog.csdn.net/hujingshuang/article/details/47337707" target="_blank" rel="external">http://blog.csdn.net/hujingshuang/article/details/47337707</a></li>
<li><a href="http://www.cnblogs.com/tornadomeet/archive/2012/08/15/2640754.html" target="_blank" rel="external">http://www.cnblogs.com/tornadomeet/archive/2012/08/15/2640754.html</a></li>
<li><a href="http://shuokay.com/2016/07/18/hog/" target="_blank" rel="external">http://shuokay.com/2016/07/18/hog/</a></li>
<li><a href="http://www.jianshu.com/p/6f69c751e9e7" target="_blank" rel="external">http://www.jianshu.com/p/6f69c751e9e7</a></li>
<li><a href="http://blog.sina.com.cn/s/blog_60e6e3d50101bkpn.html" target="_blank" rel="external">http://blog.sina.com.cn/s/blog_60e6e3d50101bkpn.html</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp;方向梯度直方图(Histogram of Oriented Gradient, HOG)特征是一种在计算机视觉和图像处理中用来进行物体检测的特征描述子。它通过计算和统计图像局部区域的梯度方向直方图来构成特征。Hog特征结合SVM分类器已经被广泛应用于图像识别中，尤其在行人检测中获得了极大的成功。&lt;br&gt;
    
    </summary>
    
      <category term="Algorithm" scheme="https://senitco.github.io/categories/Algorithm/"/>
    
    
      <category term="Image" scheme="https://senitco.github.io/tags/Image/"/>
    
  </entry>
  
  <entry>
    <title>C/C++处理十六进制数和字符串</title>
    <link href="https://senitco.github.io/2017/06/08/string-processing/"/>
    <id>https://senitco.github.io/2017/06/08/string-processing/</id>
    <published>2017-06-08T01:53:53.621Z</published>
    <updated>2017-06-08T04:19:20.127Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;C/C++处理十六进制数和字符串小结，包括十六进制数组和字符串的相互转换，二进制字符串和十六进制数组的转换，不定长字符串的读取等。<br><a id="more"></a></p>
<h3 id="十六进制数组和字符串的相互转换"><a href="#十六进制数组和字符串的相互转换" class="headerlink" title="十六进制数组和字符串的相互转换"></a>十六进制数组和字符串的相互转换</h3><p>例如 { 0x23, 0x3A, 0x46, 0x4C, 0x52 } &lt;=&gt; “233A464C52”<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div></pre></td><td class="code"><pre><div class="line">/******************************************************************************************</div><div class="line">*	功能：将一个十六进制字节串转换成 ASCII 码表示的十六进制的字符串</div><div class="line">*	输入参数：pHex	 -- 十六进制数字节串首地址</div><div class="line">*			 pAscii -- 转换后的 ASCII 码表示的十六进制字符串的首地址</div><div class="line">*			 nLen	 -- 要转换的十六进制数的长度（字节数）</div><div class="line">*	输出参数：None</div><div class="line">*	注：	转换后的结果全部是大写 ASCII 表示的十六进制数</div><div class="line">*******************************************************************************************/</div><div class="line">void HexToAscii(unsigned char * pHex, unsigned char * pAscii, int nLen)</div><div class="line">&#123;</div><div class="line">    unsigned char Nibble[2];</div><div class="line"></div><div class="line">    for (int i = 0; i &lt; nLen; i++)</div><div class="line">    &#123;</div><div class="line">        Nibble[0] = (pHex[i] &amp; 0xF0) &gt;&gt; 4;</div><div class="line">        Nibble[1] = pHex[i] &amp; 0x0F;</div><div class="line">        for (int j = 0; j &lt; 2; j++)</div><div class="line">        &#123;</div><div class="line">            if (Nibble[j] &lt; 10)</div><div class="line">                Nibble[j] += 0x30;</div><div class="line">            else</div><div class="line">            &#123;</div><div class="line">                if (Nibble[j] &lt; 16)</div><div class="line">                    Nibble[j] = Nibble[j] - 10 + &apos;A&apos;;</div><div class="line">            &#125;</div><div class="line">            *pAscii++ = Nibble[j];</div><div class="line">        &#125;	// for (int j = ...)</div><div class="line">    &#125;	// for (int i = ...)</div><div class="line">&#125;</div><div class="line"></div><div class="line">/******************************************************************************************</div><div class="line">*	功能：将一个 ASCII 码表示的十六进制字符串转换成十六进制的字节串</div><div class="line">*	输入参数：pAscii -- 转换后的 ASCII 码表示的十六进制字符串的首地址</div><div class="line">*			 pHex	-- 十六进制数字节串首地址</div><div class="line">*			 nLen	-- 要转换的 ASCII 码表示的十六进制字符串的长度（字节数）</div><div class="line">*	输出参数：None</div><div class="line">*	注：	要求输入的 ASCII 码表示的十六进制数的字符个数必须为偶数，除了是1 - 9 和 A(a) - F(f) 以外没有别的字符</div><div class="line">*******************************************************************************************/</div><div class="line">void AsciiToHex(unsigned char * pAscii, unsigned char * pHex, int nLen)</div><div class="line">&#123;</div><div class="line">    if (nLen % 2)</div><div class="line">        return;</div><div class="line">    int nHexLen = nLen / 2;</div><div class="line"></div><div class="line">    for (int i = 0; i &lt; nHexLen; i++)</div><div class="line">    &#123;</div><div class="line">        unsigned char Nibble[2];</div><div class="line">        Nibble[0] = *pAscii++;</div><div class="line">        Nibble[1] = *pAscii++;</div><div class="line">        for (int j = 0; j &lt; 2; j++)</div><div class="line">        &#123;</div><div class="line">            if (Nibble[j] &lt;= &apos;F&apos; &amp;&amp; Nibble[j] &gt;= &apos;A&apos;)</div><div class="line">                Nibble[j] = Nibble[j] - &apos;A&apos; + 10;</div><div class="line">            else if (Nibble[j] &lt;= &apos;f&apos; &amp;&amp; Nibble[j] &gt;= &apos;a&apos;)</div><div class="line">                Nibble[j] = Nibble[j] - &apos;a&apos; + 10;</div><div class="line">            else if (Nibble[j] &gt;= &apos;0&apos; &amp;&amp; Nibble[j] &lt;= &apos;9&apos;)</div><div class="line">                Nibble[j] = Nibble[j] - &apos;0&apos;;</div><div class="line">            else</div><div class="line">                return;</div><div class="line">        &#125;	// for (int j = ...)</div><div class="line">        pHex[i] = Nibble[0] &lt;&lt; 4;	// Set the high nibble</div><div class="line">        pHex[i] |= Nibble[1];	//Set the low nibble</div><div class="line">    &#125;	// for (int i = ...)</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="十六进制数组和二进制字符串的相互转换"><a href="#十六进制数组和二进制字符串的相互转换" class="headerlink" title="十六进制数组和二进制字符串的相互转换"></a>十六进制数组和二进制字符串的相互转换</h3><p>例如 { 0x23, 0x4A, 0x5E } &lt;=&gt; “001000110100101001011110”<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div></pre></td><td class="code"><pre><div class="line">/***十六进制数转换成二进制字符串***/</div><div class="line">void HexToBinStr(unsigned char* hexStr, unsigned char* binStr, int lenHex)</div><div class="line">&#123;</div><div class="line">    memset(binStr, &apos;0&apos;, lenHex * 8);</div><div class="line">    unsigned char hexChar[2];</div><div class="line">    for (int i = 0; i &lt; lenHex; i++)</div><div class="line">    &#123;</div><div class="line">        hexChar[0] = (hexStr[i] &amp; 0xF0) &gt;&gt; 4;</div><div class="line">        hexChar[1] = hexStr[i] &amp; 0x0F;</div><div class="line">        for (int j = 0; j &lt; 2; j++)</div><div class="line">        &#123;</div><div class="line">            for (int k = 0; k &lt; 4; k++)</div><div class="line">            &#123;</div><div class="line">                if (hexChar[j] &amp; (0x08 &gt;&gt; k))</div><div class="line">                &#123;</div><div class="line">                    binStr[8 * i + 4 * j + k] = &apos;1&apos;;</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">/***二进制字符串转换成十六进制数***/</div><div class="line">void BinStrToHex(unsigned char* binStr, unsigned char* hexStr, int lenBin)</div><div class="line">&#123;</div><div class="line">    int lenHex = lenBin / 8;</div><div class="line">    memset(hexStr, &apos;\0&apos;, lenHex);</div><div class="line">    unsigned char hexChar[2];</div><div class="line">    for (int i = 0; i &lt; lenHex; i++)</div><div class="line">    &#123;</div><div class="line">        for (int j = 0; j &lt; 2; j++)</div><div class="line">        &#123;</div><div class="line">            hexChar[j] = 0;</div><div class="line">            for (int k = 0; k &lt; 4; k++)</div><div class="line">            &#123;</div><div class="line">                if (binStr[8 * i + 4 * j + k] == &apos;1&apos;)</div><div class="line">                &#123;</div><div class="line">                    hexChar[j] |= (0x08 &gt;&gt; k);</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        hexStr[i] = ((hexChar[0] &amp; 0x0F) &lt;&lt; 4) | (hexChar[1] &amp; 0x0F);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="读取不定长字符串"><a href="#读取不定长字符串" class="headerlink" title="读取不定长字符串"></a>读取不定长字符串</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line">/*******************读取不定长字符串******************/</div><div class="line">unsigned char* getlineStr()</div><div class="line">&#123;</div><div class="line">	int nByte = 50;</div><div class="line">    char * line = (char *)malloc(nByte), *linep = line;</div><div class="line">    size_t lenmax = nByte, len = lenmax;</div><div class="line">    int c;</div><div class="line"></div><div class="line">    if (line == NULL)</div><div class="line">        return NULL;</div><div class="line"></div><div class="line">    for (;;)</div><div class="line">    &#123;</div><div class="line">        c = fgetc(stdin);</div><div class="line">        if (c == EOF)</div><div class="line">            break;</div><div class="line"></div><div class="line">        if (--len == 0)</div><div class="line">        &#123;</div><div class="line">            len = lenmax;</div><div class="line">            char * linen = (char *)realloc(linep, lenmax *= 2);</div><div class="line"></div><div class="line">            if (linen == NULL)</div><div class="line">            &#123;</div><div class="line">                free(linep);</div><div class="line">                return NULL;</div><div class="line">            &#125;</div><div class="line">            line = linen + (line - linep);</div><div class="line">            linep = linen;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        if ((*line++ = c) == &apos;\n&apos;)</div><div class="line">            break;</div><div class="line">    &#125;</div><div class="line">    *--line = &apos;\0&apos;;     //用&apos;\0&apos;替换掉换行&apos;\n&apos;</div><div class="line">    return (unsigned char*)linep;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="奇偶校验"><a href="#奇偶校验" class="headerlink" title="奇偶校验"></a>奇偶校验</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">/***奇偶校验，使每个字节比特1的个数为奇数个***/</div><div class="line">void checkParity(unsigned char* srcChar, unsigned char* dstChar, int nLen)</div><div class="line">&#123;</div><div class="line">    unsigned char sinChar;</div><div class="line">    short minBit = 0;</div><div class="line">    short count = 0;</div><div class="line">    for (int i = 0; i &lt; nLen; i++)</div><div class="line">    &#123;</div><div class="line">        count = 0;</div><div class="line">        sinChar = srcChar[i];</div><div class="line">        minBit = sinChar % 2;</div><div class="line">        for (int j = 0; j &lt; 8; j++)</div><div class="line">        &#123;</div><div class="line">            if (sinChar % 2 == 1)</div><div class="line">                count++;</div><div class="line">            sinChar &gt;&gt;= 1;</div><div class="line">        &#125;</div><div class="line">        if (count % 2 == 1)</div><div class="line">            dstChar[i] = srcChar[i];</div><div class="line">        else if (minBit == 1)</div><div class="line">            dstChar[i] = srcChar[i] - 1;</div><div class="line">        else</div><div class="line">            dstChar[i] = srcChar[i] + 1;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="字节填充-nByte字节的整数倍"><a href="#字节填充-nByte字节的整数倍" class="headerlink" title="字节填充(nByte字节的整数倍)"></a>字节填充(nByte字节的整数倍)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line">/***********************************************************************************</div><div class="line">* 字节填充（8字节的整数倍）</div><div class="line">* 输入：binStr 二进制字符串; nByte 字节数</div><div class="line">* 返回：fillStr 填充后的字符串</div><div class="line">* 填充方法：在最右端填充一个‘1’位，之后再填充若干‘0’，直到该数据的最终字节数为 nByte 的整数倍</div><div class="line">************************************************************************************/</div><div class="line">unsigned char* fillByte(unsigned char* binStr, int nByte)</div><div class="line">&#123;</div><div class="line">    int nBit = nByte * 8;</div><div class="line">    int len1 = 0, len2 = 0;</div><div class="line">    unsigned char* fillStr;</div><div class="line">    unsigned char* tmpStr;</div><div class="line">    if (strlen((const char*)binStr) % nBit == 0)</div><div class="line">    &#123;</div><div class="line">        len1 = nBit;</div><div class="line">    &#125;</div><div class="line">    else</div><div class="line">    &#123;</div><div class="line">        len1 = nBit - strlen((const char*)binStr) % nBit;</div><div class="line">    &#125;</div><div class="line">    len2 = strlen((const char*)binStr) + len1;</div><div class="line">    tmpStr = (unsigned char*)malloc((len1 + 1) * sizeof(unsigned char));</div><div class="line">    fillStr = (unsigned char*)malloc((len2 + 1) * sizeof(unsigned char));</div><div class="line">    if (fillStr == NULL)</div><div class="line">    &#123;</div><div class="line">        printf(&quot;allocation failture\n&quot;);</div><div class="line">        exit(0);</div><div class="line">    &#125;</div><div class="line">    memset(tmpStr, &apos;0&apos;, len1);</div><div class="line">    tmpStr[0] = &apos;1&apos;;</div><div class="line">    tmpStr[len1] = &apos;\0&apos;;</div><div class="line"></div><div class="line">    memcpy(fillStr, binStr, strlen((const char*)binStr));</div><div class="line">    memcpy(fillStr + strlen((const char*)binStr), tmpStr, len1);</div><div class="line">    fillStr[len2] = &apos;\0&apos;;</div><div class="line"></div><div class="line">    return fillStr;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="以十六进制数形式读取文件"><a href="#以十六进制数形式读取文件" class="headerlink" title="以十六进制数形式读取文件"></a>以十六进制数形式读取文件</h3><p>文件是以字符形式读取的，因此需要转换为对应的十六进制数(例如”5C”-&gt;0x5C)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div></pre></td><td class="code"><pre><div class="line">/*****************单个字符转为数字(&apos;A&apos;-&gt;10)*******************/</div><div class="line">static unsigned int hex_char_to_dec(char c)</div><div class="line">&#123;</div><div class="line">    if (&apos;0&apos; &lt;= c &amp;&amp; c &lt;= &apos;9&apos;)</div><div class="line">    &#123;</div><div class="line">        return (c - &apos;0&apos;);</div><div class="line">    &#125;</div><div class="line">    else if (&apos;a&apos; &lt;= c &amp;&amp; c &lt;= &apos;f&apos;)</div><div class="line">    &#123;</div><div class="line">        return (c - &apos;a&apos; + 10);</div><div class="line">    &#125;</div><div class="line">    else if (&apos;A&apos; &lt;= c &amp;&amp; c &lt;= &apos;F&apos;)</div><div class="line">    &#123;</div><div class="line">        return (c - &apos;A&apos; + 10);</div><div class="line">    &#125;</div><div class="line">    else</div><div class="line">    &#123;</div><div class="line">        return -1;</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">/************两个字符转为一个16进制数(&quot;4B&quot;-&gt;0x4B)**************/</div><div class="line">static unsigned int str_to_hex(const char *str)</div><div class="line">&#123;</div><div class="line">    return (str[1] == &apos;\0&apos;) ? hex_char_to_dec(str[0]) : hex_char_to_dec(str[0]) * 16 + hex_char_to_dec(str[1]);</div><div class="line">&#125;</div><div class="line"></div><div class="line">/*</div><div class="line">*对字符串inputString按tag字符分割</div><div class="line">*返回vector&lt;string&gt;格式的一维向量</div><div class="line">*/</div><div class="line">vector&lt;string&gt; split(string inputString, char tag)</div><div class="line">&#123;</div><div class="line">    int length = inputString.length();</div><div class="line">    int start = 0;//数值起始下标</div><div class="line">    vector&lt;string&gt; line;</div><div class="line">    for (int i = 0; i&lt;length; i++)</div><div class="line">    &#123;</div><div class="line">        if (inputString[i] == tag)</div><div class="line">        &#123;//遇到tag字符</div><div class="line">            string sub = inputString.substr(start, i - start);    //取inputString[start]-inputString[i]子串</div><div class="line">            line.push_back(sub);//压入向量中</div><div class="line">            start = i + 1;</div><div class="line">        &#125;</div><div class="line">        else if (i == length - 1)</div><div class="line">        &#123;</div><div class="line">            string sub = inputString.substr(start, i - start + 1);//最后一个字符没有标点，需单独处理</div><div class="line">            line.push_back(sub);//压入向量中</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    return line;</div><div class="line">&#125;</div><div class="line"></div><div class="line">/*</div><div class="line">*读取绝对路径为filePath的文件，文件中每行中的数值以tag字符分开</div><div class="line">*返回字节数</div><div class="line">*/</div><div class="line">int readFile(char tag, string filePath, unsigned char* data)</div><div class="line">&#123;</div><div class="line">    ifstream fileReader;</div><div class="line">    fileReader.open(filePath, ios::in);//以只读方式打开</div><div class="line">    vector&lt;vector&lt;string&gt;&gt; vecData;//以2维向量的形势保持整个文件</div><div class="line">    int i = 0;</div><div class="line">    while (!fileReader.eof())</div><div class="line">    &#123;//未到文件末尾    </div><div class="line">        string linestring;</div><div class="line">        getline(fileReader, linestring);//读取一行</div><div class="line">        vector&lt;string&gt; line = split(linestring, tag);//分割每行,并放在line向量中    </div><div class="line">        for (vector&lt;string&gt;::iterator iter = line.begin(); iter != line.end(); iter++)</div><div class="line">        &#123;</div><div class="line">            data[i] = str_to_hex(iter-&gt;c_str());</div><div class="line">            i++;</div><div class="line">        &#125;</div><div class="line">        vecData.push_back(line);</div><div class="line">    &#125;</div><div class="line">    //return vecData;</div><div class="line">    return i + 1;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp;C/C++处理十六进制数和字符串小结，包括十六进制数组和字符串的相互转换，二进制字符串和十六进制数组的转换，不定长字符串的读取等。&lt;br&gt;
    
    </summary>
    
      <category term="coding" scheme="https://senitco.github.io/categories/coding/"/>
    
    
      <category term="C/C++" scheme="https://senitco.github.io/tags/C-C/"/>
    
  </entry>
  
  <entry>
    <title>字符编码：Unicode、UTF-8、GBK</title>
    <link href="https://senitco.github.io/2017/06/08/character-encoding/"/>
    <id>https://senitco.github.io/2017/06/08/character-encoding/</id>
    <published>2017-06-08T01:07:19.479Z</published>
    <updated>2017-06-08T01:54:22.203Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;在coding过程中会时不时地遇到字符集的编码问题，之前就一直没弄清楚过，很是头疼，因此查阅了一些资料，并对各种字符集(Ascii、Unicode、GB2312)、编码(UTF8、GBK)以及不同编码之间的转换做一个简单的总结。<br><a id="more"></a></p>
<h3 id="字符集-Charcater-Set-与字符编码-Encoding"><a href="#字符集-Charcater-Set-与字符编码-Encoding" class="headerlink" title="字符集(Charcater Set)与字符编码(Encoding)"></a>字符集(Charcater Set)与字符编码(Encoding)</h3><p><strong>字符集</strong>(Charcater Set 或 Charset)：是一个系统支持的所有抽象字符的集合，也就是一系列字符的集合。字符是各种文字和符号的总称，包括各国家文字、标点符号、图形符号、数字等。常见的字符集有： ASCII 字符集、Unicode 字符集等。<br><strong>字符编码</strong>(Character Encoding)：是一套法则，使用该法则能够对自然语言的字符的一个字符集（如字母表或音节表），与计算机能识别的二进制数字进行配对。即它能在符号集合与数字系统之间建立对应关系，是信息处理的一项基本技术。通常人们用符号集合（一般情况下就是文字）来表达信息，而计算机的信息处理系统则是以二进制的数字来存储和处理信息的。字符编码就是将符号转换为计算机能识别的二进制编码。<br>&emsp;&emsp;一般一个字符集等同于一个编码方式，ANSI 体系( ANSI 是一种字符代码，为使计算机支持更多语言，通常使用 0x80~0xFF 范围的 2 个字节来表示 1 个字符)的字符集如 ASCII、ISO 8859-1、GB2312、 GBK 等等都是如此。一般我们说一种编码都是针对某一特定的字符集。一个字符集上也可以有多种编码方式，例如 UCS 字符集(也是 Unicode 使用的字符集)上有 UTF-8、UTF-16、UTF-32 等编码方式。<br>从计算机字符编码的发展历史角度来看，大概经历了三个阶段： </p>
<ul>
<li>第一个阶段：ASCII 字符集和 ASCII 编码。 计算机刚开始只支持英语(即拉丁字符)，其它语言不能够在计算机上存储和显示。ASCII 用一个字节( Byte )的 7 位(bit)表示一个字符，第一位置 0。后来为了表示更多的欧洲常用字符又对 ASCII 进行了扩展，又有了 EASCII，EASCII 用 8 位表示一个字符，使它能多表示 128 个字符，支持了部分西欧字符。  </li>
<li>第二个阶段：ANSI 编码（本地化） 为使计算机支持更多语言，通常使用 0x80~0xFF 范围的 2 个字节来表示 1 个字符。比如：汉字 ‘中’ 在中文操作系统中，使用 [0xD6,0xD0] 这两个字节存储。 不同的国家和地区制定了不同的标准，由此产生了 GB2312, BIG5, JIS 等各自的编码标准。这些使用 2 个字节来代表一个字符的各种汉字延伸编码方式，称为 ANSI 编码。在简体中文系统下，ANSI 编码代表 GB2312 编码，在日文操作系统下，ANSI 编码代表 JIS 编码。 不同 ANSI 编码之间互不兼容，当信息在国际间交流时，无法将属于两种语言的文字，存储在同一段 ANSI 编码的文本中。  </li>
<li>第三个阶段：UNICODE（国际化） 为了使国际间信息交流更加方便，国际组织制定了 UNICODE 字符集，为各种语言中的每一个字符设定了统一并且唯一的数字编号，以满足跨语言、跨平台进行文本转换、处理的要求。UNICODE 常见的有三种编码方式:UTF-8、UTF-16、UTF-32。<br>下面是用一个树状图表示的由ASCII发展而来的各个字符集和编码的分支：<br><img src="https://ooo.0o0.ooo/2017/06/07/59380c714cbe2.png" alt="charset.png" title="字符集和字符编码树状图">  </li>
</ul>
<h3 id="ASCII、Unicode字符集"><a href="#ASCII、Unicode字符集" class="headerlink" title="ASCII、Unicode字符集"></a>ASCII、Unicode字符集</h3><h4 id="ASCII码"><a href="#ASCII码" class="headerlink" title="ASCII码"></a>ASCII码</h4><p>&emsp;&emsp;在计算机内部，所有的信息最终都表示为一个二进制的字符串。每一个二进制位（bit）有0和1两种状态，因此八个二进制位就可以组合出256种状态，这被称为一个字节（byte）。也就是说，一个字节一共可以用来表示256种不同的状态，每一个状态对应一个符号，就是256个符号，从0000000到11111111。ASCII码一共规定了128个字符的编码，比如空格”SPACE”是32（二进制00100000），大写的字母A是65（二进制01000001）。这128个符号（包括32个不能打印出来的控制符号），只占用了一个字节的后面7位，最前面的1位统一规定为0。</p>
<h4 id="非ASCII编码"><a href="#非ASCII编码" class="headerlink" title="非ASCII编码"></a>非ASCII编码</h4><p>&emsp;&emsp;英语用128个符号编码就够了，但是用来表示其他语言，128个符号是不够的。比如，在法语中，字母上方有注音符号，它就无法用ASCII码表示。于是，一些欧洲国家就决定，利用字节中闲置的最高位编入新的符号。比如，法语中的é的编码为130（二进制10000010）。这样一来，这些欧洲国家使用的编码体系，可以表示最多256个符号。但是不同的国家有不同的字母，因此会出现同一中编码对应不同字符的情况。至于亚洲国家的文字，使用的符号更多，因此用一个字节来编码字符显然是不够的，必须使用多个字节表达一个字符或符号，比如中文中常见的编码方式是GB2312，使用两个字节表示一个汉字。</p>
<h4 id="GBK编码"><a href="#GBK编码" class="headerlink" title="GBK编码"></a>GBK编码</h4><p>&emsp;&emsp;GBK是国家标准GB2312基础上扩容后兼容GB2312的标准。GBK的文字编码是用双字节来表示的，即不论中、英文字符均使用双字节来表示，为了区分中文，将其最高位都设定成1。GBK包含全部中文字符，是国家编码，通用性比UTF8差，不过UTF8占用的数据库比GBD大。GBK、GB2312等与UTF8之间都必须通过Unicode编码才能相互转换。  </p>
<h4 id="Unicode字符集"><a href="#Unicode字符集" class="headerlink" title="Unicode字符集"></a>Unicode字符集</h4><p>&emsp;&emsp;世界上存在着多种编码方式，同一个二进制数字可以被解释成不同的符号。因此，要想打开一个文本文件，就必须知道它的编码方式，否则用错误的编码方式解读，就会出现乱码。Unicode应运而生，给每个符号给予一个独一无二的编码，现在的规模可以容纳100多万个符号。Unicode的编码空间可以划分为17个平面（plane），每个平面包含2的16次方（65536）个码位。17个平面的码位可表示为从U+0000到U+10FFFF，共计1114112个码位，第一个平面称为基本多语言平面（Basic Multilingual Plane, BMP），或称第零平面（Plane 0）。其他平面称为辅助平面（Supplementary Planes）。基本多语言平面内，从U+D800到U+DFFF之间的码位区段是永久保留不映射到Unicode字符，所以有效码位为1112064个。<br>&emsp;&emsp;需要注意的是，Unicode只是一个符号集，它只规定了符号的二进制代码，却没有规定这个二进制代码应该如何存储。<br>比如，汉字“严”的unicode是十六进制数4E25，转换成二进制数足足有15位（100111000100101），也就是说这个符号的表示至少需要2个字节。表示其他更大的符号，可能需要3个字节或者4个字节，甚至更多。此外，还有两个比较严重的问题，第一个如何才能区分Unicode和ASCII？计算机如何知道三个字节表示一个符号而不是表示三个符号;第二个问题就是如果Unicode统一规定，每个符号要3个或4个字节表示，对于只需用一个字节就可以编码的英文字母，势必会浪费存储，而且文本文件也会增大不少。这两个问题导致的结果就是出现了Unicode的多种存储方式，也就是说有多种不同的二进制格式，可以用来表示Unicode。</p>
<h3 id="UTF-8、UTF-16编码以及不同编码之间的转换"><a href="#UTF-8、UTF-16编码以及不同编码之间的转换" class="headerlink" title="UTF-8、UTF-16编码以及不同编码之间的转换"></a>UTF-8、UTF-16编码以及不同编码之间的转换</h3><h4 id="UTF-8编码"><a href="#UTF-8编码" class="headerlink" title="UTF-8编码"></a>UTF-8编码</h4><p>&emsp;&emsp;UTF-8是使用较为广泛的一种Unicode实现方式，其他实现方式还包括UTF-16、UTF-32。UTF-8的最大特点就是它是一种变长的编码方式，使用1~4个字节表示一个符号，根据不同的符号而变化字节长度，UTF-8的编码规则很简单，主要有下面两点： </p>
<ul>
<li>对于单字节的符号，字节的第一位设为0，后面7位为这个符号的Unicode码，对于英文字母，UTF-8编码和ASCII码是相同的。</li>
<li>对于n字节的符号(n &gt; 1),第一个字节的前n位都设为1，第n+1位设为0，后面字节的前两位一律设为10，剩下的二进制位就是这个符号的Unicode码。<br>根据这个编码规则很容易实现Unicode和UTF-8编码之间的转换，两种编码的对应关系如下表所示： </li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:center">Unicode编码</th>
<th style="text-align:center">UTF-8编码(二进制)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">U+0000 – U+007F</td>
<td style="text-align:center">0xxxxxxx</td>
</tr>
<tr>
<td style="text-align:center">U+0080 – U+07FF</td>
<td style="text-align:center">110xxxxx 10xxxxxx</td>
</tr>
<tr>
<td style="text-align:center">U+0800 – U+FFFF</td>
<td style="text-align:center">1110xxxx 10xxxxxx 10xxxxxx</td>
</tr>
<tr>
<td style="text-align:center">U+10000 – U+10FFFF</td>
<td style="text-align:center">11110xxx 10xxxxxx 10xxxxxx 10xxxxxx</td>
</tr>
</tbody>
</table>
<p>其中绝大部分的中文用三个字节编码，部分中文用四个字节编码。UTF-8编码的主要优点有：1.兼容ASCII码；2.没有字节序（大小端）的问题，适合网络传输；3.存储英文和拉丁文等比较节省存储空间。但也存在不足，例如边长编码不利于文本处理，对于CJK文字比较浪费存储空间。</p>
<h4 id="UTF-16编码"><a href="#UTF-16编码" class="headerlink" title="UTF-16编码"></a>UTF-16编码</h4><p>&emsp;&emsp;UTF-16也是一种变长编码，对于一个Unicode字符被编码成1至2个码元，每个码元为16位。在基本多语言平面(码位范围U+0000-U+FFFF)内的码位UTF-16编码使用1个码元且其值与Unicode是相等的（不需要转换）,<br>在辅助平面(码位范围U+10000-U+10FFFF)内的码位在UTF-16中被编码为一对16bit的码元（即32bit,4字节），称作代理对(surrogate pair)。组成代理对的两个码元前一个称为前导代理(lead surrogates)范围为0xD800-0xDBFF，后一个称为后尾代理(trail surrogates)范围为0xDC00-0xDFFF。</p>
<h4 id="Unicode、UTF-8编码的互转"><a href="#Unicode、UTF-8编码的互转" class="headerlink" title="Unicode、UTF-8编码的互转"></a>Unicode、UTF-8编码的互转</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">void UTF8ToUnicode(wchar_t* pOut,char *pText)</div><div class="line">&#123;</div><div class="line">    char* uchar = (char *)pOut;</div><div class="line">    uchar[1] = ((pText[0] &amp; 0x0F) &lt;&lt; 4) + ((pText[1] &gt;&gt; 2) &amp; 0x0F);</div><div class="line">    uchar[0] = ((pText[1] &amp; 0x03) &lt;&lt; 6) + (pText[2] &amp; 0x3F);</div><div class="line">    return;</div><div class="line">&#125;</div><div class="line"></div><div class="line">void UnicodeToUTF8(char* pOut,wchar_t* pText)</div><div class="line">&#123;</div><div class="line">	//注意 WCHAR高低字的顺序,低字节在前，高字节在后</div><div class="line">    char* pchar = (char *)pText;</div><div class="line">    pOut[0] = (0xE0 | ((pchar[1] &amp; 0xF0) &gt;&gt; 4));</div><div class="line">    pOut[1] = (0x80 | ((pchar[1] &amp; 0x0F) &lt;&lt; 2)) + ((pchar[0] &amp; 0xC0) &gt;&gt; 6);</div><div class="line">    pOut[2] = (0x80 | (pchar[0] &amp; 0x3F));</div><div class="line">    return;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="Unicode、GB2312编码的互转"><a href="#Unicode、GB2312编码的互转" class="headerlink" title="Unicode、GB2312编码的互转"></a>Unicode、GB2312编码的互转</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">//注：此处用到windows编码转换的函数</div><div class="line">void UnicodeToGB2312(char* pOut,wchar_t uData)</div><div class="line">&#123;</div><div class="line">    WideCharToMultiByte(CP_ACP,NULL,&amp;uData,1,pOut,sizeof(wchar_t),NULL,NULL);</div><div class="line">    return;</div><div class="line">&#125;     </div><div class="line"> </div><div class="line">void GB2312ToUnicode(wchar_t* pOut,char *gbBuffer)</div><div class="line">&#123;</div><div class="line">    MultiByteToWideChar(CP_ACP,MB_PRECOMPOSED,gbBuffer,2,pOut,1);</div><div class="line">    return ;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="UTF-8、GBK-GB2312-编码的互转"><a href="#UTF-8、GBK-GB2312-编码的互转" class="headerlink" title="UTF-8、GBK(GB2312)编码的互转"></a>UTF-8、GBK(GB2312)编码的互转</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div></pre></td><td class="code"><pre><div class="line">void GB2312ToUTF8(string&amp; pOut,char *pText, int pLen)</div><div class="line">&#123;</div><div class="line">    char buf[4];</div><div class="line">    int nLength = pLen* 3;</div><div class="line">    char* rst = new char[nLength];</div><div class="line">    </div><div class="line">    memset(buf,0,4);</div><div class="line">    memset(rst,0,nLength);</div><div class="line">    </div><div class="line">    int i = 0;</div><div class="line">    int j = 0;      </div><div class="line">    while(i &lt; pLen)</div><div class="line">    &#123;</div><div class="line">        if( *(pText + i) &gt;= 0)</div><div class="line">        &#123;</div><div class="line">            rst[j++] = pText[i++]; </div><div class="line">        &#125;</div><div class="line">        else</div><div class="line">        &#123;</div><div class="line">			wchar_t pbuffer;</div><div class="line">			Gb2312ToUnicode(&amp;pbuffer,pText+i);</div><div class="line">			UnicodeToUTF_8(buf,&amp;pbuffer);</div><div class="line">			unsigned short int tmp = 0;</div><div class="line">			tmp = rst[j] = buf[0];</div><div class="line">			tmp = rst[j+1] = buf[1];</div><div class="line">			tmp = rst[j+2] = buf[2];    </div><div class="line">			j += 3;            </div><div class="line">			i += 2;        </div><div class="line">        &#125;   </div><div class="line">    &#125;</div><div class="line">    </div><div class="line">    rst[j] = &apos; &apos;;</div><div class="line">    pOut = rst;             </div><div class="line">    delete []rst;     </div><div class="line">    return;</div><div class="line">&#125;</div><div class="line"></div><div class="line">void UTF8ToGB2312(string &amp;pOut, char *pText, int pLen)</div><div class="line">&#123;</div><div class="line">    char * newBuf = new char[pLen];</div><div class="line">    char Ctemp[4];</div><div class="line">    memset(Ctemp,0,4);</div><div class="line">    int i =0;</div><div class="line">    int j = 0;</div><div class="line"> </div><div class="line">    while(i &lt; pLen)</div><div class="line">    &#123;</div><div class="line">        if(pText &gt; 0)</div><div class="line">        &#123;</div><div class="line">            newBuf[j++] = pText[i++];                       </div><div class="line">        &#125;</div><div class="line">        else</div><div class="line">        &#123;</div><div class="line">			WCHAR Wtemp;</div><div class="line">			UTF_8ToUnicode(&amp;Wtemp,pText + i);</div><div class="line">			UnicodeToGB2312(Ctemp,Wtemp);</div><div class="line">			newBuf[j] = Ctemp[0];</div><div class="line">			newBuf[j + 1] = Ctemp[1];</div><div class="line"></div><div class="line">			i += 3;    </div><div class="line">			j += 2;   </div><div class="line">		&#125;</div><div class="line">    &#125;</div><div class="line"> </div><div class="line">    newBuf[j] = &apos; &apos;;</div><div class="line">    pOut = newBuf;</div><div class="line">    delete []newBuf;</div><div class="line">    return; </div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>另外一种实现GBK和UTF-8编码转换的方法：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line">string GBKToUTF8(const char* strGBK)</div><div class="line">&#123;</div><div class="line">    int len = MultiByteToWideChar(CP_ACP, 0, strGBK, -1, NULL, 0);</div><div class="line">    wchar_t* wstr = new wchar_t[len + 1];</div><div class="line">    memset(wstr, 0, len + 1);</div><div class="line">    MultiByteToWideChar(CP_ACP, 0, strGBK, -1, wstr, len);</div><div class="line">    len = WideCharToMultiByte(CP_UTF8, 0, wstr, -1, NULL, 0, NULL, NULL);</div><div class="line">    char* str = new char[len + 1];</div><div class="line">    memset(str, 0, len + 1);</div><div class="line">    WideCharToMultiByte(CP_UTF8, 0, wstr, -1, str, len, NULL, NULL);</div><div class="line">    string strTemp = str;</div><div class="line">    if (wstr) delete[] wstr;</div><div class="line">    if (str) delete[] str;</div><div class="line">    return strTemp;</div><div class="line">&#125;</div><div class="line"></div><div class="line">string UTF8ToGBK(const char* strUTF8)</div><div class="line">&#123;</div><div class="line">    int len = MultiByteToWideChar(CP_UTF8, 0, strUTF8, -1, NULL, 0);</div><div class="line">    wchar_t* wszGBK = new wchar_t[len + 1];</div><div class="line">    memset(wszGBK, 0, len * 2 + 2);</div><div class="line">    MultiByteToWideChar(CP_UTF8, 0, strUTF8, -1, wszGBK, len);</div><div class="line">    len = WideCharToMultiByte(CP_ACP, 0, wszGBK, -1, NULL, 0, NULL, NULL);</div><div class="line">    char* szGBK = new char[len + 1];</div><div class="line">    memset(szGBK, 0, len + 1);</div><div class="line">    WideCharToMultiByte(CP_ACP, 0, wszGBK, -1, szGBK, len, NULL, NULL);</div><div class="line">    string strTemp(szGBK);</div><div class="line">    if (wszGBK) delete[] wszGBK;</div><div class="line">    if (szGBK) delete[] szGBK;</div><div class="line">    return strTemp;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h3><ul>
<li><a href="http://wiki.jikexueyuan.com/project/visual-studio/14.html" target="_blank" rel="external">http://wiki.jikexueyuan.com/project/visual-studio/14.html</a>  </li>
<li><a href="http://www.cnblogs.com/zhenjing/archive/2011/08/07/chinese_string.html" target="_blank" rel="external">http://www.cnblogs.com/zhenjing/archive/2011/08/07/chinese_string.html</a>  </li>
<li><a href="http://www.crazyant.net/251.html" target="_blank" rel="external">http://www.crazyant.net/251.html</a></li>
<li><a href="http://blog.poxiao.me/p/unicode-character-encoding-conversion-in-cpp11/" target="_blank" rel="external">http://blog.poxiao.me/p/unicode-character-encoding-conversion-in-cpp11/</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp;在coding过程中会时不时地遇到字符集的编码问题，之前就一直没弄清楚过，很是头疼，因此查阅了一些资料，并对各种字符集(Ascii、Unicode、GB2312)、编码(UTF8、GBK)以及不同编码之间的转换做一个简单的总结。&lt;br&gt;
    
    </summary>
    
      <category term="coding" scheme="https://senitco.github.io/categories/coding/"/>
    
    
      <category term="encode/decode" scheme="https://senitco.github.io/tags/encode-decode/"/>
    
  </entry>
  
  <entry>
    <title>简述云平台和相关软件工具</title>
    <link href="https://senitco.github.io/2017/05/24/cloud-platform/"/>
    <id>https://senitco.github.io/2017/05/24/cloud-platform/</id>
    <published>2017-05-24T06:55:58.508Z</published>
    <updated>2017-05-24T07:06:10.325Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;本文简单论述了公有云平台和私有云平台的关系，它们之间的异同点，并列举在公有云资源上搭建私有云的软件工具，说明它们采用的技术、以及应用的领域等方面存在的异同。<br><a id="more"></a></p>
<h3 id="公有云平台和私有云平台的关系以及异同点"><a href="#公有云平台和私有云平台的关系以及异同点" class="headerlink" title="公有云平台和私有云平台的关系以及异同点"></a>公有云平台和私有云平台的关系以及异同点</h3><p>&emsp;&emsp;云计算是近年来由集群、网格、分布式和效用计算发展而来的全新计算模式，将IT资源、数据、应用等作为一种服务，通过网络提供给用户。在云计算模式下，用户不必构建和组织这些资源，而是可以直接按需付费使用云计算服务商提供的服务。</p>
<h4 id="公有云、私有云与混合云"><a href="#公有云、私有云与混合云" class="headerlink" title="公有云、私有云与混合云"></a>公有云、私有云与混合云</h4><p>&emsp;&emsp;根据商业模式或者服务是否公开，云计算可以分为以下三个类别，公有云、私有云和混合云。公有云通常是指由第三方企业提供的云平台服务，构建在互联网之上，任何已付费的用户都可以访问，其基础设施由提供云计算服务的大型运营组织建立和维护，这些运营组织一般是拥有大量计算资源的IT巨头，例如Google、Amazon、IBM、微软等大型企业，这些公司将云计算服务以按需付费的方式销售给一般用户或中小企业群体，用户只需要将请求提交给云计算系统，付费租用所需的资源和服务，而不需要再投入成本建立数据中心、进行系统的维护，可以专心开发核心的应用服务。现有的一些代表性公有云平台包括GAE（谷歌应用引擎）、AWS（亚马逊的Web服务）、微软Azure、IBM蓝云和Salesforce.com的Force.com。这些云由商业提供商提供公共可访问的远程接口，通过这些接口可以在各自的基础设施中创建或管理虚拟机实例。公有云以共享的方式通过互联网提供给用户非常有吸引力的低成本服务，但开放性较高，而且用户失去了对数据和计算的控制权，因此数据安全隐患较为突出。私有云通常构建在局域网内部，云平台的拥有者和消费者都是同一个公司或组织，它属于客户、由客户管理，而且其可访问范围限制在所属客户及其合作者之间。私有云并不是在互联网之上通过公共可访问的接口售卖容量和计算资源，而是部署在企业内部，由用户内部所共享，在管理域中运行服务负载，对计算资源进行统一管理和动态分配，不提供对外服务，为本地用户提供了一个灵活便捷、相对安全可靠且高质量的云基础设施。但私有云平台要求企业组织购买基础设施，建立相应规模的数据中心，并投入人力物力来维护数据中心的正常运转，在一定程度上提高了企业的成本。由于私有云的开放性不高，可能会影响云的标准化，但安全威胁相对较少，可以获得更大的可定制化和组织控制能力。私有云的一个例子是美国国家航空航天局（NASA）构建的私有云，用于研究者在其提供的远程系统上运行气象模型。混合云由公有云和私有云共同构成，通过外部公有云的计算能力补充本地基础设施。不同云平台仍然是独立实体，通过利用标准的或专用的技术实现绑定，彼此之间能够进行数据和应用的移植。例如混合云可以在公有云和私有云之间通过负载均衡技术应付突发负载；应用混合云模式，用户可以将次要的、非敏感的数据和应用部署到公有云上，充分利用公有云在扩展性和成本上的优势，同时将任务关键性的、敏感的数据放在私有云上，保证安全性。</p>
<h4 id="公有云和私有云的相同点"><a href="#公有云和私有云的相同点" class="headerlink" title="公有云和私有云的相同点"></a>公有云和私有云的相同点</h4><p>&emsp;&emsp;无论是公有云还是私有云，都是利用数据中心的服务器集群和大规模数据库，搭建虚拟化平台，通过按需动态配置硬件、软件和数据集，将弹性资源放在一起，将桌面计算移向基于服务的平台，充分利用其对提供商和用户的低成本和简易性，使用户可以专注于应用的开发，避免了大量的数据移动，可以带来更好的网络带宽利用率。而且，机器虚拟化进一步提高了资源利用率，增加了应用程序灵活性，降低了使用虚拟化数据中心资源的总体成本。公有云和私有云都是在互联网上开发的，并且许多云都是由商业提供商或企业以分布式的方式产生，它们会通过网络互连来达到可扩展的、有效的计算服务。云提供商在不同地区创建平台，这种分布有益于故障容错、降低响应延迟。基于局域网的私有云可以连接到公有云，从而获得额外的资源；在不用用户团体之间开发广泛的服务级协议（SLA），可以在一定程度上提供云平台的用户体验和服务质量。此外，公有云和私有云都用到了网格计算等许多已有的技术。</p>
<h4 id="公有云和私有云的不同点"><a href="#公有云和私有云的不同点" class="headerlink" title="公有云和私有云的不同点"></a>公有云和私有云的不同点</h4><p>&emsp;&emsp;现阶段公有云和私有云存在着显著的差异。首先，公有云和私有云针对的客户群体和服务层级有所不同，公有云的服务对象是中小企业、初创公司或者是个人，而且一般是以应用或者平台的方式提供；而私有云的服务对象是政府或者是大型公司，服务形式更多是平台或者基础设施，客户可以在此基础上搭建自己专属的平台并开发相关的应用。应用、平台和基础设施分别对应云计算的三个服务层级，SaaS（软件即服务）、PaaS（平台即服务）、IaaS（基础设施即服务）通常，SaaS构建在PaaS之上，PaaS则构建在IaaS之上。SaaS模型将软件应用程序作为服务进行提供，客户可通过浏览器或使用特殊的接口进行访问；PaaS模型在基础设施之上提供操作系统及运行时库支持的平台，客户可以基于该模型来开发和部署自己的应用程序；IaaS则提供基础设施服务，用户可以使用计算、网络、存储、通信等底层资源。因此，对于公有云平台，提供的服务主要集中在上两层，而私有云平台则集中在下两层。在业务场景方面，公有云提供对外互联网业务，而私有云着重于政府企业的内部业务。公有云和私有云的基础设施也存在一定的差异，当企业构建一个私有云平台时，IT基础设施一般属于自己且位于企业内部，采用公有云平台的时候，基础设施则位于第三方的数据中心；不过也有例外，一些服务提供商提出虚拟私有云（VPC）的概念，通过在第三方数据中心内部使用技术手段隔离出来一个专用计算环境，并通过安全通道与企业客户相连接。这是在基础设施的部署位置上的不同，设备自身也有所差异。对于许多大型企业，经过多年的IT建设和技术演变，其基础设施往往采用了不同的技术和平台，也就是说，这些企业的私有云采用的是异构平台环境。对于目前大部分公有云提供商来说，他们的云平台往往是通过廉价和标准的硬件平台来构建的，能够以较好的性价比满足大部分用户的需求；另外，公有云服务提供商往往提供最为大众化的、需求量最为广泛和集中的服务。因此，对于公有云服务来说，其服务和环境一般是同构的。<br>在技术架构方面，公有云采用自研架构，关注分布式、大集群和可扩展性；私有云一般采用开源架构，更关注高可用、灵活性和可定制化。在安全性方面，公有云的应用和数据在第三方云提供商的数据中心，存在被泄露和篡改的风险，数据安全取决于第三方的技术能力、专业性和信誉度，安全威胁相对较大；私有云可以部署在客户对象的防火墙内，属于客户、由客户管理，在一定程度上和外界隔离，数据的安全性相对较高。在可控性和定制化方面，公有云为第三方提供的标准解决方案或个性化方案，客户不能任意地修改需求；而私有云是为了企业单独使用而构建的，可以定制、与现有系统集成或者从零开发，灵活性较高。在服务质量方面，公有云取决于服务提供商，可能会受到网络等因素的影响；而私有云则是企业自主保证服务质量，可以通过加强监控，保证服务的稳定性。此外，公有云的开放度高、规模大、应用场景广泛，初期成本低，后期业务量增加时，成本也会相应提高；而私有云的初期成本高，随着业务量增加，后期成本低。随着技术的发展，一旦私有云成熟起来并且防护更为安全时，可以将其开放或转化为公有云，因此，公有云和私有云的界限在未来会变得越来越模糊，未来非常有可能大部分云天然就是混合云。</p>
<h3 id="搭建私有云的软件工具，所采用技术和应用领域"><a href="#搭建私有云的软件工具，所采用技术和应用领域" class="headerlink" title="搭建私有云的软件工具，所采用技术和应用领域"></a>搭建私有云的软件工具，所采用技术和应用领域</h3><p>&emsp;&emsp;目前在公有云资源上搭建私有云的软件工具主要有OpenStack、CloudStack、Eucalyptus、OpenNubela等。</p>
<h4 id="OpenStack"><a href="#OpenStack" class="headerlink" title="OpenStack"></a>OpenStack</h4><p>&emsp;&emsp;OpenStack是由NASA和Rackspace公司合作研发的云计算平台，两者分别贡献计算代码（Nova）和存储代码（Swift），以Apache许可协议进行授权，是一款完全开放源代码的项目和自由软件。OpenStack采用分布式架构，整个平台按照功能不同分为多个模块项目，每个项目实现独自的功能，项目之间通过消息队列中间件和Restful形式的API进行交互通信，将项目之间的耦合性降到最低。每个项目都可以部署在不同的主机上，进行单独地安装和测试，架构非常的灵活。在项目内部，OpenStack遵循开放的设计原则，底层除了支持开源技术外，还对商业产品提供支持，如虚拟化技术能够用VMware的ESXI或者微软的Hyper-V，存储可以采用IBM或者VMware的产品，网络虚拟化能够使用Cisco或者Nicira的网络设备，而且OpenStack没有将底层的技术实现锁定在某一厂商的产品上，而是通过扩展的形式对其进行支持。OpenStack对外提供丰富和功能强大的API，使得资源可以被用户方便地使用和调度，同时提供和AWS（亚马逊Web服务）兼容的API。OpenStack致力于提供一个既可以用来建设公有云也能建设私有云的通用的开源云计算平台，而且做到云平台的搭建尽量简单方便，同时能够快速地横向扩展；遵循开源、开放的理念，完全由社区主导和维护；不同项目之间几乎没有耦合，可以方便地进行开发定制，但项目要单独安装，部署会比较麻烦。</p>
<h4 id="CloudStack"><a href="#CloudStack" class="headerlink" title="CloudStack"></a>CloudStack</h4><p>&emsp;&emsp;CloudStack最初由Cloud.com公司开发，在被收购后贡献给Apache软件基金会，采用Apache许可协议。与OpenStack的分布式架构不同，CloudStack采用集中式的单体架构，包括DashBoard/CLI层、CloudStack API、核心引擎层和计算/网络/存储控制层，是典型的分层结构。整个平台只有一个项目构成，不同模块之间通过本地调用进行交互，在一台主机上就可以完成平台的部署，但CloudStack本身未采用面向服务的架构（SOA），组件之间的耦合度较高，平台的扩展性相对弱一些。从开发平台来看，CloudStack使用Java语言API等部分，运行时部署为Tomcat的Servlet；另外还大量使用Python开发与网络和系统管理相关的部分。CloudStack的一套独立Java代码库，涵盖通信、数据管理、事件管理、任务管理和插件管理等部分，基本形成了开发平台。CloudStack同样对外提供自身API和与Amazon AWS兼容的API。总体来说，CloudStack提供高度可用的、能够进行大规模虚拟机部署和管理的开放云平台，在云平台构建时会比较方便，但平台架构比较集中，模块间紧耦合，扩展性不是很好。</p>
<h4 id="Eucalyptus"><a href="#Eucalyptus" class="headerlink" title="Eucalyptus"></a>Eucalyptus</h4><p>&emsp;&emsp;Eucalyptus是一个与Amazon EC2兼容的IaaS系统，是EC2的一个开源实现，通过集群计算来实现高弹性、实用的云计算服务。Eucalyptus提供许多高级的特性，包括支持VM在Xen或者KVM上运行，用于系统管理以及对用户结算等项目进行云管理，兼容Amazon EC2和S3接口等。Eucalyptus包括云控制器（CLC）、Walrus、集群控制器（CC）、存储控制器（SC）和节点控制器（NC）五个组件。CLC是整个系统的核心，负责高层次的资源调度，例如向CC请求计算资源；Walrus是一个与Amazon S3类似的存储服务，主要用于存储虚拟机映像和用户数据；CC是一个集群的前端，负责协调一个集群内的计算资源，并且管理集群内的网络流量；SC是与Amazon EBS类似的存储块设备服务，可以用来存储业务数据；NC是最终的计算节点，通过调用操作系统层的虚拟化技术来启动和关闭虚拟机。在同一个集群内的所有计算节点必须在同一个子网内，而且一个集群内通常要部署一台存储服务器，为计算节点提供数据存储服务。从组件服务角度看，每个集群中计算和存储服务设计为独立服务，网络仍为计算服务的一部分；从分层角度来看，Eucalyptus在SOA层面做得较好，但缺乏API层设计，技术门槛相对较高，整体上对抽象框架和插件的设计做得不够。</p>
<h4 id="OpenNebula"><a href="#OpenNebula" class="headerlink" title="OpenNebula"></a>OpenNebula</h4><p>&emsp;&emsp;OpenNebula是欧洲研究学会发起的虚拟基础设备和云端运算计划的虚拟化的开源实现，其核心部分是Front End。OpenNebula主要分为三层，即接口层、核心层和驱动层。接口层提供了原生的XML-RPC接口，同时实现了Amazon EC2等多种API；核心层提供统一的插件管理、请求管理、声明周期管理、Hypervisor管理、网络资源管理和存储资源管理等核心功能；最底层是驱动层，主要与虚拟化软件（KVM、XEN）和物理基础设施交互。在OpenNebula中，计算、存储和网络部分是独立的模块，资源调度也被分离出来支持多种可选的策略和资源额度管理。OpenNebula没有采用SOA的设计，解耦合做的不够，但采用Libvirt所提供的接口远程调用计算节点上虚拟化控制命令，这种设计在系统安装部署阶段会减少很多软件安装配置工作。</p>
<h4 id="平台的应用领域和综合对比"><a href="#平台的应用领域和综合对比" class="headerlink" title="平台的应用领域和综合对比"></a>平台的应用领域和综合对比</h4><p>&emsp;&emsp;综合对比分析，OpenSack是一个用来管理数据中心级别资源池包括计算资源、网络资源、存储资源的云操作系统，通过授权，用户可以通过Web界面获取资源，同时管理员通过统一的仪表盘对资源调度进行控制；而且OpenStack的应用领域是针对所有类型的云平台，发布一个简单、易扩展、功能丰富的解决方案。CloudStack主要被设计用来发布和管理大型虚拟机网络，以实现一个高可用以及可扩展的IaaS云计算平台，包含了大部分组织需要的功能如虚拟机管理、网络管理、完善的API等；而且支持大部分主流的虚拟化技术，既适用于构建公有云服务，也可搭建私有云和混合云。Eucalyptus是一个用来构建私有云，或者基于AWS API的混合云的开源工具，能够根据应用的工作负载动态地扩容或者缩容；使用Eucalyptus的组织可以将以往使用公有云的经验应用到私有的IT资源上，同时获得更好的数据安全、更好的性能；而且Eucalyptus提供了很多AWS组件的开源实现，用户可以很方便地将AWS应用部署到自由基础设施上。OpenNebula提供对虚拟化数据中心全方位管理、简单的但是功能丰富灵活的完整解决方案，既包含搭建私有云所必须的功能，同时也可以提供公有云的服务，能够对虚拟化数据中心和云基础设施进行管理；其良好的互操作性保证用户能够使用现有的设备进行云计算方面的改造，同时避免与供应商的绑定。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp;本文简单论述了公有云平台和私有云平台的关系，它们之间的异同点，并列举在公有云资源上搭建私有云的软件工具，说明它们采用的技术、以及应用的领域等方面存在的异同。&lt;br&gt;
    
    </summary>
    
      <category term="Projects" scheme="https://senitco.github.io/categories/Projects/"/>
    
    
      <category term="computing" scheme="https://senitco.github.io/tags/computing/"/>
    
  </entry>
  
  <entry>
    <title>数据挖掘中的度量方法</title>
    <link href="https://senitco.github.io/2017/05/24/measurement-method/"/>
    <id>https://senitco.github.io/2017/05/24/measurement-method/</id>
    <published>2017-05-24T02:20:09.854Z</published>
    <updated>2017-05-24T06:43:54.575Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;在数据挖掘中，无论是对数据进行分类、聚类还是异常检测、关联性分析，都建立在数据之间相似性或相异性的度量基础上。通常使用距离作为数据之间相似性或相异性的度量方法，常用的度量方法有欧式距离、曼哈顿距离、切比雪夫距离、闵可夫斯基距离、汉明距离、余弦距离、马氏距离、Jaccard系数、相关系数、信息熵。<br><a id="more"></a></p>
<!-- mathjax config similar to math.stackexchange -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
        inlineMath: [ ['$', '$'] ],
        displayMath: [ ['$$', '$$']],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    messageStyle: "none",
    "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> 

<h3 id="欧式距离"><a href="#欧式距离" class="headerlink" title="欧式距离"></a>欧式距离</h3><p>&emsp;&emsp;$n$维空间中两个样本点$x$和$y$之间的欧几里得距离定义如下：<br>$$d(x,y)=\sqrt{\Sigma_{k=1}^n (x_k-y_k)^2}$$<br>标准化欧式距离公式如下：<br>$$d(x,y)=\sqrt{\Sigma_{k=1}^n (\dfrac{x_k-y_k}{s_k})^2}$$<br>式中，$s_k$为数据每一维的方差，标准化欧式距离考虑了数据各维分量的量纲和分布不一样，相当于对每维数据做了标准化处理。欧式距离适用于度量数据属性无关、值域或分布相同的数据对象。</p>
<h3 id="曼哈顿距离"><a href="#曼哈顿距离" class="headerlink" title="曼哈顿距离"></a>曼哈顿距离</h3><p>&emsp;&emsp;曼哈顿距离也称为街区距离，计算公式如下：<br>$$d(x,y)=\Sigma_{k=1}^n \left|x_k-y_k\right|$$</p>
<h3 id="切比雪夫距离"><a href="#切比雪夫距离" class="headerlink" title="切比雪夫距离"></a>切比雪夫距离</h3><p>$$d(x,y) = \lim_{n\rightarrow \infty} (\Sigma_{k=1}^n (\left|x_k-y_k\right|)^r)^\dfrac{1}{r} = max_k (\left|x_k-y_k\right|)$$<br>上面两个公式是等价的。</p>
<h3 id="闵可夫斯基距离"><a href="#闵可夫斯基距离" class="headerlink" title="闵可夫斯基距离"></a>闵可夫斯基距离</h3><p>$$d(x,y)=(\Sigma_{k=1}^n (\left|x_k-y_k\right|)^r)^\dfrac{1}{r}$$<br>式中，r是一个可变参数，根据参数r取值的不同，闵可夫斯基距离可以表示一类距离<br>&emsp;&emsp;r = 1时，为曼哈顿距离<br>&emsp;&emsp;r = 2时，为欧式距离<br>&emsp;&emsp;r →∞时，为切比雪夫距离<br>闵可夫斯基距离包括欧式距离、曼哈顿距离、切比雪夫距离都假设数据各维属性的量纲和分布（期望、方差）相同，因此适用于度量独立同分布的数据对象。</p>
<h3 id="汉明距离"><a href="#汉明距离" class="headerlink" title="汉明距离"></a>汉明距离</h3><p>&emsp;&emsp;两个等长字符串之间的汉明距离是两个字符串对应位置的不同字符的个数，也就是将一个字符串变换为另一个字符串所需要替换的最小字符个数，例如<br>$$Hamming Distance(1001001, 0101101) = 3$$<br>汉明距离常用于信息编码中。</p>
<h3 id="余弦距离"><a href="#余弦距离" class="headerlink" title="余弦距离"></a>余弦距离</h3><p>&emsp;&emsp;余弦相似度公式定义如下：<br>$$cos⁡(x,y)=\dfrac{xy}{\left|x\right|\left|y\right|} = \dfrac{\Sigma_{k=1}^n x_k y_k}{\sqrt{\Sigma_{k=1}^n x_k^2} \sqrt{\Sigma_{k=1}^n y_k^2}}$$<br>余弦相似度实际上是向量$x$和$y$夹角的余弦度量，可用来衡量两个向量方向的差异。如果余弦相似度为$1$，则$x$和$y$之间夹角为$0°$，两向量除模外可认为是相同的；如果预先相似度为$0$，则$x$和$y$之间夹角为$90°$，则认为两向量完全不同。在计算余弦距离时，将向量均规范化成具有长度$1$，因此不用考虑两个数据对象的量值。<br>余弦相似度常用来度量文本之间的相似性。文档可以用向量表示，向量的每个属性代表一个特定的词或术语在文档中出现的频率，尽管文档具有大量的属性，但每个文档向量都是稀疏的，具有相对较少的非零属性值。</p>
<h3 id="马氏距离"><a href="#马氏距离" class="headerlink" title="马氏距离"></a>马氏距离</h3><p>&emsp;&emsp;马氏距离的计算公式如下：<br>$$mahalanobis(x,y)=(x-y)\Sigma^{-1}(x-y)^T$$<br>式中，$\Sigma^{-1}$是数据协方差矩阵的逆。<br>前面的距离度量方法大都假设样本独立同分布、数据属性之间不相关。马氏距离考虑了数据属性之间的相关性，排除了属性间相关性的干扰，而且与量纲无关。若协方差矩阵是对角阵，则马氏距离变成了标准欧式距离；若协方差矩阵是单位矩阵，各个样本向量之间独立同分布，则变成欧式距离。</p>
<h3 id="Jaccard系数"><a href="#Jaccard系数" class="headerlink" title="Jaccard系数"></a>Jaccard系数</h3><p>&emsp;&emsp;Jaccard系数定义为两个集合A和B的交集元素在其并集中所占的比例，即<br>$$J(A,B)=\dfrac{A\cap B}{A\cup B}$$<br>对于两个数据对象$x$和$y$，均由$n$个二元属性组成，则<br>$$J=\dfrac{f_{11}}{f_{01}+f_{10}+f_{11}}$$<br>式中，$f_{11}$为$x$取$1$且$y$取$1$的属性个数，$f_{01}$为$x$取$0$且$y$取$1$的属性个数，$f_{10}$为$x$取$1$且$y$取$0$的属性个数。<br>Jaccard系数适用于处理仅包含非对称的二元属性的对象。<br>广义Jaccard系数定义如下：<br>$$EJ(x,y)=\dfrac{xy}{‖x‖^2+‖y‖^2-xy}$$<br>广义Jaccard系数又称为Tanimoto系数，可用于处理文档数据，并在二元属性情况下归约为Jaccard系数。</p>
<h3 id="相关系数"><a href="#相关系数" class="headerlink" title="相关系数"></a>相关系数</h3><p>&emsp;&emsp;两个数据对象之间的相关性是对象属性之间线性关系的度量，计算公式如下<br>$$\rho_{xy}=\dfrac{s_{xy}}{s_x s_y}$$<br>$$s_{xy}=\dfrac{1}{n-1} \Sigma_{k=1}^n (x_k-\overline{x})(y_k-\overline{y})$$<br>$$s_x=\sqrt{\dfrac{1}{n-1} \Sigma_{k=1}^n (x_k-\overline{x})^2}$$<br>$$s_y=\sqrt{\dfrac{1}{n-1} \Sigma_{k=1}^n (y_k-\overline{y})^2}$$<br>$$\overline{x}=\dfrac{1}{n} \Sigma_{k=1}^n x_k ,&emsp;\overline{y}=\dfrac{1}{n} \Sigma_{k=1}^n y_k$$<br>相关系数是衡量数据对象相关程度的一种方法，取值范围为$[-1,1]$。相关系数的绝对值越大，则表明$x$和$y$相关度越高。当$x$和$y$线性相关时，相关系数取值为$1$（正线性相关）或$-1$（负线性相关）；线性无关时取值为$0$。在线性回归中，使用直线拟合样本点，可利用相关系数度量其线性性。</p>
<h3 id="信息熵"><a href="#信息熵" class="headerlink" title="信息熵"></a>信息熵</h3><p>&emsp;&emsp;信息熵描述的是整个系统内部样本之间的一个距离，是衡量分布的混乱程度或分散程度的一种度量。样本分布越分散（或者说分布越平均），信息熵越大；分布越有序（或者说分布越集中），信息熵就越小。给定样本集$X$的信息熵公式定义如下：<br>$$Entropy(X)=\Sigma_{i=1}^n -p_i log_2⁡(p_i)$$<br>式中，$n$为样本集的分类数，$p_i$为第$i$类元素出现的概率。当$S$中$n$个分类出现的概率一样大时，信息熵取最大值$log2(n)$。当$X$只有一个分类时，信息熵取最小值$0$。信息熵用于度量不确定性，在决策树分类中，信息熵可用于计算子树划分前后的信息增益作为选择最佳划分的度量。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp;在数据挖掘中，无论是对数据进行分类、聚类还是异常检测、关联性分析，都建立在数据之间相似性或相异性的度量基础上。通常使用距离作为数据之间相似性或相异性的度量方法，常用的度量方法有欧式距离、曼哈顿距离、切比雪夫距离、闵可夫斯基距离、汉明距离、余弦距离、马氏距离、Jaccard系数、相关系数、信息熵。&lt;br&gt;
    
    </summary>
    
      <category term="Algorithm" scheme="https://senitco.github.io/categories/Algorithm/"/>
    
    
      <category term="ML" scheme="https://senitco.github.io/tags/ML/"/>
    
  </entry>
  
  <entry>
    <title>VS2013编译配置openssl</title>
    <link href="https://senitco.github.io/2017/05/14/VS2013-compile-openssl/"/>
    <id>https://senitco.github.io/2017/05/14/VS2013-compile-openssl/</id>
    <published>2017-05-14T03:21:35.970Z</published>
    <updated>2017-05-24T06:46:42.834Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;简单介绍如何使用VS2013编译配置openssl，并添加到工程中<br><a id="more"></a></p>
<h3 id="VS2013编译openssl1-1-0e"><a href="#VS2013编译openssl1-1-0e" class="headerlink" title="VS2013编译openssl1.1.0e"></a>VS2013编译openssl1.1.0e</h3><p>1.下载OpenSSL <a href="http://www.openssl.org" target="_blank" rel="external">http://www.openssl.org</a> ，并解压到指定目录，例如 D:\openssl</p>
<p>2.下载并安装Perl  <a href="http://www.activestate.com/ActivePerl" target="_blank" rel="external">http://www.activestate.com/ActivePerl</a></p>
<p>3.新建一个存放openssl库文件的目录，例如 D:\openssl\openssl_lib</p>
<p>4.打开VS2013控制台命令提示(root_dir为VS安装目录)<br>Visual Studio 2013, 32-bit: Open CMD.EXE and run<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">root_dir\Microsoft Visual Studio 12.0\VC\bin\vcvars32.bat</div></pre></td></tr></table></figure></p>
<p>Visual Studio 2013, 64-bit: Open CMD.EXE and run<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">root_dir\Microsoft Visual Studio 12.0\VC\bin\amd64\vcvars64.bat</div></pre></td></tr></table></figure></p>
<p>5.进入openssl源代码目录路径<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cd D:\openssl</div></pre></td></tr></table></figure></p>
<p>6.依次执行以下命令<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">perl Configure VC-WIN32 &lt;no-asm&gt; --perfix=D:\openssl\openssl_lib //&lt;no-asm&gt;为可选参数，忽略汇编处理</div><div class="line"></div><div class="line">nmake</div><div class="line"></div><div class="line">nmake test</div><div class="line"></div><div class="line">nmake install</div></pre></td></tr></table></figure></p>
<p>7.编译成功后，会在openssl_lib目录下生成3个文件目录</p>
<p>bin: 主要有libcrypto-1_1.dll、libssl-1_1.dll动态链接库文件和openssl.exe文件</p>
<p>lib: 静态链接库libcrypto.lib、libssl.lib文件</p>
<p>include\openssl: 相关头文件</p>
<h3 id="VS2013中使用openssl"><a href="#VS2013中使用openssl" class="headerlink" title="VS2013中使用openssl"></a>VS2013中使用openssl</h3><p>1.新建VS工程，将openssl库文件(.lib、.dll)和头文件拷至工程的相应目录中</p>
<p>2.配置路径</p>
<p>静态库: 链接附加库目录至libssl.lib、libcrypto.lib库目录，并在附加依赖项下添加.lib文件</p>
<p>动态库：libcrypto-1_1.dll、libssl-1_1.dll放置到.exe输出目录中（Debug/Release)</p>
<p>头文件：链接附加包含目录至 include 目录</p>
<p>*关于动态库dll的链接问题：<br>（1）包含exe文件的输出目录<br>（2）进程的工作目录（工程主目录）<br>（3）Windows系统目录<br>（4）Windows目录<br>（5）列在Path环境变量中的一系列目录<br>  在VS工程中设置Path路径：配置属性&gt;调试&gt;环境 PATH=dll所在路径，可以是相对路径（不要有空格，最后已半角分号结束）</p>
<p>*注：openssl的1.1.0及以上版本和1.0.2及以下版本的编译方式有所不同</p>
<h3 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h3><ul>
<li><a href="http://p-nand-q.com/programming/windows/building_openssl_with_visual_studio_2013.html" target="_blank" rel="external">http://p-nand-q.com/programming/windows/building_openssl_with_visual_studio_2013.html</a></li>
<li><a href="http://blog.csdn.net/u010725842/article/details/50295235" target="_blank" rel="external">http://blog.csdn.net/u010725842/article/details/50295235</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp;简单介绍如何使用VS2013编译配置openssl，并添加到工程中&lt;br&gt;
    
    </summary>
    
      <category term="Compile &amp; Installation" scheme="https://senitco.github.io/categories/Compile-Installation/"/>
    
    
      <category term="Sofeware" scheme="https://senitco.github.io/tags/Sofeware/"/>
    
  </entry>
  
  <entry>
    <title>机器学习算法之数据降维</title>
    <link href="https://senitco.github.io/2017/05/10/data-dimensionality-reduction/"/>
    <id>https://senitco.github.io/2017/05/10/data-dimensionality-reduction/</id>
    <published>2017-05-10T13:17:14.930Z</published>
    <updated>2017-05-24T06:43:25.532Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;数据降维是通过某种数学变换将原始高维属性空间，转变为一个低维子空间，对数据进行降维，可以有效地去除样本中冗余的属性，减少数据容量，缓解维数灾难，加快学习速度。数据降维的常用方法有主成分分析(PCA)、多维缩放(MDS)、线性判别分析(LDA)、等度量映射(Isomap)、局部线性嵌入(LLE)、t分布随机邻域嵌入(t-SNE)、Laplacian Eigenmaps等。<br><a id="more"></a></p>
<!-- mathjax config similar to math.stackexchange -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
        inlineMath: [ ['$', '$'] ],
        displayMath: [ ['$$', '$$']],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    messageStyle: "none",
    "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<h3 id="主成分分析-PCA"><a href="#主成分分析-PCA" class="headerlink" title="主成分分析(PCA)"></a>主成分分析(PCA)</h3><p>&emsp;&emsp;主成分分析是一种线性降维方法，将高维空间映射到低维空间，并使得所有样本在低维空间的投影点尽可能分开，也就是低维子空间对样本具有最大可分性，为了实现这种最大可分性，应该使投影后样本的方差最大化。</p>
<p><img src="https://ooo.0o0.ooo/2017/05/11/59141de4ab509.png" alt="pca.png" title="PCA最大化投影点方差" width="256" height="240" align="center">   </p>
<p>&emsp;&emsp;对于一个维数为$D$的高维空间，样本点$x_i=(x_1,x_2,…,x_D)$通过与矩阵$W$相乘映射到低维空间（维数为$d$，$d&lt;D$）中的某个点$z_i=W^T x_i=(z_1,z_2,…,z_d)$，矩阵$W$的大小是$D\ast d$。令数据样本集的大小为$N$，PCA的目标是要让低维子空间中 $z_{i}$ 尽可能地分开，因此投影后样本的方差要尽可能的大。假定数据样本进行了中心化，数据每一维的均值为$0$，即 $\Sigma_{i}x_{i}=0$，乘上矩阵$W^T$得到的降维后的数据每一维均值也为$0$，考虑高维空间中原始样本数据集的协方差矩阵$C=\dfrac{1}{N}\ast XX^T$，协方差矩阵中对角线上的值为某一维的方差，非对角线上的值为两维之间的协方差。降维后低维子空间中相应的协方差矩阵为$B=\dfrac{1}{N}\ast ZZ^T$，如果希望降维后的点具有最大的可分性，那么协方差矩阵$B$对角线上的值也就是每一维的方差应该尽可能的大，同时为了让不同的属性能够更多地表示原始信息，而不包含冗余的信息，可以使不同属性之间正交，这种情况下矩阵$B$非对角线上的值即不同维之间的协方差为$0$。因此降维后的每一维既有足够的区分性，又能代表不同的信息。对于矩阵$B$，可进一步推导出$B=\dfrac{1}{N}\ast ZZ^T=\dfrac{1}{N}\ast W^T X(W^T X)^T=W^T (\dfrac{1}{N}\ast XX^T)W=W^TCW$，这个式子表明，线性变换矩阵$W$实现数据降维的过程是将高维空间中的协方差矩阵$C$对角化，因此可通过求协方差矩阵$C$的特征值以及对应的特征向量来确定投影变换矩阵$W$。PCA的算法流程如下所述： </p>
<ul>
<li><strong>输入</strong>：样本集${x_1,x_2,…,x_N }$，低维空间的维数$d$；  </li>
<li><strong>过程</strong>：  </li>
<li>对所有数据样本进行中心化$x_i=x_i-\dfrac{1}{N} \Sigma_{i}x_{i}$；  </li>
<li>计算样本的协方差矩阵$C=\dfrac{1}{N} XX^T$；  </li>
<li>对协方差矩阵$C$做特征值分解：  </li>
<li>取最大的$d$个特征值对应的特征向量$w_1,w_2,…,w_d$；  </li>
<li><strong>输出</strong>：投影矩阵$W=(w_1,w_2,…,w_d)$，$w_i$为$D$维列向量。  </li>
</ul>
<h3 id="多维缩放-MDS"><a href="#多维缩放-MDS" class="headerlink" title="多维缩放(MDS)"></a>多维缩放(MDS)</h3><p>&emsp;&emsp;多维缩放要求原始高维空间中数据样本之间的距离在低维空间中保持不变，即在降维的过程中保留原始数据的差异性。</p>
<p><img src="https://ooo.0o0.ooo/2017/05/11/5914394c82f1d.jpg" alt="MDS.jpg" title="多维缩放示意图" align="center"></p>
<p>&emsp;&emsp;假定$N$个样本在$D$维原始空间的距离矩阵为$A\in R^{N×N}$，其第$i$行第$j$列的元素$a_{ij}$为样本$x_i$到$x_j$的距离。多维缩放的目标是获得数据样本在$d$维空间的表示$Z\in R^{d×N}$,$d≤D$，且任意两个样本在低维空间的欧氏距离等于原始空间中的距离，即$\left|z_i-z_j \right|=a_{ij}$。令$B=Z^T Z\in R^{N×N}$,其中$B$为降维后样本的內积矩阵，$b_{ij}=z_i^T z_j$，根据样本在原始空间和低维空间的距离相等有<br>$$a_{ij}^2=‖z_i-z_j ‖^2=‖z_i ‖^2+‖z_j ‖^2-2z_i^T z_j=b_{ii}+b_{jj}-2b_{ij}$$<br>&emsp;&emsp;令降维后的数据样本$Z$中心化，数据每一维的均值为$0$，即$\Sigma_i z_i = 0$。显然，內积矩阵$B$的行与列之和均为$0$，即$\Sigma_{i=1}^N b_{ij} = \Sigma_{j=1}^N b_{ij} = 0$，则有以下式子成立：<br>$$\Sigma_{i=1}^N a_{ij}^2 =tr(B)+Nb_{jj}$$<br>$$\Sigma_{j=1}^N a_{ij}^2 =tr(B)+Nb_{ii}$$<br>$$\Sigma_{i=1}^N \Sigma_{j=1}a_{ij}^2 =2Ntr(B)$$<br>其中 $tr(B)=\Sigma_{i=1}^N ‖z_i‖^2$ 为矩阵$B$的迹，令<br>$$a_{i\cdot}^2=\dfrac{1}{N} \Sigma_{j=1}^N a_{ij}^2$$<br>$$a_{\cdot j}^2=\dfrac{1}{N} \Sigma_{i=1}^N a_{ij}^2$$<br>$$a_{\cdot \cdot}^2=\dfrac{1}{N^2} \Sigma_{i=1}^N \Sigma_{j=1}^N a_{ij}^2$$<br>由以上各式可得<br>$$b_{ij}=-\dfrac{1}{2} (a_{ij}^2-a_{i \cdot}^2-a_{\cdot j}^2+a_{\cdot \cdot}^2)$$<br>由此即可通过降维前后保持不变的距离矩阵$A$求取內积矩阵$B$。对矩阵$B$做特征值分解，$B=VΛV^T$，其中$Λ=diag(λ_1,λ_2,…,λ_d)$为特征值构成的对角矩阵，$λ_1≥λ_2≥\ldots≥λ_d$，$V$为特征向量矩阵，则$Z$可表达为<br>$$Z=Λ^{1/2} V^T∈R^{d×N}$$<br>为了实现有效降维，往往仅需降维后的距离与原始空间中距离尽可能接近，而不必严格相等，因此可取$d(d&lt;&lt;D)$个最大特征值构成对角矩阵。MDS的算法流程如下所述：  </p>
<ul>
<li><strong>输入</strong>：距离矩阵$A∈R^{N×N}$，其元素$a_{ij}$为样本$x_i$到$x_j$的距离，原始空间维数为$D$，低维空间维数为$d$；</li>
<li><strong>过程</strong>：</li>
<li>计算內积矩阵$B$；</li>
<li>对矩阵$B$做特征值分解；</li>
<li>取$d$个最大的特征值构成的对角矩阵$Λ$和对应的特征向量矩阵$V$；</li>
<li><strong>输出</strong>：矩阵$Z=Λ^{1/2} V^T∈R^{d×N}$，每列为一个样本的低维坐标。  </li>
</ul>
<h3 id="线性判别分析-LDA"><a href="#线性判别分析-LDA" class="headerlink" title="线性判别分析(LDA)"></a>线性判别分析(LDA)</h3><p>&emsp;&emsp;线性判别分析是一种典型的线性学习方法，在二分类问题上最早由Fisher提出。LDA的基本思想是给定数据样本集，设法将样本投影到一个低维空间，使得同类样本的投影点尽可能接近，不同类样本的投影点尽可能远离。LDA和PCA的降维思路相似，都是通过矩阵乘法进行线性降维，但两者原理有所不同，PCA是希望所有样本在每一维上尽可能分开。  </p>
<p><img src="https://ooo.0o0.ooo/2017/05/11/59143a62391a0.jpg" alt="LDA.jpg" title="LDA投影示意图" align="center/"></p>
<p>&emsp;&emsp;给定数据样本集$D={(x_i,y_i )},i=1,2,…,N$，样本集的大小为$N$，样本的类别数为$K$，令$X_i$ 、$μ_i$ 、$Σ_i$分别表示第$i(i=1,2,…,K)$类样本的集合、均值向量和协方差矩阵，样本在低维空间的表示为$z_i=W^T x_i$，欲使同类样本的投影点尽可能近，可以让同类样本投影点的协方差尽可能小；欲使不同类样本的投影点尽可能远离，则可以让不同类中心之间的距离尽可能大，定义类内散度矩阵<br>$$S_w=\Sigma_{k=1}^K S_k = \Sigma_{k=1}^K \Sigma_{X∈X_k} (X-μ_k)(X-μ_k)^T$$<br>即$K$个类的原始数据协方差矩阵相加。定义类间散度矩阵<br>$$S_b=\Sigma_{k=1}^K N_k (μ_k-u)(μ_k-u)^T$$<br>其中$μ=1/N \Sigma_{k=1}^K N_k μ_k$($N_k$为第$k$类的样本个数)，同时考虑两者，则LDA算法的最大化目标<br>$$max_W J(W)=tr(W^T S_b W)/tr(W^T S_w W)$$<br>其中，$W∈R^{D×(N-1)}$，$tr(∙)$表示矩阵的迹，$J(W)$对$W$求偏导<br>$$∂J(W)/∂W=(W^T S_w W)2S_b W-(W^T S_b W)2S_w W = 0$$<br>$$S_b W - J(W) S_w W = 0$$<br>上式表明$W$的闭式解是$S_w^{-1} S_b$的$K-1$最大广义个特征值所对应的特征向量组成的矩阵。若将$W$视为一个投影矩阵，则多分类LDA将样本投影到$K-1$维空间，$K-1$通常远小于数据的原有属性数。通过投影可有效减少样本的维数，而且投影过程中使用了类别信息，因此LDA也常视为一种经典的监督降维技术。LDA的算法流程如下：  </p>
<ul>
<li><strong>输入</strong>：数据样本集$D={(x_i,y_i)},i=1,2,…,N$，数据可以分为$K$个类；  </li>
<li><strong>过程</strong>：<br>  计算类内散度矩阵$S_w$和类间散度矩阵$S_b$；<br>  对矩阵$S_w$做奇异值分解，$S_w=UΣV^T, S_w^{-1}=VΣ^{-1} U^T$，$Σ$是一个实对称矩阵；<br>  对矩阵$S_w^{-1} S_b$进行特征值分解；<br>  取最大的d个特征值对应的特征向量；  </li>
<li><strong>输出</strong>：$W=(w_1,w_2,…,w_d)$  </li>
</ul>
<h3 id="等度量映射-Isomap"><a href="#等度量映射-Isomap" class="headerlink" title="等度量映射(Isomap)"></a>等度量映射(Isomap)</h3><p>&emsp;&emsp;等度量映射是一种基于流形学习的数据降维方法，流形是在局部与欧式空间同胚的空间，也就是说在局部具有欧式空间的性质，可以利用欧氏距离进行距离计算。低维流形嵌入到高维空间之后，直接在高维空间中计算直线距离具有误导性，因为高维空间中直线距离在低维嵌入流形上是不可达的。利用流形在局部上与欧式空间同胚的性质，对每个点基于欧式距离找出其近邻点，然后建立一个近邻连接图，图中近邻点之间存在连接，而非近邻点之间不存在连接。于是计算两点之间测地线距离的问题，就转变为计算近邻连接图上两点之间的最短路径问题，基于近邻逼近能获得低维流形上测地线很好的近似。  </p>
<p><img src="https://ooo.0o0.ooo/2017/05/11/59143b0c1c127.jpg" alt="Isomap.jpg" title="低维嵌入流形示意图" align="center/"></p>
<p>&emsp;&emsp;多维缩放(MDS)对数据降维，需要已知高维空间中样本之间的距离关系，等度量映射(Isomap)结合流形学习的思想和多维缩放的方法来进行降维，在高维空间的局部空间，计算邻近点的欧式距离，并构建近邻连接图。然后利用Dijkstra算法或Floyd算法在近邻连接图上计算两点间的最短路径，得到任意两点间的距离之后，即可作为MDS算法的输入距离矩阵，通过MDS算法输出样本在低维空间的投影。Isomap算法描述如下：</p>
<ul>
<li><strong>输入</strong>：数据样本集${x_1,x_2,…,x_N }$，近邻参数$k$，低维空间维数$d$；</li>
<li><strong>过程</strong>：</li>
<li>利用$k$近邻算法计算$x_i$与$k$个近邻样本点的欧式距离，与其他点的距离设为无穷大；  </li>
<li>根据最短路径算法计算任意两个样本点之间的距离，得到距离矩阵$A$；  </li>
<li>将距离矩阵$A$作为MDS算法的输入，得到输出；  </li>
<li><strong>输出</strong>：样本集在低维空间的投影$Z=(z_1,z_2,…,z_N)$，$z_i$为低维空间的向量。</li>
</ul>
<h3 id="局部线性嵌入-LLE"><a href="#局部线性嵌入-LLE" class="headerlink" title="局部线性嵌入(LLE)"></a>局部线性嵌入(LLE)</h3><p>&emsp;&emsp;局部线性嵌入是一种基于流形学习的算法，能够使降维后的数据较好地保持原有的流形结构。与等度量映射(Isomap)试图保持近邻样本之间的距离不同，LLE试图保持降维前后邻域内样本之间的线性关系。</p>
<p><img src="https://ooo.0o0.ooo/2017/05/11/5914408c847b5.jpg" alt="LLE.jpg" title="局部线性嵌入示意图" align="center/"></p>
<p>&emsp;&emsp;在原始空间中，假定样本点$x_i$的坐标利用其邻域样本的坐标通过线性组合而重构出来，即$x_i=\Sigma_{j∈X_i} w_{ij} x_j$，其中$X_i$是$x_i$邻域内样本点的下标集合。通过最小化重构误差来求解对每个样本点$x_i$进行线性重构的权值系数$w_i$，即<br>$$min_{w_1,w_2,…,w_m} \Sigma_{i=1}^m ‖x_i-\Sigma_{j∈X_i} w_{ij} x_j‖,  s.t.\Sigma_(j∈X_i) w_{ij}=1$$<br>其中$x_i$和$x_j$均为已知样本点，定义局部协方差矩阵$C_{jk}=(x_i-x_j)^T (x_i-x_k )，w_{ij}$有闭式解<br>$$w_{ij}=(\Sigma_{k∈X_i} C_{jk}^{-1})/(\Sigma_{l,s∈X_i} C_{ls}^{-1})$$<br>LLE在低维空间中保持权重$w_i$不变，因此$x_i$对应在低维空间的坐标$z_i$可通过最优化下式求解<br>$$min_{z_1,z_2,…,z_m} \Sigma_{i=1}^m ‖z_i-\Sigma_{j∈X_i} w_{ij} z_j‖$$<br>令$Z=(z_1,z_2,…,z_m)∈R^{d×m}, (W)_{ij}=w_{ij}$,<br>$$M=(I-W)^T (I-W)$$<br>则最优化目标可重写为<br>$$min_Z tr(ZMZ^T),  s.t.ZZ^T=I$$<br>利用拉格朗日乘子法可以得到$MZ=λZ$的形式，因此可对矩阵$M$进行特征值分解，取$d$个最小的非零特征值对应的特征向量组成的矩阵即为样本在低维空间的投影$Z$。算法描述如下：  </p>
<ul>
<li><strong>输入</strong>：数据样本集${x_1,x_2,…,x_m}$，近邻参数$k$，低维空间维数$d$；</li>
<li><strong>过程</strong>：</li>
<li>利用$k$近邻算法确定每个样本点$x_i$的邻域样本的下标集合$X_i$；  </li>
<li>最小化重构误差计算样本$x_i$的权值系数$w_i$，并得到矩阵$M$；  </li>
<li>对矩阵$M$进行特征值分解；  </li>
<li>取$d$个最小的非零特征值对应的特征向量；  </li>
<li><strong>输出</strong>：样本集在低维空间的投影$Z=(z_1,z_2,…,z_m)$。</li>
</ul>
<h3 id="t分布随机邻域嵌入-t-SNE"><a href="#t分布随机邻域嵌入-t-SNE" class="headerlink" title="t分布随机邻域嵌入(t-SNE)"></a>t分布随机邻域嵌入(t-SNE)</h3><p>&emsp;&emsp;t-SNE是一种非线性降维方法，非常适用于高维数据降到二维或者三维空间，进行可视化。其基本原理是在高维空间中构建一个样本之间的概率分布，使得相似的样本有更高的概率被选择，而不相似的样本被选择的概率较低；然后在低维空间中构建这些样本点的概率分布，使得这两个概率分布尽可能的相似，并利用KL散度(Kullback–Leibler divergence)来度量两个分布之间的相似性。<br>&emsp;&emsp;给定一个高维空间的数据样本集${x_1,x_2,…,x_N },x_i∈R^D$，$N$为样本集的大小。假设高维空间中的任意两个样本点，$x_j$的取值服从以$x_i$为中心、$σ_i$为方差的高斯分布，同样$x_i$也服从以$x_j$为中心、$σ_j$为方差的高斯分布，这样样本点$x_j$与$x_i$相似的条件概率为<br>$$p_{j|i}=\dfrac{-exp(\left|x_i-x_j\right|^2 / 2\sigma^2)}{\Sigma_{k\neq i} exp(\left|x_i-x_k\right|^2 / 2\sigma^2)}$$<br>即$x_j$在$x_i$高斯分布下的概率占全部样本在$x_i$高斯分布下概率的多少。定义两个点相似度在全部样本两两相似度的联合概率<br>$$p_{ij}=(p_{j|i}+p_{i|j})/2N$$<br>t-SNE的目标是学习一个高维到低维的映射${y_1,y_2,…,y_N },y_i∈R^d$，在低维空间中，两个点相似度也利用联合概率来表示，假设低维空间中两点间的欧氏距离服从学生分布，两个点$y_i$和$y_j$的相似度可定义为<br>$$q_{ij}=\dfrac{(1+\left|y_i-y_j\right|^2)^{-1}}{\Sigma_{k\neq i} (1+\left|y_k-y_l\right|^2)^{-1}}$$<br>如果在高维空间中样本点之间的相似度$p_{ij}$和在低维空间中样本点之间的相似度$q_{ij}$相同，就说明低维空间的点能正确反映高维空间中的相对位置关系。t-SNE的目标就是要找到一组降维表示能够最小化$p_{ij}$和$q_{ij}$的差值，因此采用KL散度来构建目标函数<br>$$C=\Sigma_i KL(P_i||Q_i)=\Sigma_i \Sigma_j p_{j|i}log{\dfrac{p_{j|i}}{q_{j|i}}}$$<br>KL散度能够衡量两个概率分布的差别，通过梯度下降法来求输入数据对应的低维表达$y_i$。即用目标函数对$y_i$求导，梯度值为<br>$$\dfrac{dC}{dy_i}=4\Sigma_j(p_{ij}-q_{ij})(y_i-y_j)(1+\left|y_i-y_j\right|^2)^{-1}$$<br>然后更新迭代$y_i$，算法流程大致如下：  </p>
<ul>
<li><strong>输入</strong>：数据样本集${x_1,x_2,…,x_N},x_i∈R^D$，代价函数的参数$Perp$，迭代次数$T$，学习率$η$，$momentum$项系数$α(t)$</li>
<li><strong>过程</strong>：  </li>
<li>计算给定$Perp$下的条件概率$p_{j|i}$；   </li>
<li>分别计算高维空间样本点的相似度$p_{ij}$和低维空间样本点的相似度$q_{ij}$；  </li>
<li>对目标函数求导，计算梯度值；  </li>
<li>迭代更新$y_i$，直至收敛或达到最大迭代次数；  </li>
<li><strong>输出</strong>：低维数据表示${y_1,y_2,…,y_N},y_i∈R^d$</li>
</ul>
<h3 id="拉普拉斯特征映射-Laplacian-Eigenmaps"><a href="#拉普拉斯特征映射-Laplacian-Eigenmaps" class="headerlink" title="拉普拉斯特征映射(Laplacian Eigenmaps)"></a>拉普拉斯特征映射(Laplacian Eigenmaps)</h3><p>&emsp;&emsp;拉普拉斯特征映射和局部线性嵌入(LLE)类似，也是一种基于流形学习的数据降维方法，都是从图的角度去构建数据之间的关系。其基本思想是在高维空间中相互有关系或者说相连的样本点，在降维后的低维空间中尽可能的靠近，以反映数据内在的流形结构。<br>&emsp;&emsp;Laplacian Eigenmaps通过构建相似关系图，图中每个顶点代表一个样本点，每一条边权重代表样本之间的相似程度，距离越近的点越相似，而且权值越大，以此来重构数据流形的局部结构特征。给定一个高维空间的数据样本集$X={x_1,x_2,…,x_N },x_i∈R^D$，$N$为样本集的大小，样本集在低维空间的映射为$Y={y_1,y_2,…,y_N},y_i∈R^d$，降维后的空间维数为$d$。如果两个样本点$x_i$和$x_j$很相似，那么在降维后的空间中应该尽可能接近，因此要优化的目标函数如下：<br>$$min\Sigma_{i,j} W_{ij} ‖y_i-y_j ‖^2 $$<br>式中，$W$为一权重矩阵，$W_{ij}$为度量样本点$x_i$和$x_j$相似性的权值，可通过一个热核函数来定义：<br>$$W_{ij}=e^{‖x_i-x_j‖^2/i}$$<br>根据距离远近确定权值大小，当然也可以简单地将直接相连样本点的权值设为$1$，其他为$0$。定义一个对角矩阵$D$，对角线上元素$D_{ii}$为权重矩阵$W$第$i$行元素之和，即<br>$$D_{ii}=\Sigma_j W_{ij}$$<br>令$L=D-W$，$L$为拉普拉斯矩阵，则<br>$$\Sigma_{i,j} W_{ij} ‖y_i-y_j‖^2 = \Sigma_i ‖y_i‖^2 D_{ii} + \Sigma_j ‖y_j‖^2 D_{jj} - 2\Sigma_{i,j} y_i^T y_j W_{ij} = 2Y^T LY$$<br>因此最优化目标可重写为<br>$$min⁡&emsp;tr(Y^T LY), &emsp;s.t.Y^T DY=I$$<br>使用拉格朗日乘子法，可得<br>$$LY=λDY$$<br>基于上式进行特征值分解，取$d$个最小的非零特征值所对应的特征向量组成的矩阵即为降维后的结果输出。算法流程如下：</p>
<ul>
<li><strong>输入</strong>：高维数据样本集$X={x_1,x_2,…,x_N},x_i∈R^D$，降维后的空间维数为$d$；  </li>
<li><strong>过程</strong>：</li>
<li>利用某种方法将所有样本点构建成一个图，例如K近邻算法，将每个点和最近的$K$个点相连；</li>
<li>确定点与点之间连接边的权重$W_{ij}$，例如热核函数；</li>
<li>进行特征映射，计算拉普拉斯矩阵最小的$d$个非零特征值对应的特征向量作为输出矩阵；  </li>
<li><strong>输出</strong>：样本集在低维空间的映射为$Y={y_1,y_2,…,y_N},y_i∈R^d$</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp;数据降维是通过某种数学变换将原始高维属性空间，转变为一个低维子空间，对数据进行降维，可以有效地去除样本中冗余的属性，减少数据容量，缓解维数灾难，加快学习速度。数据降维的常用方法有主成分分析(PCA)、多维缩放(MDS)、线性判别分析(LDA)、等度量映射(Isomap)、局部线性嵌入(LLE)、t分布随机邻域嵌入(t-SNE)、Laplacian Eigenmaps等。&lt;br&gt;
    
    </summary>
    
      <category term="Algorithm" scheme="https://senitco.github.io/categories/Algorithm/"/>
    
    
      <category term="ML" scheme="https://senitco.github.io/tags/ML/"/>
    
  </entry>
  
  <entry>
    <title>Chinese Text Detection and Recognition</title>
    <link href="https://senitco.github.io/2017/03/03/text-detection-recognition/"/>
    <id>https://senitco.github.io/2017/03/03/text-detection-recognition/</id>
    <published>2017-03-03T06:45:21.196Z</published>
    <updated>2017-05-24T06:44:44.280Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;The task of Chinese text detection is to localize the regions in a 2D image which contain Chinese characters. The task of Chinese text recognition is, given the localized regions including text, to convert each region into machine-encoded text. It is an important technique for understanding text information in 2D images, and many other applications such as text-to-speech, machine translation, text mining, etc.<br><a id="more"></a></p>
<h3 id="Course"><a href="#Course" class="headerlink" title="Course"></a>Course</h3><p>&emsp;&emsp;Image Analysis and Understanding</p>
<h3 id="Project"><a href="#Project" class="headerlink" title="Project"></a>Project</h3><p>&emsp;&emsp;Chinese Text Detection and Recognition</p>
<h3 id="Description"><a href="#Description" class="headerlink" title="Description"></a>Description</h3><p>&emsp;&emsp;The task of Chinese text detection is to localize the regions in a 2D image which contain Chinese characters. The task of Chinese text recognition is, given the localized regions including text, to convert each region into machine-encoded text. It is an important technique for understanding text information in 2D images, and many other applications such as text-to-speech, machine translation, text mining, etc.</p>
<h3 id="Deadline"><a href="#Deadline" class="headerlink" title="Deadline"></a>Deadline</h3><p>&emsp;&emsp;April 11, Tuesday, 2017</p>
<h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><p>&emsp;&emsp;图像文本一般分为两大类，图形文本(Graphic text)和场景文本(Scene text)，图形文本通常是指覆盖在图像上的机器打印的文本，如图片水印、视频字幕等；而场景文本则是自然场景中物体上的文本，如墙壁上的标语、衣服上的文字等。最近大部分的研究都集中在自然场景中文本检测与识别上，由于受到场景复杂、光照变化、成像随意等因素的影响，这一研究任务具有较大的挑战性，但其应用领域十分广泛，包括文字转语音、多语言翻译、自动化生产等。<br>&emsp;&emsp;对于文本检测，需要在一幅2D图像上准确定位到文本区域，而识别则是在此基础上将其识别转换为机器编码的文字。此次项目设计，主要针对自然场景中文本图像，采用多种方法进行检测并作对比，在定位到文本区域的基础上，采用Tesseract的开源库做进一步的识别。</p>
<h3 id="Method-amp-Model"><a href="#Method-amp-Model" class="headerlink" title="Method &amp; Model"></a>Method &amp; Model</h3><p>&emsp;&emsp;文本检测方法来源于ECCV 2016上的一篇文章——<a href="https://arxiv.org/pdf/1609.03605.pdf" target="_blank" rel="external">Detecting Text in Natural Image with Connectionist Text Proposal Network</a>，是一种基于Faster R-CNN的端到端的检测方法。R-CNN是目标检测领域中十分经典的方法，相比于传统的手工特征，R-CNN将卷积神经网络引入，用于提取深度特征，后接一个分类器预测搜索区域是否包含目标及其置信度，并取得了相对而言较为准确的检测结果，而Fast R-CNN和Faster R-CNN则是R-CNN的升级版本，在准确率和实时性方面都得到了较大的提升。在Fast R-CNN中，首先需要使用Selective Search的方法提取图像的proposals，也就是候选目标区域。而新提出的Faster R-CNN模型则引入了RPN网络(Region Proposal Network)提取proposals，RPN是一个全卷积网络，通过共享卷积层特征大大缩短了proposals提取的时间，Fast R-CNN基于RPN提取的proposal作进一步的检测和识别。因此Faster R-CNN模型主要由两大模块组成：RPN候选框提取模块和Fast R-CNN检测模块，如下图所示。</p>
<p><img src="https://ooo.0o0.ooo/2017/05/14/5917b8d52ee44.jpg" alt="Faster R-CNN.jpg" title="Faster R-CNN模型图" width="50%" height="50%" align="center"></p>
<p>&emsp;&emsp;在Faster R-CNN中，利用VGG-16进行特征提取，RPN网络结构如图2所示，在conv5卷积层用一个n x n的滑动窗口生成一个512维的全连接层，该层后接两个子连接层：分类层(cls-layer)和回归层(reg-layer)，cls-layer用于判断检测的proposal是目标还是背景，reg-layer则用于预测proposal的宽高和中心锚点的坐标，滑动窗口的处理方式保证了两个子连接层关联了conv5的全部特征空间。在RPN中有一个较为重要的概念——Anchor，对于一个滑动窗口，可以同时预测多个proposal，假设proposal最多为k个，k个proposal对应k个参考候选框(reference box)，这k个参考候选框即为Anchor，通过取不同的scale和aspect ratio，对应不同的Anchor，Faster R-CNN模型k值为9，即3种不同的scale和aspect ratio确定当前滑动窗口位置处对应的9个Anchor，最后cls-layer和reg-layer输出参数的数量分别为2k和4k。对于一幅W x H的卷积特征层，对应 W x H x k个Anchor，所有的Anchor都具有尺度不变性。</p>
<p><img src="https://ooo.0o0.ooo/2017/05/14/5917b9c3ab2a9.jpg" alt="RPN.jpg" title="RPN网络结构" width="50%" height="50%" align="center"></p>
<p>&emsp;&emsp;训练RPN时，一个Mini-batch是由一幅图像中任意选取的256个proposal组成的，其中正负样本的比例为1 : 1。如果正样本数不足，则多补充一些负样本以满足有256个proposal可以用于训练。在RPN训练开始时，共享的VGG卷积层参数可以直接拷贝ImageNet中训练好的模型参数，剩余层参数用标准差为0.01的高斯分布初始化。RPN在提取到proposal后，通过训练Fast R-CNN进行检测和识别，而RPN和Fast R-CNN共用了VGG的卷积层，因此采用交替训练的方式实现卷积层特征共享。Faster R-CNN一个较为突出的贡献就是引入RPN，将proposal部分嵌入到了内部网络，因此整个网络模型即可完成端到端的检测任务，而不需要先执行proposal的搜索定位算法。<br>&emsp;&emsp;Faster R-CNN在目标检测方面能取得良好的效果，但文本检测和一般的目标检测不同，文本是一系列字符、笔画或单词的序列集合，而不是一般目标检测中独立的目标，同一文本序列上的不同字符可能差异较大、距离长短不一，检测出一个完整的文本行可能比检测单个目标的难度要大。因此针对文本检测这种特殊的情况，论文中提出了一种Recurrent Connectionist Text Proposal Network (CTPN)的检测方法，算法思想和Faster R-CNN类似，通过搜索定位多个候选文本框(Text Proposal)，对每个proposal做分类判决，包括proposal为文本、非文本的概率以及proposal的坐标位置。不同的是，CTPN中定义的Anchor是fine-scale的，在水平方向固定宽度为16个像素，而在垂直方向考虑k(=10)种尺寸，这和RPN中同一个滑动窗口考虑9个Anchor，分别为3种不同的scale和aspect ratio有所不同，正是考虑了文本和一般目标检测的差异，作者认为预测文本的垂直位置比水平位置要更容易，在proposal生成网络中，最后的输出分别为proposal的分类概率以及proposal的高度、中心锚点的y坐标以及在水平方向的偏移量，因为宽度是固定的，不予考虑。CTPN与Faster R-CNN还有一个较大的不同之处就是将RPN换成了双向的长短时记忆网络(BLSTM)，VGG-16的conv5卷积层(W x H x C)，不是直接连接到全连接层，而是将每一行的所有滑动窗口对应的3 x 3 x C特征输入到BLSTM中，用于编码Text Proposal的上下文信息，更加准确地检测文本区域。单向LSTM的维数为128，因此得到W x 256的输出，然后将BLSTM连接到512维的全连接层，全连接层后接3个子连接层，分别用于预测proposal的类别信息、在垂直方向的高度和y坐标以及在水平方向的偏移量。CTPN的整体网络结构和提取的Text Proposal示意图如图3所示，在得到多个细长的Text Proposal后，文中利用一种文本行构造算法，将多个Text Proposal合并成一个完整的文本区域，其主要思想是根据一定的约束条件，将相邻的Text Proposal两两合并，直到没有公共元素为止。</p>
<p><img src="https://ooo.0o0.ooo/2017/05/14/5917ba8f3a3ed.jpg" alt="CTPN.jpg" title="CTPN网络结构和Text Proposal" align="center"></p>
<h3 id="Detection-Results"><a href="#Detection-Results" class="headerlink" title="Detection Results"></a>Detection Results</h3><!-- <figure class="third">
    <img src="https://ooo.0o0.ooo/2017/05/14/5917bc63897c8.jpg" alt="1.jpg" width=30% height=30%>
    <img src="https://ooo.0o0.ooo/2017/05/14/5917bc6386978.jpg" alt="2.jpg" width=30% height=30%>
    <img src="https://ooo.0o0.ooo/2017/05/14/5917bc638a778.jpg" alt="3.jpg" width=30% height=30%>
</figure>
<figure class="third">
    <img src="https://ooo.0o0.ooo/2017/05/14/5917bc63857a0.jpg" alt="4.jpg" width=30% height=30%>
    <img src="https://ooo.0o0.ooo/2017/05/14/5917bc638e4f5.jpg" alt="5.jpg" width=30% height=30%>
    <img src="https://ooo.0o0.ooo/2017/05/14/5917bc6387f6b.jpg" alt="6.jpg" width=30% height=30%>
</figure> -->
<p><img src="https://ooo.0o0.ooo/2017/05/14/5917cbb71e93b.png" alt="7.png" title="Detection Results" align="center"></p>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>&emsp;&emsp;在文本检测中用到的这种基于Faster R-CNN的算法模型，针对自然场景的多语言文本能取得良好的检测结果，比较适用于水平方向的文本检测，对于非水平方向的文本，该模型虽然也能有效检测，但不能获取文本的整体偏转信息，不利于后续的文本识别，因此在检测到文本区域后，对文本的整体偏转角度做了进一步的检测和校正。在识别任务中，主要用到了Tesseract的开源库，该OCR引擎对于中文的识别效果不是太理想。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6945320" target="_blank" rel="external">Text Detection and Recognition in Imagery: A Survey</a><br><a href="http://lbmedia.ece.ucsb.edu/member/uweb/Teaching/website/index.htm" target="_blank" rel="external">Course Website: Image Analysis and Understanding</a><br><a href="http://www.cnblogs.com/venus024/p/5717766.html" target="_blank" rel="external">R-CNN,SPP-NET, Fast-R-CNN,Faster-R-CNN系列检测方法解读</a><br><a href="https://arxiv.org/pdf/1609.03605.pdf" target="_blank" rel="external">Detecting Text in Natural Image with Connectionist Text Proposal Network</a><br><a href="http://www.cnblogs.com/lillylin/p/6277061.html" target="_blank" rel="external">Paper Reading: CTPN</a><br><a href="https://github.com/tianzhi0549/CTPN" target="_blank" rel="external">Source Code: CTPN</a><br><a href="https://github.com/chongyangtao/Awesome-Scene-Text-Recognition" target="_blank" rel="external">Text Detection and Recognition Resource –1</a><br><a href="https://handong1587.github.io/deep_learning/2015/10/09/ocr.html" target="_blank" rel="external">Text Detection and Recognition Resource –2</a><br><a href="http://blog.csdn.net/peaceinmind/article/details/51387367" target="_blank" rel="external">Text Detection and Recognition Resource –2</a>  </p>
<p>关于Tesseract OCR引擎的安装和配置：<br><a href="http://www.leptonica.org/source/README.html" target="_blank" rel="external">依赖库Leptonica的编译</a><br><a href="https://github.com/tesseract-ocr/tesseract/wiki/Compiling" target="_blank" rel="external">Tesseract-OCR的编译和配置</a><br><a href="https://github.com/openpaperwork/pyocr" target="_blank" rel="external">OCR引擎的Python接口</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp;The task of Chinese text detection is to localize the regions in a 2D image which contain Chinese characters. The task of Chinese text recognition is, given the localized regions including text, to convert each region into machine-encoded text. It is an important technique for understanding text information in 2D images, and many other applications such as text-to-speech, machine translation, text mining, etc.&lt;br&gt;
    
    </summary>
    
      <category term="Projects" scheme="https://senitco.github.io/categories/Projects/"/>
    
    
      <category term="Image" scheme="https://senitco.github.io/tags/Image/"/>
    
  </entry>
  
</feed>
